{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR-COAYCUOqf",
        "outputId": "ec4a621d-082a-45e1-abf7-9035ef8f466a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "excel_filepath = \"/content/drive/MyDrive/submission_content_transparency.xlsx\"\n",
        "df = pd.read_excel(excel_filepath)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zsuOn_vpUzTs",
        "outputId": "05af092a-b831-4fe0-8b8c-de3030c997c2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              filename  \\\n",
              "0                        Australian Federal Police.txt   \n",
              "1    Office of the Australian Information Commissio...   \n",
              "2                         Law Council of Australia.txt   \n",
              "3                Digital Industry Group Inc (DIGI).txt   \n",
              "4               Department of Health and Aged Care.txt   \n",
              "..                                                 ...   \n",
              "242                                            OOP.txt   \n",
              "243                                     Complexico.txt   \n",
              "244                                Lilin Australia.txt   \n",
              "245                                      IdeaSpies.txt   \n",
              "246                           Codemaster Institute.txt   \n",
              "\n",
              "                                               content  \\\n",
              "0    21 August 2023\\nAustralian Federal\\nPolice sub...   \n",
              "1    Department of Industry, Science and Resources\\...   \n",
              "2    Safe and responsible AI in\\nAustralia\\nDepartm...   \n",
              "3    Department of Industry, Science and Resources,...   \n",
              "4    Department of Health and Aged Care\\nSafe and R...   \n",
              "..                                                 ...   \n",
              "242                                sine-conic fractals   \n",
              "243  Supporting responsible AI: Complexico's submis...   \n",
              "244  No! The definitions do not incorporate devices...   \n",
              "245  IdeaSpies is an open innovation platform shari...   \n",
              "246                                                yes   \n",
              "\n",
              "                                     transparency_text  \n",
              "0    transparency, accountability, fairness, privac...  \n",
              "1    public trust and confidence in AI.4 The OAIC h...  \n",
              "2    transparency.....................................  \n",
              "3    transparencyreport.google.com/youtube-policy/r...  \n",
              "4    transparency of AI in the delivery of health c...  \n",
              "..                                                 ...  \n",
              "242                                                NaN  \n",
              "243  transparency, accountability, and trust in the...  \n",
              "244                                                NaN  \n",
              "245                                                NaN  \n",
              "246                                                NaN  \n",
              "\n",
              "[247 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c532e65-0df9-4339-b87c-19383c684089\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>content</th>\n",
              "      <th>transparency_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>21 August 2023\\nAustralian Federal\\nPolice sub...</td>\n",
              "      <td>transparency, accountability, fairness, privac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Office of the Australian Information Commissio...</td>\n",
              "      <td>Department of Industry, Science and Resources\\...</td>\n",
              "      <td>public trust and confidence in AI.4 The OAIC h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Law Council of Australia.txt</td>\n",
              "      <td>Safe and responsible AI in\\nAustralia\\nDepartm...</td>\n",
              "      <td>transparency.....................................</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Digital Industry Group Inc (DIGI).txt</td>\n",
              "      <td>Department of Industry, Science and Resources,...</td>\n",
              "      <td>transparencyreport.google.com/youtube-policy/r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Department of Health and Aged Care.txt</td>\n",
              "      <td>Department of Health and Aged Care\\nSafe and R...</td>\n",
              "      <td>transparency of AI in the delivery of health c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>OOP.txt</td>\n",
              "      <td>sine-conic fractals</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>Complexico.txt</td>\n",
              "      <td>Supporting responsible AI: Complexico's submis...</td>\n",
              "      <td>transparency, accountability, and trust in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Lilin Australia.txt</td>\n",
              "      <td>No! The definitions do not incorporate devices...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>IdeaSpies.txt</td>\n",
              "      <td>IdeaSpies is an open innovation platform shari...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>Codemaster Institute.txt</td>\n",
              "      <td>yes</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>247 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c532e65-0df9-4339-b87c-19383c684089')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c532e65-0df9-4339-b87c-19383c684089 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c532e65-0df9-4339-b87c-19383c684089');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-567b7778-4344-4572-8d95-a5910723925f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-567b7778-4344-4572-8d95-a5910723925f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-567b7778-4344-4572-8d95-a5910723925f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ab3688f6-104d-4136-b99b-f62b3ec36d09\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab3688f6-104d-4136-b99b-f62b3ec36d09 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 247,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 247,\n        \"samples\": [\n          \"Digital Media Research Centre, QUT.txt\",\n          \"Commonwealth Bank of Australia.txt\",\n          \"ANZSA.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 247,\n        \"samples\": [\n          \"Discussion Paper Submission\\nSafe and Responsible AI in Australia | 4 August 2023\\nRhyle Simcock, Nicholas Godfrey, A/Professor Anna Huggins, Professor Mark Burdon\\nSchool of Law/Digital Media Research Centre, Queensland University of Technology*\\nOverview\\nWe thank the Department of Industry, Science and Resources for the opportunity to make a submission in response to the Safe and Responsible AI in Australia discussion paper. We recognise the range of potential advantages that the adoption of AI can bring to both the public and private sectors. However, appropriate governance mechanisms are critical to ensure the responsible development of AI and to mitigate the accompanying risks.\\nAccordingly, Australia\\u2019s existing regulatory frameworks will need to evolve to accommodate the novel challenges posed by AI, and to ensure that adequate mechanisms are in place to address potential harms associated with its use.\\nThis submission draws on our combined expertise as researchers in privacy, public law and digital technologies to outline a number of regulatory reform recommendations for safe and responsible AI in Australia. Our main recommendations, related to questions 1, 2, 6, 7 & 9 of the discussion paper, are that the Australian Government should:\\n\\u2022 adopt different approaches to the regulation of AI in the public and private sectors.\\n\\u2022 amend legislation to safeguard the availability of judicial review for fully or partially\\nautomated decisions.\\n\\u2022 better understand the role of legal code in the digital compliance structures that will\\npower AI/ML developments in the public and private sectors.\\n\\u2022 introduce a statutory requirement for human oversight and review for public sector\\nautomated decision-making systems with serious consequences for individuals.\\n\\u2022 consider approaches to harmonising data quality standards across all levels of\\ngovernment.\\n1\\n\\u2022 consider the merits of design methodologies that promote transparency at all stages\\nof AI development.\\n\\u2022 reform federal and state freedom of information legislation, as well as government\\nprocurement practices, to facilitate open government ideals.\\nQ1. Do you agree with the definitions in this discussion paper? If not, what definitions do you prefer and why?\\nWe do not contribute specifically to the discussion on core definitions except to add that the adoption of language incorporated internationally through the ISO standard appears to be a sensible way forward and should assist to align Australia with developments in other jurisdictions. Given the increasing standardisation of core concepts through legislation with extra-territorial reach, such as the EU\\u2019s General Data Protection\\nRegulation (\\u2018GDPR\\u2019) framework, it would seem beneficial to adopt generally accepted definitions, rather than unique Australian constructions. However, it is important to note that the discussion paper solely focuses on definitions involving core technical processes of AI/machine learning (ML) without consideration of how different types of data/information could be used in those processes. Most notable is the absence of any definitional considerations of personal or sensitive information which is obviously relevant to the application of AI/ML systems. The current Attorney General\\u2019s Department\\nReview of the Privacy Act (\\u2018AG Review\\u2019) is examining whether the definition of personal and sensitive information should be more aligned with the conceptual basis of the GDPR.\\nIt seems non-controversial, but nonetheless important, to consider core definitions for the range of information that will power AI/ML systems and ensure there is consistency across existing and future legal regimes.\\nQ2. What potential risks from AI are not covered by Australia\\u2019s existing regulatory approaches? Do you have suggestions for possible regulatory action to mitigate these risks?\\n2\\nAs noted in our response above, the discussion paper focuses squarely on the core conceptual processes of AI/ML and the risks arising from generated outputs. The paper tacitly acknowledges that the advent of new AI/ML will require major restructuring of data sharing and availability practices. Current processes are governed by a range of different legal frameworks as outlined in the paper. However, the paper does not engage deeply with the major information risks that could flow from widespread adoption of AI/ML processes and the concomitant requirements of industrialised, or government-wide, data sharing requirements. A major concern is information privacy and how the Australian\\nPrivacy Principles could apply to AI/ML driven technological structures. The AG Review appears to be suggesting stronger alignment between the Privacy Act 1988 (Cth) and the GDPR.\\nWe are strongly supportive of this alignment and repeat calls to better understand how alignment with the GDPR, and the possibility of broader alignments with other EU frameworks, such as the AI Act, could operate in Australia given the absence of an ostensible foundation of fundamental rights that guarantee stronger legal protections for\\nAustralian citizens.1 It is clear that the Australian Government sees AI/ML as a core part of Australia\\u2019s future digital economy and the digital governance structures it requires.\\nThese are by necessity driven by the types of technological components highlighted in the discussion paper. However, while these technical changes are necessary, they should not detract from the deeper and more critical issue of how Commonwealth law should best protect the fundamental rights of Australian citizens.\\nApplications involving the use of AI/ML also need to consider how both public and private sector organisations comply with legal and regulatory obligations, particularly in real- time workflows that produce automated forms of decision-making. Since 2018, we have\\n1\\nMark Burdon and Tegan Cohen (2023) Submission to the Attorney General's Department Privacy Act\\nReview Report https://eprints.qut.edu.au/242023/.\\n3\\nproduced research that outlines the complex challenges arising from the conversion of natural language legal and regulatory obligations into machine executable code that is intended to be used for digital compliance purposes.2 Our research has shown that it is a complex and challenging task to produce machine executable legal code that is both functional from a business use perspective and aligns with legal expectations involving judicially approved processes of statutory interpretation.3 Digital compliance processes predicated on the application of legal code in automated decision-making (\\u2018ADM\\u2019) systems will underpin the safe and responsible development of AI/ML in a more ubiquitous sense. The discussion paper is largely silent on this essential issue but it is nonetheless important to consider especially in relation to the development of new legal and regulatory structures, whether they be regulatory or self-regulatory in nature. A broader conceptual framing is required that considers how the technical components outlined in the discussion paper operate in current and future structures that are governed increasingly by automated forms of output built on legal code. As such, it is important to understand how digital compliance processes are conducted across the different logics and perspectives of legal, regulatory and computational based disciplines and professions.4\\nQ6. Should different approaches apply to public and private sector use of AI technologies? If so, how should the approaches differ?\\n2\\nSee, eg, Anna Huggins, Mark Burdon, Alice Witt and Nicolas Suzor, \\u2018Digitising Legislation: Connecting\\nRegulatory Mind-Sets and Constitutional Values\\u2019 (2022) 14(2) Law, Innovation and Technology 325; Alice\\nWitt, Anna Huggins, Guido Governatori and Joshua Buckley, \\u2018Encoding Legislation: A Methodology for\\nEnhancing Technical Validation, Legal Alignment and Interdisciplinarity\\u2019 (2023) Artificial Intelligence and\\nLaw, https://doi.org/10.1007/s10506-023-09350-1; Anna Huggins et al, \\u2018Submission No 196 to the Select\\nSenate Committee on Financial Technology and Regulatory Technology\\u2019 (Issues Paper Submission, 2020, https://www.aph.gov.au/Parliamentary_Business/Committees/Senate/Financial_Technology_and_Regulatory\\n_Technology/FinancialRegulatoryTech/Submissions); Anna Huggins, \\u2018Addressing Disconnection: Automated\\nDecision-Making, Administrative Law and Regulatory Reform\\u2019 (2021) 44(3) University of New South Wales\\nLaw Journal 1048.\\n3\\nMark Burdon et al, \\u2018From Rules as Code to Mindset Strategies and Aligned Interpretive Approaches\\u2019 (2023)\\nJournal of Cross-Disciplinary Research into Computational Law (forthcoming).\\n4\\nHuggins et al, \\u2018Digitising Legislation\\u2019 (n 2 above); Burdon et al (n 3 above).\\n4\\nWe believe that fundamental differences between the public and private sector necessitate different regulatory approaches to the use of AI. While private sector entities typically prioritise profitability, innovation, efficiency and corporate secrecy, traditional public sector principles of good administration include transparency, accountability, rationality, fairness and consistency. Government agencies are not subject to market forces and consumer choice like private entities. Consumers have the power to choose to engage with a different business for the delivery goods and services. However, there is no such freedom of choice in the delivery of government services. The potential risks from the misuse of AI can be heightened in the public sector. There is a significant power imbalance between the state and its citizens, and government use of AI can significantly impact the rights, interests and expectations of individuals. This warrants a higher degree of scrutiny and oversight of the public sector use of AI.\\nAustralia\\u2019s public law frameworks provide important mechanisms for regulating public sector use of AI, including safeguarding executive accountability and protecting individual rights and interests. However, regulatory reform is needed to address gaps in the application of\\nAustralia\\u2019s existing public law frameworks to ADM systems, including to safeguard the contestability of automated government decisions and to ensure human involvement in certain high stakes government decisions.\\nSafeguarding the Contestability of Automated Government Decisions\\nThere is some uncertainty about whether automated government decisions are judicially reviewable. The majority in Pintarich v Deputy Commissioner of Taxation held that a\\n\\u2018decision\\u2019 under the Administrative Decisions (Judicial Review) Act 1977 (Cth) (\\u2018ADJR Act\\u2019) requires a mental process of deliberation.5 This casts doubt on the availability of judicial review under the ADJR Act because ADM, by its very nature, lacks the requisite human mental processes to satisfy this criterion.6 This creates an unacceptable risk that individuals\\n5\\nPintarich v Deputy Commissioner of Taxation (2018) 262 FCR 41.\\n6\\nSee Yee-Fui Ng and Maria O\\u2019Sullivan, \\u2018Deliberation and Automation: When Is a Decision a \\u201cDecision\\u201d?\\u2019\\n(2019) 26(1) Australian Journal of Administrative Law 21.\\n5\\nadversely affected by erroneous or unlawful ADM systems will have limited options for redress.7\\nWe suggest that reform to clarify this legal uncertainty should be a priority for the Australian\\nGovernment. One option is to amend the definition of a \\u2018decision\\u2019 in the relevant State and\\nCommonwealth ADJR Acts to include decisions that are wholly or partly automated.8\\nAnother approach is to modify specific legislation authorising ADM to clarify the availability of judicial review. For example, a deeming provision could be inserted into the respective legislation to confirm that any ADM decision is considered a decision of the authorised decision-maker. We suggest that the first option is preferable given it is inclusive and does not require modification to individual pieces of authorising legislation.9\\nStatutory Protections for Human Involvement in Government Decision-making\\nExisting public law frameworks presuppose that humans remain at the core of the decision- making process. Human oversight and intervention is important for identifying and addressing problems in administrative processes. This remains true for the use of automated systems by administrative agencies. Manual human reviews of the automated debt notices under the Centrelink Online Compliance system (commonly known as\\n\\u2018robodebt\\u2019), for example, would likely have ameliorated many of the problems that arose during its operation. However, there are currently no statutory protections in place that require humans to oversee and review automated outputs.\\nWe suggest that there should be legislative mechanisms in place that mandate human involvement for certain types of automated administrative processes, particularly decisions which have potentially serious consequences for individuals. This aligns with previous recommendations by the Australian Law Reform Commission and the Australian Human\\n7\\nHuggins, \\u2018Addressing Disconnection' (n 2 above) 1061\\u20131064.\\n8\\nYee-Fui Ng et al, \\u2018Revitalising Public Law in a Technological Era: Rights, Transparency and Administrative\\nJustice\\u2019 (2020) 43(3) University of New South Wales Law Journal 1041, 1066.\\n9\\nIbid.\\n6\\nRights Commission that suggest exploring \\u2018the degree of human involvement, if any, that should be required for particular types of decisions\\u2019.10 Some guidance can be sought from the GDPR. Article 22, in particular, prohibits solely automated decision-making that affects individual rights and interests by requiring \\u2018meaningful\\u2019 human involvement. 11 While there are exceptions, minimum protections are in place to ensure that affected individuals have a right to obtain human intervention, to express their views or to contest automated decisions.12\\nQ7. How can the Australian Government further support responsible AI practices in its own agencies?\\nHarmonised Data Quality Standards\\nThe Australian Government should consider approaches to harmonising data quality standards across government, including its collection, management and use. The public sector use of ADM will become increasingly dependent on the exchange of data between administrative agencies. But Australia lacks unified data quality standards across Federal,\\nState and Local Government agencies, including standard definitions, units of measurement and accuracy benchmarks.13 Administrative agencies therefore often have different approaches to how data is organised, characterised and structured.14 This kind of data\\n10\\nAustralian Law Reform Commission, The Future of Law Reform: A Suggested Program of Work 2020\\u201325\\n(Report, December 2019) 24; Australian Human Rights Commission, \\u2018Human Rights and Technology\\u2019 (Final\\nReport, 1 March 2021) 71.\\n11\\nRegulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the\\nProtection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of\\nSuch Data, and Repealing Directive 95/46/EC (\\u2018GDPR\\u2019) [2016] OJ L 119/1 arts 22(2)(a)\\u2013(c). See also Article\\n29 Data Protection Working Party, \\u2018Guidelines on Automated Individual Decision-Making and Profiling for the\\nPurposes of Regulation 2016/679\\u2019 (Guidelines No WP251rev.01, 6 February 2018) 20-21\\n.\\n12\\nGDPR (n 11 above) art 22(3).\\n13\\nData Availability and Use: Productivity Commission Inquiry Report (Australian Government, Productivity\\nCommission, March 2017) 159\\u2013164.\\n14\\nPublic sector data is often fragmented, meaning administrative agencies rarely have enough data to accurately model an outcome of interest in the absence of inter-agency data sharing: Fola Malomo and\\nVania Sena, \\u2018Data Intelligence for Local Government? Assessing the Benefits and Barriers to Use of Big\\nData in the Public Sector\\u2019 (2017) 9(1) Policy & Internet 7, 9\\u201310. See also Andrew Iliadis, \\u02bbThe Tower of Babel\\nProblem: Making Data Make Sense with Basic Formal Ontology\\u02bc (2019) 3(6) Online Information Review\\n1021.\\n7\\nfragmentation can have detrimental impacts on the quality of the data, and consequently, the validity of ADM outputs.\\nWe note that the Data Availability and Transparency Act 2022 (Cth) introduced a legislative scheme for sharing Australian Government data. However, the Act does not contain any stipulations regarding data quality. Only the Australian Privacy Principles, enacted through the Privacy Act 1988 (Cth), impose an obligation on all private and public sector entities to ensure the quality and accuracy of information they hold.15\\nOne potential solution is for the Office of the National Data Commissioner, as the national regulator for Australian Government data sharing, to provide advice and guidance on inter- agency data quality standards. This might include, for example, technical best practice for the collection, management and use of government data nationwide.\\nQ9. Given the importance of transparency across the AI lifecycle, please share your thoughts on:\\na. where and when transparency will be most critical and valuable to mitigate\\npotential AI risks and to improve public trust and confidence in AI.\\nb. mandating transparency requirements across the private and public\\nsectors, including how these requirements could be implemented.\\nTransparency by Design\\nWe recommend consideration of design methodologies that promote transparency at all stages of development. In particular, the Government should consider:\\na) mandating technical and organisational record-keeping across the AI lifecycle.\\nContemporary technical and interdisciplinary scholarship has developed a suite of\\nvaluable tools for recording and disclosing information at different stages of the AI\\n15\\nPrivacy Act 1988 (Cth), sch 2 s 10.\\n8\\nlifecycle. This includes data documentation and provenance methods,16 model\\nperformance cards,17 auditing processes and logging mechanisms.18 Organisational\\nrecord-keeping is equally as important. Documentation about impact assessments,\\nprocurement processes and broader organisational choices should also be publicly\\navailable for scrutiny.19\\nb) adopting inherently transparent and interpretable AI systems in high-stakes settings.\\nAI complexity is a significant impediment to meaningful transparency.20 Such\\ninscrutability is often a symptom of system design.21 The more sophisticated kinds of\\nmachine learning models are not always necessary to achieve organisational goals.\\nNor do more complex models necessarily lead to better predictive performance.22 It is\\noften possible to achieve good predictive performance with much simpler machine\\nlearning models.23 Accordingly, simpler and inherently transparent AI systems should\\nbe used in domains where automated outputs will have significant consequences for\\naffected individuals.\\nc) consider the merits of acceptance test driven development (\\u2018ATDD\\u2019) methodologies.\\nATTD approaches, such as the development of interdisciplinary \\u2018user stories\\u2019, can\\nclose the understanding gap between policy designers and developers of ADM\\nsystems, while also generating concise natural language documentation which can\\nconvey the intent of specific system operations. While ethical guidelines can be useful,\\n16\\nTimnit Gebru et al, \\u2018Datasheets for Datasets\\u2019 [2018] arXiv:1803.09010 [cs]\\n.\\n17\\nMargaret Mitchell et al, \\u2018Model Cards for Model Reporting\\u2019 (Conference Paper, Conference on Fairness,\\nAccountability, and Transparency, 2019) .\\n18\\nJoshua A Kroll, \\u2018Outlining Traceability: A Principle for Operationalizing Accountability in Computing\\nSystems\\u2019 (Conference Paper, Conference on Fairness, Accountability, and Transparency, 2021)\\n; Jatinder Singh, Jennifer Cobbe and Chris Norval,\\n\\u2018Decision Provenance: Harnessing Data Flow for Accountable Systems\\u2019 (2019) 7 IEEE Access 6562.\\n19\\nJennifer Cobbe, Michelle Seng Ah Lee and Jatinder Singh, \\u2018Reviewable Automated Decision-Making: A\\nFramework for Accountable Algorithmic Systems\\u2019 (Conference Paper, Conference on Fairness,\\nAccountability, and Transparency, 2021) .\\n20\\nJenna Burrell, \\u2018How the Machine \\u201cThinks\\u201d: Understanding Opacity in Machine Learning Algorithms\\u2019 3(1)\\nBig Data & Society 1, 4\\u20135.\\n21\\nJoshua A Kroll, \\u2018The Fallacy of Inscrutability\\u2019 (2018) 376(2133) Philosophical Transactions of the Royal\\nSociety of London 20180084.\\n22\\nCynthia Rudin, \\u2018Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use\\nInterpretable Models Instead\\u2019 (2019) 1(5) Nature Machine Intelligence 206.\\n23\\nIbid.\\n9\\nAI developers cannot always map principles to practical development.24\\na. Ethical User Stories25 have been proposed to increase alignment of ADM\\nsystems26 by outlining links between abstract ethical values and functional\\nrequirements.27 A preliminary study comparing the use of ECCOLA,28 a\\nmethodology for ethical user story construction, with standard user story\\napproaches, revealed that the former produced noticeably more \\u2018human-\\ncentric\\u2019 user stories, while standard user story methods generated significantly\\nmore \\u2018technology-centric\\u2019 user stories.29 The study further showed that, when\\ncompared to an independent user story evaluation model,30 the ECCOLA\\nmethod produced higher-scoring stories, indicating that even beyond ethical\\nconsiderations, there is value for developers and other stakeholders in\\nadoption of the method.31\\nb. Value sensitive design32 methodologies such as participatory design have\\nbeen increasingly explored to embed desired values into AI systems.33 These\\napproaches reduce the likelihood of marginalised groups being unfairly\\nimpacted.34 They have been used to shift the design of legal AI systems\\u2019 goals\\n24\\nVille Vakkuri et al, \\u2018ECCOLA \\u2014 A Method for Implementing Ethically Aligned AI Systems\\u2019 (2021) 182\\nJournal of Systems and Software 111067; Erika Halme et al, \\u2018How to Write Ethical User Stories? Impacts of the ECCOLA Method\\u2019 in Peggy Gregory et al (eds), Agile Processes in Software Engineering and Extreme\\nProgramming (Springer International Publishing, 2021) 37.\\n25\\nEthical user stories differ from standard user stories in that the former also considers non-functional user requirements: Erika Halme et al, \\u2018Ethical User Stories: Industrial Study\\u2019 in Joint Proceedings of REFSQ-2022\\nWorkshops, Doctoral Symposium, and Posters & Tools Track (CEUR-WS, 2022) 5.\\n26\\nIbid; Halme et al, \\u2018How to Write Ethical User Stories\\u2019 (n 24 above) 36.\\n27\\nQinghua Lu et al, \\u2018Towards a Roadmap on Software Engineering for Responsible AI\\u2019 in Proceedings of the\\n1st International Conference on AI Engineering: Software Engineering for AI (Association for Computing\\nMachinery, 2022) 101, 105 .\\n28\\nVakkuri et al (n 24 above).\\n29\\nHalme et al, \\u2018How to Write Ethical User Stories\\u2019 (n 24 above) 45-46, 49.\\n30\\nLuigi Buglione and Alain Abran, \\u2018Improving the User Story Agile Technique Using the INVEST Criteria\\u2019 in\\n2013 Joint Conference of the 23rd International Workshop on Software Measurement and the 8th\\nInternational Conference on Software Process and Product Measurement (2013) 49.\\n31\\nHalme et al, \\u2018How to Write Ethical User Stories\\u2019 (n 24 above) 46-47, 49-50.\\n32\\nBatya Friedman, \\u2018Value-Sensitive Design\\u2019 (1996) 3(6) Interactions 16.\\n33\\nSteven Umbrello, \\u2018Beneficial Artificial Intelligence Coordination by Means of a Value Sensitive Design\\nApproach\\u2019 (2019) 3(1) Big Data and Cognitive Computing 5.\\n34\\nSee, eg, Q Vera Liao and Michael Muller, \\u2018Enabling Value Sensitive AI Systems through Participatory\\nDesign Fictions\\u2019 (No arXiv:1912.07381, arXiv, 12 December 2019) .\\n10\\nand methods from computer scientists to legal experts, as well as decrease\\nthe knowledge gaps between such domain experts.35 Further, participatory\\ndesign has a history of being used in the development of expert systems to\\nreduce abstraction,36 thereby encouraging the development of decision-\\nmaking systems which can be understood with limited computational\\nproficiency. Participatory design can be used across various points of\\ndevelopment.37 Like ethical user story approaches, they generate artifacts\\nwhich are collaboratively constructed by computer scientists and domain\\nexperts alike.38 Accordingly, they can be used to audit and understand the\\ngoals and methods of ADM systems. In this way, the implementation of ethical\\nuser stories or participatory design methodologies generates transparency as\\na by-product, and therefore may be palatable to developers concerned about\\ninefficiencies and the costs of compliance with transparency mandates.\\nSafeguarding Transparency in the Government Use of AI\\nTransparency and explainability are critically important for all uses of AI, but they are especially crucial in the public sector where there is an expectation of higher standards of transparency and accountability. AI systems used in the public sector should be sufficiently transparent to permit public scrutiny and facilitate contestation where necessary. In line with open government and transparency ideals, we recommend introducing the following regulatory reform solutions aimed at tackling AI opacity barriers in the public sector:\\na) Reforming federal and state freedom of information legislation to ensure that\\nsufficient information about Government AI can be obtained by individual citizens,\\nmedia and civil society groups. Government refusal of some freedom of information\\n35\\nFernando Delgado, Solon Barocas and Karen Levy, \\u2018An Uncommon Task: Participatory Design in Legal\\nAI\\u2019 (2022) 6(CSCW1) Proceedings of the ACM on Human-Computer Interaction 51:1-51:23, 51:2, 51:5.\\n36\\nIbid 51:5.\\n37\\nDouglas Zytko et al, \\u2018Participatory Design of AI Systems: Opportunities and Challenges Across Diverse\\nUsers, Relationships, and Application Domains\\u2019 in Extended Abstracts of the 2022 CHI Conference on\\nHuman Factors in Computing Systems (Association for Computing Machinery, 2022) 1, 2\\n (\\u2018Participatory Design of AI Systems\\u2019).\\n38\\nJeanette Blomberg, Lucy Suchman and Randall H Trigg, \\u2018Reflections on a Work-Oriented Design Project\\u2019\\n(1996) 11(3) Human\\u2013Computer Interaction 237.\\n11\\nrequests was identified as a significant impediment to meaningful scrutiny of the\\nCentrelink online compliance intervention scheme.39\\nb) Establishing public sector procurement standards that prioritise transparency over\\ncommercial secrecy and outline what specific information administrative agencies are\\nrequired to collect and disclose about AI systems in use.40 These standards should\\nalso be used to facilitate openness in freedom of information requests when AI-\\nsystems are developed by, or in conjunction with, private contractors.\\nc) Instituting a proactive disclosure regime containing a public register of Government\\nAI systems in use, as well as public disclosure of technical documentation sufficient\\nto facilitate external scrutiny and individual contestation. Ideally, government\\nagencies should be required to make the source code of AI publicly available. We\\nrecognise, however, that source code transparency alone may be insufficient for\\nachieving meaning accountability and transparency in AI systems,41 particularly for\\nadversely affected individuals.42 Therefore, in addition to source code disclosure,\\ntechnical and organisational documentation of coding decisions should also be made\\npublicly available.\\nd) Modifications to the ADJR Act that explicitly require the provision of a statement of\\nreasons for all decisions made by, or in reliance on, an ADM system. Reasons are\\nessential for the contestation of automated administrative decisions. Affected\\npersons should be able to understand the rationality behind a decision and be given\\nenough information to contest it where necessary. However, we note that there is\\nsignificant doubt about the ability for fully automated AI systems to produce \\u2018legally\\n39\\nSee Ashlynne McGhee, \\u2018Centrelink Debt Recovery Program: Department Rejects FOI Requests Relating to Plagued Scheme\\u2019, ABC News (online, 10 February 2017) .\\n40\\nCatherine Holmes, Royal Commission into the Robodebt Scheme (Report, 2023) 656\\u2013657.\\n41\\nJoshua A Kroll et al, \\u2018Accountable Algorithms\\u2019 (2016) 165(3) University of Pennsylvania Law Review 633,\\n647\\u2013650.\\n42\\nSee, eg, Mike Ananny and Kate Crawford, \\u2018Seeing without Knowing: Limitations of the Transparency Ideal and Its Application to Algorithmic Accountability\\u2019 (2018) 20(3) New Media and Society 973; Deven R Desai and Joshua A Kroll, \\u2018Trust but Verify: A Guide to Algorithms and the Law\\u2019 (2017) 31(1) Harvard Journal of\\nLaw and Technology 1.\\n12\\ncompelling\\u2019 reasons for decisions.43 Technical explanations, including those\\nproduced by modern explainability tools, often fall short of providing the type of\\nreasons needed to facilitate understanding and contestation of an administrative\\ndecision. Reasons must go beyond the logic of how the decision was made and\\ninclude reasons as to why the decision was made.44 In circumstances where this is\\nnot possible, we suggest that ADM should not be used for government decision-\\nmaking purposes.\\n* About QUT\\u2019s Digital Media Research Centre\\nThe Digital Media Research Centre (\\u2018DMRC\\u2019) at the Queensland University of Technology is a leading research centre in digital humanities and social science research with a focus on digital communication, media, and the law. Our research programs investigate digital inclusion and participation, the digital transformation of media industries, the growing role of\\nAI and automation on digital societies and the role of social media in public communication.\\nScholars in the DMRC are undertaking important research on many of the concerns raised by the discussion paper. This includes ongoing work to investigate the development of regulatory regimes to address emerging risks for AI and ADM.\\n43\\nWill Bateman, \\u2018Algorithmic Decision-Making and Legality: Public Law Dimensions\\u2019 (2020) 94(1) Australian\\nLaw Journal 520, 527.\\n44\\nJennifer Cobbe, \\u2018Administrative Law and the Machines of Government: Judicial Review of Automated\\nPublic-Sector Decision-Making\\u2019 (2019) Legal Studies 1, 22.\\n13\",\n          \"\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\\n\\uf0b7\",\n          \"About us\\n1 This submission is made on behalf of the Australia New Zealand Screen Association (ANZSA).\\nThe ANZSA represents the film and television content and distribution industry in Australia and\\nNew Zealand. Its core mission is to advance the business and art of filmmaking, increasing its\\nenjoyment around the world and to support, protect and promote the safe and legal\\nconsumption of movie and TV content across all services. Members of ANZSA include: Village\\nRoadshow Limited; Motion Picture Association; Walt Disney Studios Motion Pictures; Netflix\\nInc.; Paramount Pictures; Sony Pictures Releasing International Corporation; Universal\\nInternational Films, Inc.; and Warner Bros. Pictures International, a division of Warner Bros.\\nEntertainment Inc., and Fetch TV.\\nGeneral comments\\n2 We thank the Government of Australia and the Department of Industry, Science and Resources\\nfor the opportunity to provide comments on the discussion paper titled Safe and responsible AI\\nin Australia (\\u201cthe discussion paper\\u201d). We welcome the Department\\u2019s forward-looking approach\\nin opening the consultation, and for the opportunity for interested parties like ANZSA and our\\nmembers to share our input. We encourage the Government to continue providing frequent and\\ntransparent opportunities for public input on the topic of artificial intelligence (\\u201cAI\\u201d)1 regulation,\\nso that interested stakeholders can continue providing feedback on this pressing and important\\nissue. We also urge the Government not to rush to regulate AI or to impose new and hasty\\nrules on the use of AI. Further development of regulation, if and when there is a demonstrated\\nneed to regulate, should be done in close consultation with all relevant stakeholders, including\\ninterested industry representatives.\\n3 We note the acknowledgement in the discussion paper that \\u201cthe range of contexts in which AI\\ncan be used, and for different purposes, may necessitate context-specific resources\\u201d, and that\\nthe consultation \\u201cdoes not seek to consolidate or replicate the development of existing general\\nor sector-specific regulations and governance initiatives across the Australian Government.\\u201d\\nAny broad new AI regulation with application across multiple sectors will also run the risk of\\noverlapping with existing regulation, causing regulatory uncertainty, which would create a\\nheavy compliance burden and disincentivize business investment.\\n4 Governments should consider carefully, and in consultation with relevant stakeholders and\\ninformed by an assessment of risk and potential for harm, the need for a regulatory framework\\nfor AI. If such a framework is found to be necessary, any obligations must be proportionate to\\nthe potential for harm. Any burdensome requirements will add another layer of compliance\\n1 We note that AI is a term used broadly but covers many technologies. Generative AI refers to a subset of artificial\\nintelligence that learns patterns from data and, when directed by a person through \\u201cprompting\\u201d, produces content based\\non those patterns. This contrasts with \\u201ctraditional AI\\u201d systems that are used to predict outcomes or generate insights.\\nburden on companies and could have major unintended consequences, including providing a\\nstrong disincentive to further investment for content creators. Broadly speaking, the creative\\nsector flourishes best in a context of light-touch regulation that encourages ease of doing\\nbusiness, both domestically and internationally.\\n5 In this regard, we support the Government\\u2019s consideration of a risk management approach that\\n\\u201ccaters to the context-specific risks of AI\\u201d and \\u201callows for less onerous obligations for lower risk\\nAI uses\\u201d. We note (in Box 4, page 32 of the discussion paper) that the Government considers\\nthe use of \\u201cAI-enabled recommendation engines to enable personalised online shopping\\nrecommendations based on users\\u2019 browsing history, preferences and interests\\u201d as a low-risk\\nuse case, with a \\u201climited, reversible or brief\\u201d impact that should allow for fewer or no obligations\\nfor its use.\\nAI can support human creativity\\n6 ANSZA member companies are already using or plan to use AI to support the creation and\\ndelivery of a wide range of works that bring benefits (both economic and cultural) to society.\\nRecent advances in AI technology, including the rise of generative AI tools like Midjourney and\\nDall-E, are leading to major and complex debates around the copyright implications of this\\ntechnology; and to intensifying pressure to regulate the use of AI, both in Australia and in other\\njurisdictions around the world. However, we note that notwithstanding these substantial\\ndevelopments, the AI field is still in a relatively nascent stage \\u2013 there are still further\\ndevelopments to come.\\n7 AI is an enabling tool that can complement aspects of filmmaking process, the audience\\nviewing experience, and fan engagement. We would note that the use of AI is not novel and\\nhas been employed as a tool in the production process, particularly in the context of special\\neffects. For example, \\u201ctraditional AI\\u201d has been used in a number of ways in production, such as\\nto predict resource usage, optimization of shooting schedules, and predicting complexity of\\nVFX shots. AI is also used in fairly routine post-production work like colour correction, detail\\nsharpening, de-blurring, or removing unwanted objects. Some are more involved, like aging\\nand de-aging an actor.\\n8 Across each of these examples, it is clear that AI use cases across the screen industry are\\ninherently low risk to consumers. They do not present the same level of harm as generating\\nmanipulated media for the purposes of misleading or deceiving a consumer. Instead, it is a\\nvaluable tool in the production process that is becoming increasingly important to present\\nvisually compelling experiences for audiences.\\n9 The rapid availability of generative AI has added additional layers of possibility as well as\\ncomplexity. Notably, we do not believe it will replace human creativity. Instead, ANZSA\\nmembers believe AI and generative AI will serve to free up humans from the most rote parts of\\ntheir work, allowing them to concentrate their limited time and effort on the most creative\\naspects.\\nDifferentiating the use of AI in curated VOD services versus user generated content\\nservices\\n10 Several ANZSA members operate, or are planning to operate, video-on-demand (VOD)\\nservices in Australia which offer large and diverse catalogues with human-curated and\\nprofessionally produced content. This human curation element is crucial; ANZSA\\u2019s members\\ncomply with existing regulation to ensure that viewers are appropriately informed about the\\ncontent they are about to watch, or which they allow their children to watch. These VOD\\nservices use various recommendation systems (some of which could be enhanced by AI) to\\nhelp viewers find content that most closely suits their interests. ANZSA submits that the use of\\nAI within this framework is inherently low risk.\\n11 This contrasts with user generated content services which do not curate their content offering\\nand as a result the risk of adverse outcomes by purely AI-driven recommendation processes is\\ngreater in this situation. ANZSA submits that regulation should recognise the differentiation\\nbetween VOD services and providers of user generated content in terms of content\\nresponsibility, consumer interest and creative-led freedom of expression, particularly with\\nrespect to public policy concerns about the potential use of AI in promoting misinformation and\\ndistributing harmful content via digital platforms.\\n12 The recommendation systems used in VOD services pose little or no risk of the type that\\nwarrant regulation. VOD services\\u2019 recommendation engines should therefore clearly be\\nconsidered very low-risk uses of AI, with few or no obligations imposed on their use.\\nAI and Copyright\\n13 ANZSA members, and the creative community more broadly, rely on strong and effective\\ncopyright legislation and policy to protect their production of and investment in creative content,\\nwhich is enjoyed around the world. Such copyright policy is of utmost importance to the creative\\ncommunity and requires considerable attention from the relevant experts, especially given the\\nhost of issues that AI has brought up in relation to intellectual property.\\n14 As the discussion paper notes, the Attorney-General\\u2019s Department (AGD) is already in the\\nprocess of organizing Ministerial Roundtables on copyright, including an upcoming one\\nscheduled for August 2023 on the implications of AI for copyright law. Given the sectoral\\nexpertise of the AGD, copyright policy should fall under its remit and the process coming out of\\nthe Ministerial Roundtables. ANZSA and its members are currently participating actively in the\\nMinisterial Roundtables.\\n15 This AI consultation led by the Department of Industry, Science and Resources should have a\\nbroader remit addressing other issues. Should a report be released following this consultation,\\nit should also note that copyright-related AI issues fall outside the Department\\u2019s purview and\\nwill be addressed by the AGD.\\n16 We thank the Department again for providing the opportunity to provide our comments on this\\nimportant topic. We are happy to meet to discuss these comments.\\nPaul Muller\\nCEO Australia New Zealand Screen Association\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transparency_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 190,\n        \"samples\": [\n          \"transparency of where and how AI technologies are being deployed. A\\nGovernment-led consumer labelling scheme, backed up by independent third-party product\\nvalidation, would enable end-users to more confidently use AI technologies, knowing steps have\\nbeen taken to reduce associated risks. We have seen similar schemes deployed for smart\\ndevices, which could be built on and learnt from. For higher-risk products, we believe that\\ncontinuous third-party product assurance should be mandated. This should take into account the\\ncontext in which AI is deployed, as well as the underlying risks in the technology itself. There\\nshould also be clear routes for redress where things go wrong, building on existing legislation.\\n\\u2022 Flexibility, agility and periodic regulatory and legislative reviews should be built in from the\\noutset to keep pace with technological and societal developments. This could include\\nrequirements for regulators to engage regularly with industry experts, drawing from a wide range\\nof backgrounds and generational perspectives.\\n\\u2022 In assuming a greater role in regulating the use of AI, regulators should be strengthened in\\ntheir powers, resources and capabilities.\\n\\u2022 There remains a significant shortage of the skills we need to develop AI frameworks, and assure\\nsystems\\u2019 safety, security and privacy. If Australia wants to be a global leader in AI, the\\nGovernment must focus investment on developing the skills needed to make its regime a\\nsuccess.\\n\\u2022 If the Government wants to ensure that Australian languages, religious outlooks, values and\\ncultural references are protected, while also minimising the risk of adopting biases seen\\nelsewhere in the world, steps must be taken to make Australian datasets more readily\\navailable for use in AI.\\n\\u2022 The drafting, approval and implementation of technical standards that underpin the\\nAustralia\\u2019s regulatory framework will be critical. We ask that a clear route map for the\\ndevelopment of technical standards is laid out, detailing where those standards are cross-sectoral\\nand where sector-specific standards are required (e.g. medical devices).\\nWe are pleased that the Government is taking the time to review its approach. We are keen to support its development by sharing our expertise and insights from operating at the \\u2018coalface\\u2019 of cyber security. Below we explore our recommendations in more detail, responding directly to the Discussion\\nPaper\\u2019s questions.\\n1\\nAbout NCC Group\\nNCC Group\\u2019s purpose is to create a more secure digital future. As experts in cyber security and risk\\nmanagement, our c.2,300 people worldwide are trusted by our customers to help protect their\\noperations from cyber threats. As a global business operating in 12 countries, we were delighted to\\nopen our regional headquarters in Sydney last year amid a rapidly growing footprint across\\nAustralia, with around 85 colleagues now based here.\\nEach year we dedicate thousands of days of internal research and development enabling us to stay\\nat the forefront of cyber security and ensuring we secure the rapidly evolving and complex\\ntechnological environment. We have many years\\u2019 experience researching artificial intelligence (AI),\\nlarge language models (LLMs) and machine learning (ML) to understand the risks and opportunities\\nthese technologies present. We have published whitepapers, blogs and guidance on everything\\nfrom security auditing of ML systems and the use of LLMs in security code reviews to security\\nvulnerabilities found in AI-based systems such as facial recognition technology and image\\nclassification.\\nPotential gaps in approaches\\n2. What potential risks from AI are not covered by Australia\\u2019s existing regulatory approaches?\\nDo you have suggestions for possible regulatory action to mitigate these risks?\\nMost AI-based products in use today are \\u2018black box\\u2019 appliances that are placed onto networks and configured to consume data, process it and output decisions without humans having much knowledge of what\\u2019s happening. This means understanding and explaining why an AI system reached a certain decision can be very difficult and could be used maliciously by some organisations to provide cover for why a decision has been reached. To enable effective governance, contestability and redress, we believe that any new regulatory framework should ensure that organisations are transparent about:\\n\\u2022 The algorithms they are using and the sources of their training data: There are two core\\ncomponents to AI-based applications: (1) the algorithms themselves and (2) the data they use. In\\nthe end, any application is only as good and fair as the algorithms used (i.e. the right questions\\nmust be asked) and the quality of data used to train it. Organisations should outline in general\\nterms how the AI makes decisions, what factors it takes into account and any biases it may have.\\nThis could be standardised through a labelling scheme.\\n\\u2022 The AI\\u2019s decision-making process: Explainability1 will be difficult to achieve for many AI-based\\nsystems. Indeed, there is an inevitable trade-off between the explainability of a system and its\\neffectiveness as an AI-based product. Nevertheless, organisations should be able to provide\\ninsights into how the AI system makes decisions. This might not mean exposing the intricacies of\\nthe algorithm, but rather explaining the type of data inputs the AI uses and the broad logic it\\nfollows. For example, a bank using AI for loan approvals could explain that the AI uses information\\nlike credit score, income and employment history to make its decision.\\n\\u2022 The processes in place to minimise risks, including human oversight: Even the highest\\nquality AI system, with well-designed algorithms and good training data, will, on occasion, deliver\\nunpredictable outcomes. We therefore believe that AI technologies should be deployed to\\nsupplement, rather than replace human decision-making. We also believe that, particularly where\\nexplainability is difficult to (proportionately) achieve and/or the output of an AI is likely to impact\\nhumans in a notable way, organisations must be clear about the processes in place to oversee\\nthe system\\u2019s outputs and minimise risk. Organisations should also explain how they continue to\\n1\\nThe extent to which it is possible for relevant parties to access, interpret and understand the decision-making processes of an\\nAI system.\\n2\\nmonitor the AI system's performance over time and how they make updates to the AI system to\\nensure its continued accuracy and fairness.\\n\\u2022 Performance metrics: Sharing metrics related to the performance and accuracy of the AI can be\\nbeneficial, particularly where end-users are not the developers of the system. For instance, an AI\\nhealth diagnostic tool could share its accuracy rate or the percentage of diagnoses that are later\\nconfirmed by human doctors.\\n\\u2022 Data handling: In alignment with existing data protection legislation, organisations should\\ndisclose what data the AI is using, how this data is being collected, processed and stored. It's also\\nimportant to communicate whether data is shared with third parties and how the user's privacy is\\nbeing protected.\\nThere is a danger that Australia adopts AI-based systems, particularly large language models (LLMs), that are linguistically, legally and culturally based on non-Australian datasets. This might mean that biases and views seen in other countries inform increasingly important AI systems that are operational in Australia. If the Government wants to ensure that Australian languages, religious outlooks, values and cultural references are protected, while also minimising the risk of adopting biases seen elsewhere in the world, steps must be taken to make Australian datasets more readily available for use in AI. There is a wealth of data already gathered by the Australian public sector; however, much of it is either not in a usable format or is protected by copyright and cannot be used commercially without payment of individual license fees (which might be prohibitively expensive to obtain for innovators). To overcome this issue, the Government should consider the benefits of:\\n\\u2022 An initiative to publish more copyright information under a Creative Commons \\u2018BY\\u2019 licence in the\\ninterests of innovation and protection of Australian culture and values; and/or,\\n\\u2022 Legislation to make all information published under the Commonwealth\\u2019s copyright available\\nunder a Creative Commons \\u2018BY\\u2019 licence (with some exceptions).\\nAs the Government\\u2019s discussion paper rightly highlights, the potential for bias in AI is a key risk.\\nRemoving or reducing inherent existing biases, while balancing data privacy needs and taking steps to ensure that social issues are not exacerbated, will be crucial. In our view, this is not sufficiently addressed through Australia\\u2019s current legal framework. Future regulatory intervention should encourage organisations to take the following steps:\\n\\u2022 Establishing clear processes and mechanisms through which applications can be carefully vetted\\nand their respective data supply chains sanitised, particularly where data originates from\\nuntrusted sources, such as the Internet and end-users.\\n\\u2022 Where proportionate to do so, updating and retraining applications with the latest available data.\\n\\u2022 Analysing datasets to ensure they are representative and appropriate for the jurisdiction in which\\nthey are used. This should take into account the diversity of the development team responsible for\\nsourcing the datasets, as this may result in unconscious biases. Creating synthetic data (i.e.\\ninformation that is artificially manufactured rather than generated by real-world events) that is\\nrepresentative could be a future solution to this, and should be a focus for R&D investment.\\n\\u2022 A multidisciplinary approach to reviewing the decision criteria used for automated decisions -\\nwhich offers a legal, policy and operational perspective in addition to a technical review \\u2013 should\\nbe taken to reduce bias wherever possible.\\n\\u2022 Responsibility for issues of bias shouldn\\u2019t end when products or systems have been released.\\nThere should be a clear reporting process that allows organisations to receive and act on\\ninformation about potential biases in a system. Lessons can be learnt from the security industry\\nwhere there are established protocols for disclosing vulnerabilities in a system.\\nIn our experience from operating within the world of cyber security, industry does not always learn from the lessons of others. Indeed, despite daily publicised data breaches, many organisations continue to make the same mistakes that eventually result in their own data breach or cyber incident. Incidents that could have been avoided by following industry best practice and learning from the mistakes of others. To avoid this happening with AI technologies, assurance and testing, backed\\n3\\nup by investment in R&D, will play an important role in ensuring organisations involved in the development and deployment of AI are taking the right steps and learning from the mistakes of the past. Such activities need to be undertaken on a continuous basis to ensure vulnerabilities are addressed and the latest threat landscape is understood and acted upon. In addition, where the risk profile necessitates, we believe independent continuous product validation should be mandated.\\nIn our experience, many claims made by AI product vendors, predominantly about products\\u2019 effectiveness in detecting threats, can be unproven or lack independent verification. Vendors should also be required to promote continuous mitigation throughout the product design, development, and post-market lifecycle, avoiding a \\u2018tick-box\\u2019 approach to compliance.\\nThe Government should consider how it might address the issue of AI alignment. AI alignment refers to the challenge of ensuring AI systems act in accordance with human values throughout their operational life. This is especially important as AI technologies become more autonomous and sophisticated, increasing the potential for their objectives to diverge from those of human operators or society at large. In order to facilitate this, we recommend that any regulatory intervention incorporates an explicit requirement for the disclosure of details about how an AI system has been trained for alignment with human values, as well as the measures in place to maintain this alignment as the system learns and evolves. Such a requirement could help build trust and facilitate external oversight of AI systems, while emphasising the responsibility of developers and operators to continually monitor their systems and correct any misalignment that arises. However, it should be noted that AI alignment is a complex problem, and our understanding of it continues to evolve. The practicalities of regulatory implementation should be carefully considered, and the requirements should be flexible enough to adapt as our understanding of AI alignment improves. Regular consultation with the AI research community, as well as industries using AI, would be crucial to ensuring the continued relevance and efficacy of these regulations.\\nIf new regulation is introduced, regulators will need to consider how they will retrospectively address the existing use of AI technologies in their sectors. Most organisations, often unknowingly, already use some form of AI (e.g. the technology used to blur or change backgrounds on video calls). How will these uses be regulated? Is investment in education required to drive up understanding of what constitutes AI, and why steps need to be taken to mitigate the associated risks?\\n3. Are there any further non-regulatory initiatives the Australian Government could implement to support responsible AI practices in Australia? Please describe these and their benefits or impacts.\\nWhile we note that data protection legislation does already exist, further legal clarity may be needed as to who owns, or has right of ownership over, the datasets that are used in AI systems. Many systems use web crawls to collate datasets available on the web, but not all publicly- available data is meant for public consumption. For example, confidential information may be intentionally or accidentally leaked on the internet. The Government should consider how scenarios where such data is (unintentionally) fed into AI systems are to be dealt with from a data privacy and legal standpoint.\\nA consumer labelling scheme, backed up by independent third-party product validation, would enable end-users to more confidently use AI technologies, knowing steps have been taken to reduce associated risks. Indeed, in our experience, many claims made by AI product vendors, predominantly about products\\u2019 effectiveness in detecting threats, can be unproven or lack independent verification.\\nThis scheme could be voluntary, replicating the cybersecurity labelling scheme for smart devices. For higher-risk products, we believe that third-party product validation should be mandated. This is in line with best practice we see in the world of cybersecurity, and will help to ensure a level playing field between those AI technology developers who are taking steps to mitigate risks and those who may not be.\\n4\\nThe Government must equip sectoral regulators with the resources and skills to effectively oversee the development and use of AI in their sectors. While some regulators are more advanced in their understanding of and ability to regulate AI, there remains a significant skills gap across authorities which will only widen as technologies and applications evolve. In addition to skills investment, a requirement should be established within all regulatory frameworks to regularly and systematically engage with the AI ecosystem to understand technological developments. This includes academics, incubators and accelerators, disruptors, and other innovation centres. This engagement could take a number of forms, including: secondment models; formal and informal government consultations and discussion papers; and regular sounding board mechanisms such as advisory groups and councils.\\n4. Do you have suggestions on coordination of AI governance across government? Please outline the goals that any coordination mechanisms could achieve and how they could influence the development and uptake of AI in Australia.\\nWhile we support a context-driven, flexible approach to regulating AI, there is a risk of reinventing the wheel when regulating cross-sectoral AI systems. In the same way that a significant proportion of organisations use Office 365, it\\u2019s likely that some AI systems will be widely adopted across the economy. In such cases, there should be a concerted effort to pool resources and coordinate regulatory responses \\u2013 otherwise there is a danger of regulatory overlap and/or conflict.\\nThere is a danger that, under a sector-based approach, some AI systems will not fit neatly within one regulator\\u2019s remit, and as such their regulation and oversight may fall through the net.\\nLessons could be learnt from the world of cyber security, where the sector may dictate what types of activities need to be undertake to improve resilience, but coordination is required across sectors to avoid fragmentation. The Government could explore establishing a central function to oversee the implementation of AI regulations. Part of the function\\u2019s remit could include regular assessments of the\\nAI landscape to ensure that there is sufficient regulatory oversight across AI applications. This responsibility may need to be established on a statutory footing to ensure effective implementation.\\nResponses suitable for Australia\\n5. Are there any governance measures being taken or considered by other countries (including any not discussed in this paper) that are relevant, adaptable and desirable for Australia?\\nWe note that the UK Government is looking to establish a central authority responsible for the general oversight of AI regulation. If the Australian Government is to pursue a sector/context-based approach, we would advise that it consider creating a similar function, giving it statutory powers to ensure the effective implementation of the Government\\u2019s regime. This should include ensuring regulators are working together and not duplicating efforts, and that there are no areas of AI that are falling through the gaps.\\nWe are pleased to see the Government emphasise the importance of international regulatory cooperation. In aligning Australia\\u2019s domestic and international approach, we recommend that the\\nGovernment:\\n\\u2022 Utilises existing successful partnerships, including the \\u2018Five Eyes\\u2019 alliance and with the European\\nUnion;\\n\\u2022 Invests time in developing practical outcomes with other governments, that go deeper than high-\\nlevel principles; and,\\n\\u2022 Ensures that civil society and industry \\u2013 who will play a central role in delivering governments\\u2019\\nobjectives - are involved in discussions from the outset.\\n5\\nTarget areas\\n6. Should different approaches apply to public and private sector use of AI technologies? If so, how should the approaches differ?\\nWhile we do not have a strong view, we would emphasise that any approach, particularly one that is risk-based, should be consistently applied across the public sector, private sector and academia.\\n7. How can the Australian Government further support responsible AI practices in its own agencies?\\nOne area that will require attention is skills. As outlined elsewhere in this response, there is a lack of the technical skills required to develop and use safe and secure AI. In addition to skills investment, the\\nGovernment might also consider where external expertise might be needed.\\n 9. Given the importance of  transparency across the AI lifecycle, please share your thoughts on: a. where and when  transparency will be most critical and valuable to  mitigate potential AI risks and to improve  public trust and confidence in AI?\\nAs highlighted above, we believe that any new regulatory framework should ensure that organisations are transparent about:\\n\\u2022 The algorithms they are using and the sources of their training data: There are two core\\ncomponents to AI-based applications: (1) the algorithms themselves and (2) the data they use. In\\nthe end, any application is only as good and fair as the algorithms used (i.e. the right questions\\nmust be asked) and the quality of data used to train it. Organisations should outline in general\\nterms how the AI makes decisions, what factors it takes into account and any biases it may have.\\nThis could be standardised through a labelling scheme.\\n\\u2022 The AI\\u2019s decision-making process: Explainability2 will be difficult to achieve for many AI-based\\nsystems. Indeed, there is an inevitable trade-off between the explainability of a system and its\\neffectiveness as an AI-based product. Nevertheless, organisations should be able to provide\\ninsights into how the AI system makes decisions. This might not mean exposing the intricacies of\\nthe algorithm, but rather explaining the type of data inputs the AI uses and the broad logic it\\nfollows. For example, a bank using AI for loan approvals could explain that the AI uses information\\nlike credit score, income and employment history to make its decision.\\n\\u2022 The processes in place to minimise risks, including human oversight: Even the highest\\nquality AI system, with well-designed algorithms and good training data, will, on occasion, deliver\\nunpredictable outcomes. We therefore believe that AI technologies should be deployed to\\nsupplement, rather than replace human decision-making. We also believe that, particularly where\\nexplainability is difficult to (proportionately) achieve and/or the output of an AI is likely to impact\\nhumans in a notable way, organisations must be clear about the processes in place to oversee\\nthe system\\u2019s outputs and minimise risk. Organisations should also explain how they continue to\\nmonitor the AI system's performance over time and how they make updates to the AI system to\\nensure its continued accuracy and fairness.\\n\\u2022 Performance metrics: Sharing metrics related to the performance and accuracy of the AI can be\\nbeneficial, particularly where end-users are not the developers of the system. For instance, an AI\\nhealth diagnostic tool could share its accuracy rate or the percentage of diagnoses that are later\\nconfirmed by human doctors.\\n2\\nThe extent to which it is possible for relevant parties to access, interpret and understand the decision-making processes of an\\nAI system.\\n6\\n\\u2022 Data handling: In alignment with existing data protection legislation, organisations should\\ndisclose what data the AI is using, how this data is being collected, processed and stored. It's also\\nimportant to communicate whether data is shared with third parties and how the user's privacy is\\nbeing protected. b.  mandating transparency requirements across the private and public sectors, including how these requirements could be implemented.\\nWe support  mandating transparency requirements. End-users and consumers should be empowered to make decisions about the AI systems they use, and this can only be achieved by improving  transparency of where and how AI technologies are being deployed.\\n10. Do you have suggestions for: a. Whether any high-risk AI applications or technologies should be banned completely? b. Criteria or requirements to identify AI applications or technologies that should be banned, and in which contexts?\\nWe would caution against the outright banning of AI applications or technologies, as this could risk stifling innovation in Australia, leaving it behind its global counterparts. Instead, we would propose that very high-risk applications or technologies could be tested and explored within limited testbeds, and under the close supervision of an independent watchdog that ensures the Government\\u2019s AI Ethics\\nPrinciples are not breached.\\n11. What initiatives or government action can increase public trust in AI deployment to encourage more people to use AI?\\nA consumer labelling scheme, backed up by independent third-party product validation, would enable end-users to more confidently use AI technologies, knowing steps have been taken to reduce associated risks. Indeed, in our experience, many claims made by AI product vendors, predominantly about products\\u2019 effectiveness in detecting threats, can be unproven or lack independent verification.\\nThis scheme could be voluntary, replicating the cybersecurity labelling scheme for smart devices. For higher-risk products, we believe that third-party product validation should be mandated. This is in line with best practice we see in the world of cybersecurity, and will help to ensure a level playing field between those AI technology developers who are taking steps to mitigate risks and those who may not be.\\nImplications and infrastructure\\n12. How would banning high-risk activities (like social scoring or facial recognition technology in certain circumstances) impact Australia\\u2019s tech sector and our trade and exports with other countries?\\nWe would caution against the outright banning of AI applications or technologies, as this could risk stifling innovation in Australia, leaving it behind its global counterparts. Instead, we would propose that very high-risk applications or technologies could be tested and explored within limited testbeds, and under the close supervision of an independent watchdog that ensures the Government\\u2019s AI Ethics\\nPrinciples are not breached.\\n13. What changes (if any) to Australian conformity infrastructure might be required to support assurance processes to mitigate against potential AI risks?\\nWe agree that assurance has a core role to play in driving up safety, privacy and security standards. However, there remains a distinct lack of people in the AI assurance sector with the\\n7\\nexperience and/or qualifications to undertake assessments, particularly assessments of cyber security risks that are unique to AI systems. We believe that Government should consider how post-16 education can be more appropriately geared toward developing educational programmes that bridge\\nAI and related disciplines such as cyber security.\\nRisk-based approaches\\n14. Do you support a risk-based approach for addressing potential AI risks? If not, is there a better approach? 15. What do you see as the main benefits or limitations of a risk-based approach? How can any limitations be overcome?\\nWe broadly support a risk-based approach to addressing potential AI risks. However, in implementing such an approach, the Government should ensure innovation is not stifled and maintain a level of flexibility and agility to future-proof against the fast-changing technological landscape. This can be done by:\\n\\u2022 Clearly defining Australia\\u2019s risk appetite. AI will never be zero risk if we wish to pioneer its\\ndevelopment and, crucially, its deployment. As such, Australia should define its risk appetite so\\nthat red lines with regards to AI systems and their security, safety and resilience are known.\\n\\u2022 Establishing periodic regulatory and legislative reviews from the outset to keep pace with\\ntechnological and societal developments. This could include requirements for regulators and the\\nproposed new central Government function to engage regularly with innovation centres and\\nindustry experts, drawing from a wide range of backgrounds and generational perspectives.\\n\\u2022 Investing in horizon-scanning activities. There is already a myriad of horizon scanning activity\\nand initiatives across government, the private sector and academia. This can lead to overlap and\\nduplication of effort, with no central coordination and collation of data. We therefore propose that\\nthe Government invest in coordinating and improving existing horizon-scanning activities, rather\\nthan reinventing the wheel.\\n17. What elements should be in a risk-based approach for addressing potential AI risks? Do you support the elements presented in Attachment C?\\nBroadly speaking, we support the elements outlined in Attachment C. We would add that independent third-party product validation should be mandated for high-risk systems, with other systems encouraged to adopt a consumer labelling scheme.\\nAs outlined in detail under question 2 above, there are a number of steps that organisations can take to improve the  transparency and explainability of their AI systems. These should be embedded in a risk-based approach, with levels of  transparency and explainability increasing for higher risk systems.\\nWe agree that training should increase proportionate to the level of risk. This, however, should be backed up with investment in the key skills needed to meet the Government\\u2019s aims. In particular, focused investment is required to ensure genuine Australian leadership in AI which we would define as producing core AI frameworks, as opposed to using AI frameworks developed by others. While there are many AI frameworks available for use that abstract away from the low-level minutiae/mathematics of AI, there is likely a major skills shortage of people with deep technical understanding of AI and its algorithms. There is therefore a danger that, as a nation, Australia will be using AI frameworks developed by other nations, reliant on the assurances that they provide regarding the security, safety and biases of those frameworks. We strongly believe that this is a much less desirable outcome to being in a position where Australia is the producer of the core AI frameworks (that others might then use).\\n8\\n20. Should a risk-based approach for responsible AI be a voluntary or self-regulation tool or be mandated through regulation?\\nWhere the risk profile dictates, we do believe that mandatory safety, security and privacy requirements will be needed. While advice, guidance and voluntary measures have a key role to play, well-crafted regulation provides industry with clarity, establishes a level playing field amongst developers and usually comes with the resources and powers regulators need to govern effectively. In particular, high-risk systems should be subject to mandatory independent third-party product validation.\\nThe drafting, approval and implementation of technical standards that underpin any regulatory framework will be critical. We know that Australia is already taking steps to be at the forefront of developing world-leading AI standards, and this is something we firmly support. We ask that a clear route map for the development of technical standards is laid out, detailing where those standards are cross-sectoral and where sector-specific standards are required (e.g. medical devices).\\nAnd should it apply to: a. public or private organisations or both? b. developers or deployers or both?\\nIt should be applied consistently across the public sector, private sector and academia, with both developers and deployers required to take steps to mitigate against the potential risks.\\nWe, however, believe that further work is required to work through edge cases and determine how legal responsibility will be defined. Other jurisdictions, such as the EU, have set out firmer views on the liability of AI systems. While we do not offer a view on whether this is the right approach, we would highlight that in the absence of a defined Australian system of legal liability, other jurisdictions\\u2019 frameworks will likely be adopted.\\n9\",\n          \"transparency, and\\naccountability are critical to the delivery of safe, properly informed decision making.\\nThe ASA is concerned that technology is progressing faster than law makers can determine\\ndefinitions and set appropriate boundaries for safe implementation of AI technology.\\nConsideration should be given to differentiating between AI and artificial assistance and clarifying\\nthis with the public. In the case of ultrasound, the embedded software in ultrasound equipment is\\nnot currently learning, it is referring to existing examples/databases, and providing information back\\nto the sonographers using the equipment. This is artificial assistance, not artificial intelligence.\\nQuestion 2. What potential risks from AI are not covered by Australia\\u2019s existing regulatory approaches? Do you have suggestions for possible regulatory action to mitigate these risks?\\nASA response:\\nProgramming databases should be transparent to ensure that all cross-cultural backgrounds,\\nincluding indigenous backgrounds, are included.\\nThe ASA also wishes to highlight the importance of ensuring appropriate protections for patients \\u2013\\nespecially vulnerable people - in clinical circumstances where AI is in use. Caution should also be\\nexercised to ensure that AI is not operating in a discriminatory manner: indeed, recent literature has\\nshown that the use of AI in healthcare settings has exhibited signs of discrimination, and that AI is\\nnot exempt from various forms of bias. 1\\nQuestion 3. Are there any further non-regulatory initiatives the Australian Government could implement to support responsible AI practices in Australia? Please describe these and their benefits or impacts.\\nASA response:\\nIn the case of diagnostic imaging, patients should be made aware in cases where their imaging\\nhas been assessed by AI. This information should include risk factors of using AI, including the\\nconfidence ratings, and whether a second reading by a healthcare professional on or off-site has\\noccurred.\\n1\\nKarimian, G., Petelos, E. & Evers, S.M.A.A. The ethical issues of the application of artificial intelligence in healthcare: a systematic scoping review. AI Ethics 2, 539\\u2013551 (2022). https://doi.org/10.1007/s43681-021-\\n00131-7\\n2\\nQuestion 10. Do you have suggestions for: a. Whether any high-risk AI applications or technologies should be banned completely?\\nb. Criteria or requirements to identify AI applications or technologies that should be banned, and in which contexts?\\nASA response:\\nAs per the EU Artificial Intelligence Act \\u2013 AI that poses an unacceptable risk should be banned\\ncompletely. Those that pose an unacceptable risk include AI that is considered a clear threat to\\npeople's safety, livelihoods and rights. This could be inclusive of systems that deploy harmful\\nmanipulative subliminal techniques, exploit specific vulnerable groups (physical or mental\\ndisability), used by public authorities, or on their behalf, for social scoring purposes and remote\\nbiometric identification systems in publicly accessible spaces for law enforcement purposes,\\nexcept in a limited number of cases. 2\\nQuestion 11. What initiatives or government action can increase public trust in AI deployment to encourage more people to use AI?\\nASA response:\\nPublic  transparency in the use of AI.\\nQuestion 15. What do you see as the main benefits or limitations of a risk-based approach?\\nHow can any limitations be overcome?\\nASA response:\\nOne limitation with a risk-based approach is that it will be difficult to account for all applications of\\nAI. The possibilities are endless. Box 4 makes no mention of radiomics and computer-aided\\ndiagnosis and detection, and the use of synthetic data training. This begs the question: what other\\napplications have been overlooked? The risks associated with the wholesale application of AI\\ncould potentially be systemic and irreversible.\\nQuestion 20. Should a risk-based approach for responsible AI be a voluntary or self-regulation tool or be mandated through regulation? And should it apply to: a. public or private organisations or both?\\nb. developers or deployers or both?\\nASA response:\\nA risk-based approach for responsible AI should be mandated through regulation in healthcare\\nsettings. Whilst this may not be necessary for all industries, any technology that could cause\\nserious harm or have significant bias against an unknowing individual should be regulated. There\\nare already major discrepancies in healthcare outcomes based on race, gender, residential\\nlocation (e.g., rural vs. metropolitan) and socioeconomic status. Recent research has found that AI\\ncould potentially contribute to healthcare inequalities. 3 Regulation needs to ensure that vulnerable\\nindividuals in Australia will be protected through mandated, responsible AI practices.\\n2\\nSee https://artificialintelligenceact.eu/the-act/\\n3\\nMurphy, K., Di Ruggiero, E., Upshur, R. et al. Artificial intelligence for good health: a scoping review of the ethics literature. BMC Med Ethics 22, 14 (2021). https://doi.org/10.1186/s12910-021-00577-8\\n3\",\n          \"transparency, context of its use. This assessment helps population and the likelihood of adverse explainability, fairness, accountability, identify the level and nature of risks outcomes. safety and security.\\ninvolved.\\n04 05\\nCompliance and Continuous Monitoring and\\nOversight Adaptation\\nOrganisations and individuals developing Implement continuous monitoring and or deploying AI systems are required to evaluation of AI systems and their impact.\\ncomply with the applicable regulatory As technology evolves and new risks requirements based on the risk class of emerge, regulatory frameworks need to their systems. Regulation may include be adaptable and updated to effectively audits, inspections, or other oversight address those risks.\\nactivities to ensure compliance, detect non-compliance and take appropriate enforcement actions if needed.\\n07\\nSafe and responsible AI\\nThe higher the risk, the stricter the rule. Horizontal application of AI regulation does guidelines that govern the development\\nRisk-based AI regulation recognises that not replace existing legislation. Rather this and use of AI technologies, monitoring rules and compliance procedures for AI approach seeks to harmonise with existing and application of sanctions to enforce applications that do not present genuine Australian general regulation (e.g., data compliance with the established risks can result in higher costs and protection and privacy, consumer law, regulations and guidelines, development burdens, without providing real benefits, online safety, copyright law etc) and sector- of certification or accreditation programs therefore regulatory obligation should specific regulation (e.g., therapeutic goods to verify compliance with established be proportional to risk. AI developers and financial services). The intent is to standards, and providing an avenue for and users should be, for example, free close the gap between existing Australian consumer complaints and users to seek to experiment with new technologies in regulation and the emerging risk that AI review of a decision made by AI systems.\\nsandbox environments and release low- systems pose. Given the global nature of AI, the risk applications. Innovation in high-risk AI Global compatibility oversight body should actively engage in systems, such as those deployed in critical Horizontal application of risk-based international collaboration opportunities. It infrastructure or that impact employment regulation is consistent with the European should work with international regulators, and education opportunities, can also be Union (EA) AI Act which is the forerunner share best practices and contribute to the supported by safeguards and appropriate in global AI regulation and emerging as the development of international standards levels of governance and control. dominant approach among comparable and norms to ensure consistency and\\nHorizontal application jurisdictions. Australian implementation of interoperability across borders.\\nA risk-based regulatory framework a compatible regulatory framework could The body's effectiveness would rely on should be implemented consistently and help facilitate cross border collaboration its ability to strike a balance between coherently across sectors, organisation size on AI development through shared supporting innovation and protecting the and AI maturity to govern the development, standards and global management of rights, safety and welfare of individuals and deployment and use of AI systems. This challenges associated with AI. Jurisdictional society and environment.\\n\\u2018horizontal\\u2019 application of AI regulation can compatibility also reduces regulatory help establish a cohesive and nationally complexities for organisations operating consistent regulatory framework for AI in multiple countries, enabling smoother systems, across the public and private cross-border AI deployments and reducing sectors. By addressing common challenges, the risk of actors gaming jurisdictional setting universal standards and promoting regulation.\\ncollaboration, it facilitates a level playing Regulatory oversight field for the regulatory expectations and An oversight body should be established obligations of AI actors. to implement and administer a regulatory\\nA consistent and coherent approach framework for safe and responsible AI, can also enhance consumer trust and ensuring consistency across federal and confidence. Consumers are more easily state levels. The specific structure, powers able to understand their rights and and processes of an AI oversight body develop confidence in their own ability would depend on the legal and regulatory to balance risk and benefit offered by AI framework to be implemented.\\nsystems through consistent standards and Depending on the framework, the role safeguards. This trust is essential for the of an AI oversight body might include widespread adoption of AI technologies developing policies, regulations and and the realisation of their benefits.\\n08\\nSafe and responsible AI\\n09\\nSafe and responsible AI\\nDefinition of AI\\nThe Australian definition of AI must be Deloitte recommends that the Australian developed in context of the regulatory definition of AI: approach by which it is to be governed.\\nThat is, if it were to be subject to narrow, rules-based regulation of specific\\n01 technologies, AI should be defined Replaces \\u2018engineered\\u2019 with precisely and explicitly. If, as recommended \\u2018computer-based\\u2019 to narrow the breadth of in this submission, it is to be regulated potential system inclusion to information according to the level of risk posed to processing systems only.\\nindividuals, society and the environment, the definition should be general and encompas all AI systems that have the\\n02 potential for negative outcomes. Excludes \\u2018without explicit programming\\u2019\\nto expand the definition to include\\nThe definition of AI proposed in the\\nautomated systems based on coded discussion paper is largely aligned to\\nlogic statements. This inclusive approach definitions proposed by the EU AI Act4\\nis aligned to the dominant emerging and OECD AI Principles5, with the critical\\ndefinition of AI across comparable distinction of stipulating that output\\njurisdictions and international policy must be generated without explicit\\norganisations6.\\nprogramming:\\n\\\"Artificial Intelligence\\\" refers to an engineered system that generates predictive outputs such 03 as content, forecasts, recommendations or Excludes \\u2018human-defined\\u2019 to be flexible decisions for a given set of human-defined to future post-generative AI systems.\\nobjectives or parameters without explicit Generative AI has brought us closer to programming. AI systems are designed to general AI which has the potential to operate with varying levels of automation. develop parameters and to create and\\nUnlike our international counterparts, pursue objective options that are not this definition restricts AI to machine explicitly defined by humans.\\nlearning \\u2013 and therefore with this definition,\\nAustralian AI regulation would only apply to machine learning systems and not the broader category of automated decision systems that have the potential to pose risk.\\n4\\nPlease refer to European Commission (2021).\\n5\\nPlease refer to Organisation for Economic Co-operation and Development (2019).\\n6\\nPlease refer to European Commission (2021), Organisation for Economic Co-operation and Development (2019), Information Commissioner\\u2019s Office (2022).\\n10\\nSafe and responsible AI\\n\\\"Artificial Intelligence\\\" refers to a computer-based system that can, for a given set of objectives, generate outputs such as content, predictions, recommendations, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy.\\n11\\nSafe and responsible AI\\n12\\nSafe and responsible AI\\nAI code of practice\\nThe design and operationalisation of in unfair discrimination against individuals, nuanced and effective AI regulation communities or groups.\\nwill take time. In the interim, Deloitte Privacy protection and security recommends that Australia develops\\nAI systems should respect and uphold an AI code of practice outlining a set of\\nprivacy rights and data protection, and guidelines, principles, and standards\\nensure the security of data.\\nthat can be used to govern the AI system lifecycle. Reliability and safety\\nAn AI code of practice should start from AI systems should reliably operate in the foundational position that AI is a accordance with their intended purpose.\\nsocio-technical system that must be  Transparency and explainability lawful, ethical and technically robust. This There should be  transparency and approach emphasises that it is the dynamic responsible disclosure so people human-machine interaction that creates can understand when they are being the potential for risk and this risk should significantly impacted by AI and, can find be managed across people, process and out when an AI system is engaging with technology. A key finding of the Deloitte them.\\nState of AI in Enterprises report7 was to\\nContestability ensure ethical and quality application of AI \\u2013 the entire operating model may When an AI system significantly impacts a need to change to accommodate the person, community, group or environment, unique capabilities of intelligent machines. there should be a timely process to allow\\nWorkflows and roles should be re- people to challenge the use or outcomes of evaluated to manage risk and achieve new the AI system.\\nvalue. Accountability\\nDesign of an AI code of practice should People responsible for the different draw from existing approaches to AI risk phases of the AI system lifecycle should management and governance and align be identifiable and accountable for the to the emerging global principles on outcomes of the AI systems and human responsible AI, for example those outlined oversight of AI systems should be enabled.\\nin Australia's AI Ethics principles8:\\nHuman, societal and environmental Features of an AI code of practice should wellbeing support safe and responsible AI across\\nAI systems should benefit individuals, the design, development, deployment society and the environment. and monitoring phases of AI. The AI code\\nHuman-centred values of practice should be flexible enough\\nto evolve with future technologies and\\nAI systems should respect human rights,\\nintegrate with different possible regulatory diversity, and the autonomy of individuals.\\nframeworks.\\nFairness\\nAI systems should be inclusive and accessible and should not involve or result\\n7\\nPlease refer to Deloitte (2022d).\\n8\\nPlease refer to Department of Industry, Science and Resources(2019).\\n13\\nSafe and responsible AI\\nResources\\nDeloitte. 2022a. Trustworthy Artificial Intelligence. Refer to: https://www.deloitte.com/au/en/Industries/consumer/ analysis/trustworthy-artificial-intelligence. Last accessed: 21/07/2023\\nDeloitte. 2022b. The Implications of Generative AI for Businesses. Refer to: https://www2.deloitte.com/us/en/pages/ consulting/articles/generative-artificial-intelligence.html. Last accessed: 21/07/2023\\nDeloitte. 2022c. The AI Dossier. Refer to: https://www.deloitte.com/au/en/services/consulting/perspectives/artificial- intelligence-dossier.html. Last accessed 21/07/2023\\nDeloitte. 2022d. State of AI in Enterprises 2022. Refer to: https://www2.deloitte.com/us/en/pages/consulting/articles/ state-of-ai-2022.html. Last accessed: 21/07/2023\\nDeloitte. 2023. 2023 \\u2013 2030 Australian Cyber Security Strategy. Refer to: https://www.deloitte.com/au/en/services/risk- advisory/perspectives/2023-2030-australian-cyber-security-strategy-deloitte-austra.html. Last accessed: 21/07/2023\\nOrganisation for Economic Co-operation and Development. 201\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create another df where the filename includes one of the following words: Australian Federal Police, UNSW.ai, Woolworths Group, IBM, KPMG, Meta, Department of Health and Aged Care, Canva, Microsoft\n",
        "\n",
        "keywords = [\"Australian Federal Police\", \"UNSW.ai\", \"Woolworths Group\", \"IBM\", \"KPMG\", \"Meta\", \"Department of Health and Aged Care\", \"Canva\", \"Microsoft\"]\n",
        "\n",
        "# Assuming 'df' is already loaded as in the previous code snippet\n",
        "df_filtered = df[df['filename'].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "\n",
        "df_filtered\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "zwgw4aLYVDUz",
        "outputId": "69e09a28-bd63-481e-8a85-83966bb0a7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   filename  \\\n",
              "0             Australian Federal Police.txt   \n",
              "4    Department of Health and Aged Care.txt   \n",
              "21                     Woolworths Group.txt   \n",
              "28                                 Meta.txt   \n",
              "77                            Microsoft.txt   \n",
              "85                       KPMG Australia.txt   \n",
              "122                   UNSW AI Institute.txt   \n",
              "154                       IBM Australia.txt   \n",
              "\n",
              "                                               content  \\\n",
              "0    21 August 2023\\nAustralian Federal\\nPolice sub...   \n",
              "4    Department of Health and Aged Care\\nSafe and R...   \n",
              "21   11 August 2023\\nVia email: DigitalEconomy@indu...   \n",
              "28   Meta’s Submission on\\nSafe & Responsible AI in...   \n",
              "77   Microsoft submission on Safe and Responsible A...   \n",
              "85   Safe and responsible AI in\\nAustralia\\nKPMG su...   \n",
              "122  UNSW AI Institute\\nai.director@unsw.edu.au\\n25...   \n",
              "154  Consultation Team\\nSafe and Responsible AI in ...   \n",
              "\n",
              "                                     transparency_text  \n",
              "0    transparency, accountability, fairness, privac...  \n",
              "4    transparency of AI in the delivery of health c...  \n",
              "21   transparency of outputs, data ethics, privacy ...  \n",
              "28   transparency, openness and responsible innovat...  \n",
              "77   transparency-led approach and addressing known...  \n",
              "85   transparency and explainability, contestabilit...  \n",
              "122  Transparency\\nAI will not be deployed responsi...  \n",
              "154  transparency that make clear the role of AI is...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d142292-cc07-4284-95a6-aabac116cada\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>content</th>\n",
              "      <th>transparency_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>21 August 2023\\nAustralian Federal\\nPolice sub...</td>\n",
              "      <td>transparency, accountability, fairness, privac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Department of Health and Aged Care.txt</td>\n",
              "      <td>Department of Health and Aged Care\\nSafe and R...</td>\n",
              "      <td>transparency of AI in the delivery of health c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Woolworths Group.txt</td>\n",
              "      <td>11 August 2023\\nVia email: DigitalEconomy@indu...</td>\n",
              "      <td>transparency of outputs, data ethics, privacy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Meta.txt</td>\n",
              "      <td>Meta’s Submission on\\nSafe &amp; Responsible AI in...</td>\n",
              "      <td>transparency, openness and responsible innovat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Microsoft.txt</td>\n",
              "      <td>Microsoft submission on Safe and Responsible A...</td>\n",
              "      <td>transparency-led approach and addressing known...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>KPMG Australia.txt</td>\n",
              "      <td>Safe and responsible AI in\\nAustralia\\nKPMG su...</td>\n",
              "      <td>transparency and explainability, contestabilit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>UNSW AI Institute.txt</td>\n",
              "      <td>UNSW AI Institute\\nai.director@unsw.edu.au\\n25...</td>\n",
              "      <td>Transparency\\nAI will not be deployed responsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>IBM Australia.txt</td>\n",
              "      <td>Consultation Team\\nSafe and Responsible AI in ...</td>\n",
              "      <td>transparency that make clear the role of AI is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d142292-cc07-4284-95a6-aabac116cada')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d142292-cc07-4284-95a6-aabac116cada button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d142292-cc07-4284-95a6-aabac116cada');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1a2eb67-b3f2-4ced-9ec4-59c8cfc46ca9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1a2eb67-b3f2-4ced-9ec4-59c8cfc46ca9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1a2eb67-b3f2-4ced-9ec4-59c8cfc46ca9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e2ca63a9-aa07-481d-be25-912e144edfce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_filtered')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e2ca63a9-aa07-481d-be25-912e144edfce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_filtered');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered",
              "summary": "{\n  \"name\": \"df_filtered\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Department of Health and Aged Care.txt\",\n          \"KPMG Australia.txt\",\n          \"Australian Federal Police.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Department of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nPreamble\\nThe Department of Health and Aged Care (the Department) welcomes the discussion paper released by the Department of Industry, Science and Resources (DISR) on Safe and Responsible AI in Australia, and provides the following submission:\\nArtificial Intelligence (AI) is an emerging capability that has the potential to transform wide areas of the economy and improve lives. It is expected to have significant impacts in the healthcare sector.\\nAI is advancing quickly and will likely generate disruptive innovation across many parts of society which has witnessed significant advancements and applications of AI in recent years. AI experts, journalists, policy makers and the public are increasingly discussing a broad spectrum of important and urgent risks from AI. The Centre for AI Safety recently called for global coordination to mitigate these risksi and the\\nDigital Health Cooperative Research Centre having recently developed a comprehensive ethical framework for the responsible design, development, and use of generative AI technology in health and medicineii. Any future regulation will need to balance the need to ensure patient safety and the need to maintain the security of protective sensitive health information and community trust with the health and economic benefits that may be realised from AI innovation.\\nThe Department supports the development and implementation of policies and governance that promote safe and responsible AI in Australia. As healthcare delivery occurs at different levels of government, a national approach to AI governance, which includes sector-specific governance of AI in healthcare, is desirable to ensure alignment in policy and legislative development, clinical safety, and public health delivery prioritisation. The success of AI in healthcare will depend on national leadership to maintain trust and ensure these systems are safe, reliable, and understandable in how they work.\\nThe responsible adoption of AI in government entails developing comprehensive policies, fostering trust and partnerships, and implementing strategies that communicate the benefits and regulate the use of\\nAI effectively in various sectors. The Department would like to see a well-informed, ethical, and comprehensive approach to AI integration in the health sector. By understanding and managing risks, fostering inclusivity, and ensuring accountability. The responsible utilisation of AI technologies can contribute significantly to advancing healthcare and aged care services in Australia. This would be complemented by further education and training in relation to AI for the health workforce, policy makers, and the broader Australian public.\\nAustralians have high expectations of the Department in the handling of sensitive information, including defining what data can be shared, with whom, and under what circumstances. Given this role in data sharing, the Department advocates for regulatory reforms and integration of AI-specific regulations within existing Acts. This would provide an avenue to harness the benefits of AI, while effectively managing its risks and protecting the integrity of healthcare information.\\nThe Department also has a key role in providing equitable access to health interventions and services through programs such as Medicare and supporting the national health system in collaboration with states and territories. With a focus on keeping Australians healthy and safe, we recommend the regulatory approach to AI consider how AI impacts wider society as well as those who may be within vulnerable or marginalised communities. This requires approaches for addressing bias and fairness of AI technologies and associated data, and managing their ongoing use, to ensure AI is being used safely and\\n1|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission responsibly. Furthermore, transparency of AI in the delivery of health care is essential and this should be consistent across public and private sectors.\\nThe Department supports greater ethics consideration when using data for AI purposes, particularly as it relates to health outcomes to enable maximum benefits while ensuring there is sufficient trust in the outcomes and how it affects individuals and society. For areas with direct impact on health outcomes of individuals, there is less tolerance for risk and the response should be proportional to the possible impact.\\nThe Department supports the current approach by the Therapeutic Goods Administration (TGA) who regulate products that are intended for medical use including software (that incorporates AI), with a robust regulatory framework for software based medical devices. The framework addresses risks associated with AI and applies to any software included with, or that is a part of, a medical device that is used for diagnosis, prevention, monitoring, treatment, alleviation of disease, injury or disability.\\nThe TGA regularly consults on its regulations to ensure it considers emerging technologies (and risks) to ensure the regulations remain fit for purpose and continue to safeguard Australian patients. The TGA publicly consulted on software including AI in 2019 and 2020 \\u2013 and published updated specific guidance including clinical evidence and performance requirements in early 2021. Further information about the framework and risk classification with some examples is included in the attached Health response\\n[Regulation of Software-based Medical Devices - Info sheet for DISR July 2023].\\nThe Department does not recommend banning the use of high-risk AI applications, rather DISR may consider developing guidance on how to use controls to mitigate risk appropriately. The Department strongly advocates for a risk-based approach in relation to AI and recognises that it may need to be mandatory for moderate to high-risk applications in health and aged care. This provides flexibility to ensure regulatory burden and oversight align with the potential risk of a particular activity, and to reduce burden and promote innovation for low-risk AI applications. Key elements of a risk-based approach should include clear definitions of consequences of the risk and objective, clearly articulated criteria to determine the risk level and how to appropriately deal with the risk. Leveraging existing risk- based approaches, integrating AI-specific risks and controls into risk management, and employing a mix of regulatory and non-regulatory frameworks can support the development of a risk-based approach for addressing AI risks.\\nThe Department recommends DISR considers, in partnership with appropriate regulators such as the\\nNational Data Commissioner and the Information Commissioner, the development of guidelines for\\nData Impact Assessments (DIA) as part of AI assessments. The DIA could be mandatory for organisations applying AI above a set impact threshold, similar to Privacy Impact Assessments. The DIA could take a multi-faceted approach taking into account the purpose, explainability, ethics, sensitivity, sovereignty, security, and impact to provide a holistic assessment of risk and need for regulation.\\nAdditional input and detail on the discussion paper has been provided via direct responses to the\\n20 discussion questions. This input differentiates between issues directly related to the Department in comparison to the broader Australian Healthcare System. i\\nCenter for AI Safety (CAIS) ii\\nhttps://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext and https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00237-2/fulltex\\n2|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nSafe and Responsible AI in Australia \\u2013 Discussion Paper August 2023\\nQuestion Department of Health and Aged Care Australian Healthcare System\\nDEFINITIONS\\n1 Do you agree with the Whilst a high-level definition could be useful, the way AI is used is context specific, as different No objection.\\ndefinitions in this discussion sectors have differing needs.\\npaper? If not, what The Therapeutic Goods Administration (TGA) already has established definitions related to AI for\\ndefinitions do you prefer medical (therapeutic) use which are aligned with the definitions in \\u201cMachine Learning-enabled\\nand why? Medical Devices: Key Terms and Definitions\\u201d published by the International Medical Device\\nRegulators Forum (IMDRF) in May 2022.\\nThe Australian Commission on Safety and Quality in Health Care (ACSQHC) supports the use of\\nthe International Organisation for Standardization definitions.\\nIt is recommended to also include a definition for Automated Decision Making (ADM) to avoid\\nmisinterpreting ADM as fully autonomous. From a legislation perspective, it is recommended to\\nkeep the definition as technologically neutral as possible and consider future use-cases for AI to\\nhelp maintain relevance.\\n2 What potential risks from AI The Department suggests that there is no clear pathway for the sharing of sensitive unit record In considering the development of AI\\nare not covered by health and aged care data with commercial entities within our current legislative frameworks. regulation we need to consider a wide\\nAustralia\\u2019s existing The existing regulations only permit the disclosure of critical departmental data, such as the array of clinicians and professional bodies\\nregulatory approaches? Australian Immunisation Register, Medicare Benefits Scheme, and Pharmaceutical Benefits across the health and aged care sectors and\\nDo you have suggestions for Scheme data, to a limited number of trusted Commonwealth agencies, including the Australian their risk appetites.\\npossible regulatory action to Bureau of Statistics (ABS) and the Australian Institute of Health and Welfare (AIHW). Similar Over the past few years, lots of work has\\nmitigate these risks? disclosures to commercial entities are not permitted under either the primary legislation or the been undertaken to strengthen regulation\\nData Availability and Transparency Scheme (which does not cover private sector firms). and safeguards of Australia\\u2019s critical\\nTo effectively manage risks and protect the integrity of healthcare information while harnessing infrastructure. Due diligence to ensure that\\nthe benefits of AI, the Department advocates for comprehensive regulatory reforms and there is no erosion of other forms of\\nproposes integrating AI-specific regulations within existing Acts. These reforms would legislation would be essential.\\nnecessitate mandatory training for healthcare professionals and adherence to specific AI-related\\nprofessional standards, ensuring that AI is utilised responsibly and ethically within the health\\nsector.\\n1|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nThe Department emphasises the need to implement flagging mechanisms or additional security\\nchecks for medical professionals and researchers seeking access to sensitive data. This would\\nensure accountability and reduce potential security risks associated with the access and use of\\nsensitive health information.\\nAddressing bias in AI algorithms is of utmost importance to avoid disproportionate impacts on\\nvulnerable populations, including First Nations and CALD and LGBTQIA+ and people with a\\ndisability. Data sets on which AI tools are trained, do themselves have inherit bias, (ie male\\nskewed, no comprehensive data on women, gender reduced to the binary) making some groups\\n\\u201cinvisible\\u201d to the algorithm.\\nPrejudice cannot be coded out of a model, but proper representation for minority groups can be\\ntaken into considered in setting up AI modelling. To support the empowerment of First Nations\\ncommunities, The Department stresses the significance of adhering to Priority Reform 4 of the\\nClosing the Gap Agreement. This reform aims to grant First Nations people the ability to collect,\\nanalyse, and use data in meeting their community's unique needs and priorities. Respecting data\\nsovereignty rights and fostering genuine partnerships between the government and First Nations\\npeople are critical principles that must be incorporated into the development of AI technologies\\nand regulatory frameworks. Complying with the CARE principles of Indigenous Data Governance\\nfurther reinforces the commitment to fair and ethical AI practices.\\nHaving approaches for ongoing monitoring and potential re-training of AI technologies and\\nmodels is essential to ensure their relevance and performance over time. Implementation of an\\nAI tool without ongoing review can result in performance deterioration over time due to data\\ndrift, where the data used to train the model is different to the data where the model is being\\napplied. This could have serious implications if the AI tool is being used in a high-risk sector such\\nas healthcare, and evidence suggests it is already a concern in medical machine learning\\ndeployment1. The Department would like the longer-term management and use of AI tools be\\nconsidered at project inception, including responsibilities for managing the tool, and\\nmechanisms for detecting and mitigating data drift and performance degradation.\\nThe Department emphasises the significance of AI applications being available in multiple\\nlanguages, ensuring inclusivity and accessibility for diverse populations, particularly culturally\\nand linguistically diverse (CALD) communities. Addressing potential racial discrimination in AI,\\n1\\nhttps://www.birpublications.org/doi/10.1259/bjr.20220878\\n2|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission particularly concerning recidivism predictions, demands meticulous examination and regulatory intervention to uphold fairness and justice.\\nThe TGA have been regulating products that are intended for medical use including software\\n(that incorporate AI) since 2002, using a robust regulatory framework for software based medical devices. The framework addresses risks associated with AI, and applies it to any software included with, or that is a part of, a medical device that is used for diagnosis, prevention, monitoring, treatment, alleviation of disease, injury or disability. Regulatory requirements are technology agnostic and apply regardless of whether the product incorporates components like AI, chatbots, cloud, mobile apps or other technologies.\\nThe TGA regularly consults on its regulations to ensure it considers emerging technologies (and risks) to ensure the regulations remain fit for purpose and continue to safeguard users. The TGA publicly consulted on software including AI in 2019 and 2020 \\u2013 and published updated specific guidance including clinical evidence and performance requirements in early 2021. The TGA has also consulted with specific groups such as MSIA and relevant health professional colleges on specific types and uses of software.\\nThe TGA has a range of regulatory actions it takes when software or AI is not performing as intended or if a product is being supplied without appropriate regulatory approval.\\nFurther information about the framework and risk classification with some examples is included in Attachment C of the Departments response [Regulation of Software-based Medical Devices -\\nInfo sheet for DISR July 2023].\\nThe National Mental Health Commission (NMHC) would like to ensure the development and utilisation of AI across Australian society does not result in people who experience mental ill- health being treated unfairly, or in other harms to the mental health and wellbeing of the\\nAustralian community. The Department highlights the specific risks associated with AI for individuals experiencing suicidality. Past incidents where AI inadvertently facilitated access to harmful information underscores the need for vigilance and prompt regulatory action to mitigate potential risks.\\nThe Department notes the discussion paper did not outline regulation regarding the use of AI in the health sector, including in supporting/replacing health workforce and points out there is a risk of AI decision making being relied upon in remote settings versus human decision making supported by AI in urban areas. Ensuring equitable access to healthcare, especially for rural and remote communities, requires the responsible integration of AI support. The Department\\n3|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nrecommends regulations that cover various aspects of AI's impact, including clinical decision-\\nmaking, medical report writing, pathology, and health administration. The Medical Workforce\\nPolicy and Strategy underscores the importance of flexible and adaptable regulations,\\nconsidering the rapid pace of AI technology evolution.\\nThe Australian Digital Health Agency (ADHA) suggests that AI presents a risk to the maintenance\\nof quality healthcare information, which is currently not covered by Australia\\u2019s existing\\nregulatory approaches. The maintenance of healthcare information is currently governed by\\nprofessional standards and regulatory frameworks that promote accuracy, quality, and handling\\nof personal health information, such as the My Health Records Act 2012, Healthcare Identifiers\\nAct 2010 and Privacy Act 1988. None of this legislation currently contemplates risks from AI nor\\nthe benefits, and although the My Health Records Act 2012 does allow for decision making using\\na computer program, there is no specific instruction on automated decision-making.\\nThe Government is considering reforms to each of these Acts so there are opportunities to\\ninclude AI-specific regulation as necessary. Current mitigations would be limited to relying on\\nhealthcare professionals undergoing mandatory training and have them meet a set of\\nprofessional standards. Another potential risk from AI that is not covered by Australia\\u2019s existing\\nregulatory approaches relates to the use of AI in policy development and administration in the\\nAustralian Public Service. Clarity and disclosure around the use of AI data and algorithms, and\\nthe limitations of these methods, is crucial when AI outcomes are used to develop policy. The\\nAgency welcomes the recently published Interim guidance for agencies on government use of\\ngenerative AI platforms and recommends the development of more detailed guidance in the\\nfuture, particularly in relation to policy development and administration.\\nThe Department suggests establishing nationally agreed AI principles as well as nationally agreed\\n3 Are there any further non- \\u2022 Likely need for public Education\\nregulatory initiatives the ethical, clinical and technical standards for AI. It is important to develop these national principles campaigns to provide education of the\\nAustralian Government and standards using a transparent, co-designed and consensus-based approach (and leveraging risks and benefits of the use of AI to\\ncould implement to support international standards where appropriate) to support community trust and confidence in AI. It ensure community and clinician\\nresponsible AI practices in acknowledges efforts by the NSW Government in developing an AI Assurance Framework which awareness and trust levels remain high.\\nAustralia? mandates ethical principles to govern bespoke AI systems. It would be appropriate to consider if \\u2022 Consider establishing controlled\\nPlease describe these and the NSW Framework can be applied nationally. environments for developers to test AI\\ntheir benefits or impacts. systems to identify risks and mitigation\\nThe Department encourages partnerships with academic researchers and centres of excellence,\\nstrategies before AI systems are\\nsuch as the National AI Centre, and close monitoring of the Responsible AI Adopt Program, CSIRO\\nreleased for use by Australians.\\nData61, and UTS Australian AI Institute to facilitate innovation, knowledge sharing, and resource\\nutilisation. It also encourages an approach to AI governance that considers publicly available\\n4|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission information both nationally and internationally. It will be important to learn from international \\u2022 Suggest encouraging positive incentives examples such as the European Union (EU) and Canadian approach and incorporating for compliance \\u2013 accountability often international guidelines, standards, and certifications into a national AI framework will ensure build on penalties but incentives to responsible adoption of AI technologies. Supporting AI developers and users is a priority, and reinforce safe and responsible use of AI diligently investigating tools developed by countries like the US and Singapore to identify and could be introduced.\\nmitigate AI-related risks effectively should be considered.\\nThe work of the ACSQHC may assist in supporting the operationalisation of the 5th principle of the AI Ethics Framework - Reliability and safety - in the context of healthcare safety and quality.\\nAs part of its work plan, the Commission is developing resources to assist health services to evaluate and assess AI before the widespread uptake of these technologies. The resources aim to enable the safe implementation of AI into clinical practice and drive measurable improvements in the quality of patient care and outcomes.\\nThe Department recognises the potential need for additional regulatory and governance responses to ensure appropriate safeguards are in place and suggests accrediting the overarching governance processes of vendors developing AI technology, along with their device and software offerings, to instil trust and confidence in AI applications.\\nThe use of software and AI that performs a medical purpose, can be enhanced through further education of relevant health professional colleges and boards, higher education systems and training. Broader benefits could be gained by providing more accessible consumer and other stakeholder education as part of the government response to AI practices. These communication activities should include ensuring those products that are used for medical purposes have relevant TGA approval and that consumers understand the implication of AI and use of their personal information. There are many new stakeholders entering the market who are unaware of existing regulatory obligations and who do not fully understand their ongoing responsibilities.\\nThe TGA partners with ANDHealth to deliver webinars and education initiatives targeted to new entrants including those seeking to commercialise their product.\\nWithin the Australian Public Service (APS), the Government could consider performing an audit of current automated processes that use AI in order to promote transparency and ensure AI is being used safely and responsibly within the APS.\\nTo effectively manage AI-related procurements, upskilling of government officials will be required and close monitoring of procurements will be essential to uphold compliance standards and mitigate potential risks associated with AI implementation.\\n5|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nEngagement of the health and aged care sector will be crucial to ensure equitable access to\\ntraining and education related to AI technology, to facilitate wider acceptance and\\nunderstanding.\\n4 Do you have suggestions on Whilst there is considerable activity related to AI occurring across government, more \\u2022 As indicated in the paper, there are a\\ncoordination of AI consideration is required to understand how AI will apply in the health and aged care contexts as range of existing regulatory\\ngovernance across there are unique ethical, legal, and regulatory challenges that must be addressed. Existing frameworks that are relevant to AI\\ngovernment? regulatory frameworks and legislation are not sufficiently developed for the full utilisation of AI governance. However, there would be\\nPlease outline the goals that and are likely to require significant reform. This is particularly so in relationship to risks to value in coordination and information\\nany coordination human health and around privacy and trust in the release of sensitive health data for use in the sharing in response to related issues.\\nmechanisms could achieve development of AI tools. For example, privacy, copyright and\\nand how they could To achieve a cohesive approach, coordination mechanisms need to establish consistency and online safety issues associated with the\\ninfluence the development coherence in AI policies and regulations across government departments and agencies. The data used to train models will likely\\nand uptake of AI in Australia. coordination of AI governance also facilitates the effective sharing of knowledge and resources have similar intelligence and inquiry\\nand encourages inter-agency cooperation. Government agencies could leverage diverse needs and would benefit from relevant\\nexpertise and experiences to address challenges and capitalise on AI's opportunities. This instrumentalities having clear and\\nknowledge-sharing approach nurtures innovation, accelerates AI adoption, and ensures that the strong channels for information sharing\\ntechnology aligns with Australia's unique needs. Common principles and guidelines will minimise and referral of issues.\\npotential inconsistencies and create an overall strategy for AI adoption in Australia.\\nSector-specific governance of AI in healthcare is essential given the unique risks, challenges and\\nopportunities posed by AI in healthcare. The Australian Alliance for Artificial Intelligence in\\nHealthcare\\u2019s Roadmap for Artificial Intelligence in Healthcare for Australia could help inform\\nAustralia\\u2019s approach to managing the opportunities and risks that AI brings. Building public trust\\nand confidence in AI technologies will be important to ensure the uptake of AI solutions.\\nStreamlining procurement processes related to AI technologies is also another crucial outcome\\nof coordination mechanisms. A cohesive framework could guide government officials in AI-\\nrelated procurements, ensuring compliance with ethical standards and mitigating potential risks.\\nAs a result, the smooth implementation of AI applications becomes feasible, driving effective and\\nefficient use of the technology across government operations. Coordination mechanisms open\\navenues for cross-sector collaborations, bringing together government, academia, industry, and\\nother stakeholders. This inclusive approach fosters strategic partnerships and joint initiatives,\\nleading to transformative research and the development of AI solutions tailored to diverse\\nsocietal challenges.\\n6|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nDISR may wish to consider options for governance that supports ongoing inter and intra-\\ngovernmental engagement on matters such as AI that are not industry specific \\u2013 such as privacy\\nor cybersecurity. The Department and the TGA already works with other governance bodies such\\nas Office of the Australian Information Commissioner (OAIC) and the Australian Cyber Security\\nCentre respectively, to ensure a cohesive approach to regulation.\\nThere is an opportunity for the Commonwealth to co-design with jurisdictions a national AI\\nethical and governance framework, in consultation with industry experts and the public. The\\nnew national framework would refresh the existing Commonwealth AI Ethics Framework and\\ncould be expanded to cover more specific guidance for key sectors in the economy where AI is\\nalready having, and will have, a significant impact, including healthcare. Such a framework could\\nform the basis to support for future self-regulation or government legislation.\\nRESPONSES SUITABLE FOR\\nAUSTRALIA\\n5 Are there any governance The Department is actively involved in ongoing surveillance of the international landscape with \\u2022 DoHAC is actively involved in ongoing\\nmeasures being taken or the view to identifying new and emerging governance measures, particularly in the EU, UK, surveillance of the international\\nconsidered by other Canada, and the USA. There is a need to understand the contextual differences between what is landscape with the view to identifying\\ncountries (including any not acceptable in these counties versus in Australia and learn from their experiences and evaluation new and emerging governance\\ndiscussed in this paper) that of new initiatives. measures, in particular in the EU, UK,\\nare relevant, adaptable, and The TGA maintains a close relationship with other comparable regulators to ensure Canada and the USA.\\ndesirable for Australia? harmonisation of approaches. New requirements for software as a medical device (including AI) There is a need to understand the\\nare emerging in different jurisdictions including Europe, Canada, UK and the USA. The European contextual differences between what is\\nMedical Device Regulations (EU MDR 2017/745) has also introduced new requirements, acceptable in these counties versus in\\nincluding classifications specific for software as a medical device as part of a risk-based Australia and learn from their\\napproach. The European rule is consistent with the IMDRF recommendations. Since 2013, the experiences and evaluation of new\\nIMDRF (covering 10 regulators covering all major markets globally) has had in place, a dedicated initiatives. Consultation with the health\\nworking group reviewing Software as a Medical Device (SaMD), and AI \\u2013 and publishes technical and aged care sectors will be essential\\ndocuments. The IMDRF undertakes global public consultation on all its work and participates in to ensure that governance measures\\nInternational Standards Organisation (ISO) standards, including those relating to SaMD. are fit for purpose.\\nA governance measure that is not discussed in the consultation paper that might help inform\\nAustralia\\u2019s approach to AI is the United States' proposed Algorithmic Accountability Act 2022.\\nThis legislation aims to establish a regulatory framework for assessing and mitigating bias and\\n7|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\ndiscrimination in AI systems used by large entities. It contains principles that might help Australia\\naddress algorithmic bias and promote fairness in AI applications.\\nConsultation with the health and aged care sectors will be essential to ensure that governance\\nmeasures are fit for purpose.\\nTARGET AREAS\\n6 Should different approaches No. There should be no differences between use in private or public sector for software and AI \\u2022 In broad terms, the approaches to\\napply to public and private used for medical purposes. public and private sector use of AI\\nsector use of AI Under existing arrangements, the private sector cannot obtain health data for AI research in should be similar in that the\\ntechnologies? preparation for commercial purposes. The private sector can however with universities and they overarching principles should be similar\\nIf so, how should the can justify public interest considerations. and the risks posed by each sector\\u2019s\\napproaches differ? use are similar. However, the\\nGovernment public health data is largely administered (ie. without consent to gather data for regulatory framework should be alive\\nMedicare and PBS) and the use of this data in potential AI applications raises additional ethical to the different kinds of conflicts of\\nconsiderations that warrant thorough review and evaluation. Despite the potential risks, the use interest each sector may have in using\\nof sensitive personal information in the health and aged care sectors can provide a significant AI technologies. In the case of the\\npublic benefit by improving policy and service delivery. Balancing these benefits against the private sector, the typical concern is\\ninherent risks becomes crucial in contemplating specific regulations for AI activities in this that the profit motivation will lead to\\ndomain, ensuring that they do not excessively burden existing frameworks and hinder genuinely misuse of these technologies and\\npublic-interested activities. regulatory arrangements are crafted\\nThere are already sophisticated frameworks applied to the public sector that aim to ensure its accordingly.\\nfocus on the public interest (including reconciling conflicts between ends and means), for \\u2022 In the case of the public sector, the\\nexample, parliamentary oversight and legislation, audit and other investigating bodies, FOI and concern is that there may sometimes\\ntransparency regimes, and public sector codes of conduct. As a result, there appear to be be a conflict between ends and means,\\ndifferences in the uses broadly considered acceptable by the public sector, including allowing for that is:\\nthe public sector to engage in\",\n          \"Safe and responsible AI in\\nAustralia\\nKPMG submission\\n_____\\nKPMG Australia, July 2023\\nKPMG.com.au\\nContents\\nExecutive summary 3\\nBackground 4\\nSection 1: KPMG recommendations 5\\nSection 2: KPMG insights 8\\n\\u00a92022 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n3 | Safe and responsible AI in Australia\\nExecutive summary\\nAs a leading professional services firm, KPMG Australia (KPMG) is committed to meeting the requirements of all our stakeholders \\u2013 not only the organisations we audit and advise, but also employees, governments, regulators \\u2013 and the wider community. We strive to contribute in a positive way to the debate that is shaping the Australian economy and we welcome the opportunity to provide a submission to the Department of\\nIndustry, Science and Resources Safe and responsible AI in Australia discussion paper (the discussion paper).\\nThis submission builds on KPMG\\u2019s previous engagement in the safe and responsible development of AI in Australia and globally. KPMG has provided a number of submissions to various forums on this topic, including on Automated Decision Making and AI regulation in July 2022, An AI Action Plan for all\\nAustralians in December 2020, the Australian Data Strategy in July 2022, and Human Rights and\\nTechnology in 2020 and Beyond in March 2020. KPMG published a report with the AIIA in March 2023,\\nNavigating AI: analysis and guidance on use and adoption, which examines the global and domestic regulatory landscape in the Artificial Intelligence space.\\nWe have also done extensive work with the University of Queensland on the topic of Trust in Artificial\\nIntelligence. The most recent paper, Trust in Artificial Intelligence: Global Insights 2023, was published in\\nFebruary 2023 and surveyed over 17,000 people from 17 countries on the public\\u2019s trust and attitudes towards AI. Previous work in this series includes Achieving Trustworthy AI: A Model for Trustworthy\\nArtificial Intelligence, Trust in Artificial Intelligence: A five country study, and Trust in Artificial Intelligence:\\nAustralian Insights 2020.\\nKPMG is an early and active user of AI, having recently expanded our partnership with Microsoft to streamline the deployment of AI in our back-office functions and consider its use across tax, audit and advisory work. 1 KPMG is also developing a people-centred approach to AI that will apply to the design and deployment of AI within the firm.\\nThe successful adoption of responsible AI needs to be assisted by addressing the public's current lack of trust in AI by ensuring the right mix of policy settings, regulations and laws to ensure AI use is safe.\\nKPMG and the University of Queensland\\u2019s research has found that only two in five people believe current regulations, laws and safeguards are sufficient to make AI use safe. Without appropriate legal and regulatory frameworks, a lack of trust in AI will persist, meaning that it is likely that its full potential will not be realised.\\nIn this submission, KPMG recommends a people-centred approach to AI that prioritises regulatory action on the human rights impact and potential harms of specific types of data used in AI solutions, data protection and integrity and ensuring the definition of personal information can meet the diverse types of data underpinning AI solutions. While in this submission we have focused on a people-centred approach to AI, we acknowledge there are various other impacts, such as environmental considerations, that will also need to be addressed. KPMG supports harmonising overlapping regulatory frameworks across\\nAustralia and ensuring greater consistency with international regulatory frameworks to reduce administrative burden and assist technology exporters.\\nThe submission outlines 16 recommendations at section one and directly addresses the consultation questions at section two. If you would like to discuss the contents of this submission further please do not hesitate to reach out. KPMG looks forward to continuing engagement with the Australian Government as it develops a safe and responsible framework for AI in Australia.\\nYours sincerely,\\nJames Mabbott Richard Boele Danielle Malone Veronica Scott\\nPartner in Charge, Chief Purpose Partner in Charge, Cyber, Privacy & Data Lead,\\nKPMG Futures Officer Data & Cloud KPMG Law\\nKPMG Australia KPMG Australia KPMG Australia KPMG Australia\\n1\\nKPMG and Microsoft agreement to put AI at the forefront of professional services \\u2013 Media release 12 July 2023\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n4 | Safe and responsible AI in Australia\\nBackground\\nAbout KPMG\\nKPMG is a global organisation of independent professional firms, providing a full range of services to organisations across a wide range of industries, governments and not-for-profit sectors. We operate in\\n146 countries and territories and have more than 227,000 people working in member firms around the world. In Australia, KPMG has a long tradition of professionalism and integrity combined with our dynamic approach to advising clients in a digital-driven world.\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n5 | Document title\\nSection 1:\\nKPMG recommendations\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n6 | Safe and responsible AI in Australia\\nRECOMMENDATION 1:\\nKPMG suggests that the following areas could be considered for regulatory action, subject to further consultation:\\n\\u2022 The human rights impacts and harms of using specific types of data (e.g., sensitive information) to\\ndevelop AI solutions.\\n\\u2022 Data related concepts such as data integrity and quality, data ownership, data collection,\\nanonymisation, de-identification, encryption and their role in the context of AI and protection of\\nhuman rights.\\n\\u2022 The definition of \\\"personal information\\\" given the increasingly diverse types of data that could trigger\\nharms and human rights violations.\\n\\u2022 The consideration of an advisory board to provide ongoing support in relation to AI regulations, ethics\\nand data sharing, including examining international trends and ensuring Australia\\u2019s regulations are\\naligned to reduce administrative burden.\\nRECOMMENDATION 2:\\nKPMG considers that there is a range of non-regulatory initiatives the government could consider in supporting responsible AI in Australia, including:\\n\\u2022 Investment in public education campaigns to increase the Australian public\\u2019s awareness, trust and\\nunderstanding of AI. This should include education on what regulatory safeguards already exist under\\nexisting regulations.\\n\\u2022 Reviewing the roles and responsibilities of existing regulators with responsibility for data, consumer\\nrights, and online harm protection to address gaps, ensure clarity and reduce overlap.\\n\\u2022 Consideration of a federal Commissioner to support regulators, policy makers, governments and\\nbusinesses to develop and apply laws and other standards in this area.\\nRECOMMENDATION 3:\\nThe government consider initiatives that help organisations embed assessments and frameworks that are fit for purpose for designing, implementing, procuring, and using different types of AI, and making decisions based on the AI and the data that is used.\\nRECOMMENDATION 4:\\nKPMG recommends that any regulatory settings for AI and automated decision making (ADM) should build on existing frameworks such as privacy, discrimination and consumer laws, with a focus on ensuring they are adequate to address potential harms caused by AI and ADM.\\nRECOMMENDATION 5:\\nKPMG supports addressing duplication within the broader landscape of data-related regulatory requirements at the state and federal level. We encourage collaboration between Commonwealth agencies to ensure harmonisation between overlapping regulatory frameworks.\\nRECOMMENDATION 6:\\nKPMG is supportive of the Commonwealth public sector data sharing scheme given the significant benefits from the ability for government departments and agencies to share and access each other\\u2019s data.\\nRECOMMENDATION 7:\\nGreater consistency with international regulatory frameworks would significantly reduce administrative burden, help with exporting technology out of Australia and set clearer expectations for the importation of technology.\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n7 | Safe and responsible AI in Australia\\nRECOMMENDATION 8:\\nGiven the mature stage of development of the EU\\u2019s AI Act, Australia could consider the risk-based approach with stricter regulation of AI and ADM applications in high-risk areas, to inform its regulation.\\nRECOMMENDATION 9:\\nKPMG considers that both the public and private sector\\u2019s use of AI technologies must be held to the same minimum standards, including in relation to privacy protection, transparency and explainability, contestability, and discrimination.\\nRECOMMENDATION 10:\\nTo further support responsible AI practices in Australian Government agencies, KPMG recommends consideration of defining principles and boundaries for ethical data sharing practices and an assessment of the impact on human rights.\\nRECOMMENDATION 11:\\nKPMG suggests it would be useful to consider the introduction of transparent disclosure obligations that require organisations to disclose why an AI use case was deemed to have complied with the particular ethics framework.\\nRECOMMENDATION 12:\\nKPMG suggests the regulatory framework should be founded on a core set of principles, ideally based on current established principles (such as: safety, security, robustness, fairness, transparency and accountability). These principles should be able to be translated into effective assessment and assurance framework tools that organisations can embed.\\nRECOMMENDATION 13:\\nKPMG recommends a range of initiatives that may increase public trust in AI deployment, including the development of a certification regime for responsible AI, embedding data quality requirements, public education campaigns, and other measures such as licencing, auditing, impact assessment and regulatory oversight.\\nRECOMMENDATION 14:\\nKPMG considers that the implementation of assurance mechanisms would facilitate greater trust in AI systems. The proposed EU AI Act requires high-risk applications of AI and ADM to be approved through a conformity assessment, and it would be worth considering whether aligning to this approach would be suitable for Australia.\\nRECOMMENDATION 15:\\nKPMG considers that the government could usefully explore with industry the development of an initial human rights risk assessment to determine an AI project's level of risk to people upfront and ensure the appropriate level of governance oversight and remediation is applied.\\nRECOMMENDATION 16:\\nKPMG considers that self-regulation may ultimately not be sufficient, and agreement on regulatory goals is necessary before effective self-regulation can occur.\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n8 | Document title\\nSection 2:\\nKPMG insights\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n9 | Safe and responsible AI in Australia\\nKPMG insights\\nDefinitions underpins the application and subsequently use\\ncase of that application. However, the\\ngovernment should consider the impact of the\\n1. Do you agree with the definitions in proposed definition on the systems that would\\nthis discussion paper? If not, what be in scope for regulation on a risk based\\ndefinitions do you prefer and why? approach.\\nThe discussion paper defines AI as an\\n2. What potential risks from AI are not engineered system that generates predictive output without explicit programming and lists covered by Australia\\u2019s existing machine learning, generative AI models regulatory approaches? Do you have\\n(including large language models, multimodal suggestions for possible regulatory foundation models) and automated decision action to mitigate these risks?\\nmaking (ADM) as examples.\\nAppropriate legal and regulatory frameworks are\\nThis definition is consistent with the definitions critical to providing individuals, businesses and previously used by KPMG, however given the governments with increased certainty about the rapidly advancing nature of this technology, it risks and benefits of adopting AI and ADM may be useful to consider a broader definition. technologies, which in turn will encourage\\nThe government could consider the following increased uptake and investment.\\nexamples when finalising its definition, which KPMG supports a regulatory approach that is also capture autonomy versus automation: simple and clear in order to achieve the right\\n\\u2022 Any artificial system that performs tasks balance between appropriate safeguards and\\nunder varying and unpredictable enabling innovation. Whilst regulation will help\\ncircumstances without significant human enable trust, doing so without being sensitive to\\noversight, or that can learn from experience what already exists risks limiting the uptake of\\nand improve performance when exposed to the technology and driving out innovation due to\\ndata sets. 2 a regulatory landscape that could be too\\ncomplex to manage or navigate.\\n\\u2022 Artificial intelligence system\\u2019 (AI One of the key challenges for private and public\\nsystem) means a system that is designed to organisations in the deployment and use of\\noperate with a certain level of autonomy and responsible AI arises from the multiplicity of\\nthat, based on machine and/or human- guidelines, frameworks, good practices and\\nprovided data and inputs, infers how to toolkits developed by the Australian\\nachieve a given set of human-defined Government as well as national and\\nobjectives using machine learning and/or international policy makers. The development\\nlogic- and knowledge based approaches, and adoption of a simplified and interoperable\\nand produces system-generated outputs regulatory framework for AI should be\\nsuch as content (generative AI systems), accompanied by the identification of a leading\\npredictions, recommendations or decisions, regulatory body responsible for developing and\\ninfluencing the environments with which the enforcing AI legislation.\\nAI system interacts. 3\\nGaps in regulatory guidance on how existing\\nKPMG also notes that two common types of AI laws apply to AI systems are generative AI and predictive AI.\\nBoth use neural network machine learning but Existing legislative frameworks that aim to are not the only systems that use machine address consumer and other individual harms learning. Therefore, it may be necessary to should be considered as a starting point, noting identify the underlying technology of neural that the current frameworks are generally not network machine learning, or the system-level yet adequately adapted to the use of AI and capability of generative/predictive AI that then ADM technologies and their potential adverse\\n2\\nKey AI terminology \\u2013 United States IT Modernization 3\\nEuropean Union \\u2013 Artificial Intelligence Act\\nCentres of Excellence\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n10 | Safe and responsible AI in Australia impacts. Further guidance is required on how considering legislating for a database right, these existing frameworks and laws apply to AI should be addressed. This should include technologies and effectively prevent the harms regulation of IP ownership of AI systems in that can arise from their use. This should reflect relation to opensource algorithms and the policy settings and principles framework for ownership of the data being used for their\\nAI and would provide guidance and certainty for development.\\nentities developing or using the technologies\\nAccountability and afford individuals or groups of individuals with appropriate rights in relation to the data In investigating an appropriate regulatory uses, inputs and outcomes from the use of AI framework, KPMG considers that the and ADM as well as assurance, monitoring and government could usefully explore with industry: oversight. There should be a focus on ensuring legislative frameworks are adequate to address \\u2022 the development and adoption of a code of outcomes and decisions made as a result of conduct or charter that supports self- using AI and ADM, including potential harms. regulation and embeds shared values and\\nprinciples to support ethical and trustworthy\\nInformation privacy data use and AI;\\nThe Privacy Act is intended to be technology neutral and therefore is a foundational\\n\\u2022 how responsibility and accountability can be\\nclearly defined, allocated, understood and regulatory framework that focuses on personal\\nexecuted across key stages of the AI information, which is one of the larger data sets\\nlifecycle; commonly used in AI and ADM. In its current state, the Privacy Act has some legislative gaps \\u2022 the development of governance, monitoring related to employee records and small business and reporting structures that provide exemptions, however we note that these areas appropriate oversight of how AI systems and are subject to reform as a result of the Review technologies are brought into an of the Privacy Act, 4 including proposals to organisation's operations, products and/or impose additional obligations in relation to the services; and use of personal information for automated decision making. Areas that are particularly \\u2022 transparently documenting who can, is and relevant to the application of AI include should be making key decisions throughout protections for de-identified information the AI system lifecycle including based on\\n(including consideration of how AI may be used the outputs.\\nto re-identify information through the use of multiple data sources); high risk privacy Governance, monitoring and reporting processes; the misuse of data which results in structures should also include assurance detrimental outcomes for consumers, as well as mechanisms that provide assurance for employees; and where technological organisations, individuals, and the community breakthroughs and innovations are often driven more broadly.\\nby smaller firms. The impact of the use of Consent different types and combinations of data by AI, in particular sensitive information, must be The Privacy Act in its current form does not adequately addressed. Further, the reliance on explicitly set out the requirements for lawful notice and consent needs revisiting to ensure consent or what types of consent must be transparency and choice is embedded. obtained according to personal information\\ntypes or processing purposes. The Privacy Act\\nHow to practically and effectively achieve Review proposes that lawful consent and its consent needs to be reconsidered in light of the elements are defined in the Act to cover both functionalities and capabilities of technology in implied and express consent which would reflect specific contexts of use, which are not static. current guidance. Further consideration should\\nFor example, in relation to facial recognition be given to the impact of the use of personal technologies where biometric data may be information as inputs and outputs of AI systems captured without any consent process, such as and technologies on the proposed consent when this technology is used for theft detection model. This should include how to strike the and prevention. right balance consistent with core AI principles,\\nIntellectual property (IP) where there may be higher expectations from\\nindividuals, and could recognise both the\\nClarity on the IP status of publicly available data important role of government and the power being used for development and training of AI models as well as AI outputs, including\\n4\\nPrivacy Act Review Report \\u2013 Attorney-General\\u2019s\\nDepartment\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n11 | Safe and responsible AI in Australia imbalances that may exist between individuals KPMG and the University of Queensland\\u2019s and government agencies. recent report Trust in Artificial Intelligence:\\nGlobal Insights 2023 found that while 82 percent\\nAlgorithmic bias\\nof people are aware of AI, one in two people\\nAs they currently exist, predictions or outputs report feeling they do not understand AI or when from some AI systems exhibit a high rate of and how it is used. 5 People who better error that disproportionately affect already understand AI are more likely to trust and vulnerable or marginalised populations, such as accept it and perceive greater benefits of AI use.\\non the basis of skin colour, gender and Further, the analysis finds that 82 percent of disability. Existing laws are inadequate to people want to know more about AI. Considered address the potential harm to people caused by together, these findings suggest a strong need the use of these technologies. Consequently, and appetite for public education on AI.\\nthis is an area requiring the development of\\nThe report finds that Asian countries and specific legislation.\\nFinland have the highest levels of AI awareness.\\nHigh rates in Finland compared to other western\\nRECOMMENDATION 1: nations may partially reflect investment in public\\nAI education, for example, the Elements of AI\\nKPMG suggests that the following areas could course is a free online course created by the be considered for regulatory action, subject to University of Helsinki and MinnaLearn and has further consultation: been completed by over 850,000 people. 6\\n\\u2022 The human rights impacts and harms of KPMG recommends the Australian government\\nusing specific types of data (e.g., sensitive consider investment in public AI education\\ninformation) to develop AI solutions. campaigns in order to drive cultural change and\\nincrease awareness, trust and responsible use\\n\\u2022 Data related concepts such as data integrity of AI. This should include education on what\\nand quality, data ownership, data collection, regulatory safeguards already exist under\\nanonymisation, de-identification, encryption existing regulations.\\nand their role in the context of AI and\\nFederal AI Commissioner\\nprotection of human rights.\\nKPMG supports the recommendation made by\\n\\u2022 The definition of \\\"personal information\\\" the Australian Human Rights Commissioner in\\ngiven the increasingly diverse types of data 2021 for the creation of a federal AI\\nthat could trigger harms and human rights Commissioner. 7 The role of the Commissioner\\nviolations. would be to \\u201csupport regulators, policy makers,\\ngovernment and business develop and apply\\n\\u2022 The consideration of an advisory board to\\nlaw and other standards in this area.\\u201d In our\\nprovide ongoing support in relation to AI\\nview, this function could deliver significant value\\nregulations, ethics and data sharing,\\nin filling the gap of uncertainty about how to\\nincluding examining international trends and\\ndesign and deploy AI in a way that is both lawful\\nensuring Australia\\u2019s regulations are aligned\\nand people centred.\\nto reduce administrative burden.\\nAI and mis-, dis- and mal-information (MDM)\\n3. Are there any further non-regulatory The speed and opacity of AI algorithms can be\\ninitiatives the Australian Government used to facilitate mis-, dis- and mal-information\\ncould implement to support (MDM). This includes attempts, amongst other\\nresponsible AI practices in Australia? things, to undermine trust in the fabric of\\ndemocratic society and mobilise extremist\\nPlease describe these and their views, including but not limited to, information\\nbenefits or impacts. warfare, as outlined in the recent Defence\\nEducation Strategic Review 2023. 8\\nKPMG considers that education is a key non- We also note examples where AI has created regulatory initiative that the government could non-existent references, articles and citations to implement to support responsible AI practices in support a desired output, where there is no ill-\\nAustralia. intent at play. It is important to consider both the\\ndeliberate use of AI systems to create distrust,\\nbut also the potential to create false facts due to\\n5 7\\nGillespie, N., Lockey, S., Curtis, C., Pool, J., & Akbari, A. AI Safety Commissioner \\u2013 Australian Human Rights\\n(2023). Trust in Artificial Intelligence: A Global Study. The Commission\\n8\\nUniversity of Queensland and KPMG Australia. National Defence: Defence Strategic Review 2023 -\\n6\\nElements of AI free online course Commonwealth of Australia 2023\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n12 | Safe and responsible AI in Australia the way some systems (generative models in protection to ensure clarity and reduce particular) operate. overlap.\\nAustralia could draw upon lessons learned from \\u2022 Consideration of a federal Commissioner to\\nNorway 9 and Germany 10 in strengthening support regulators, policy makers,\\nAustralia\\u2019s information resilience. As society has governments and businesses to develop become more dependent on information, the and apply laws and other standards in this ability to think critically about the information area.\\ncitizens receive becomes critical. Greater education and awareness are required at every level of society to build democratic resilience. RECOMMENDATION 3:\\nCentralisation versus decentralisation of AI The government consider initiatives that help\\nThe centralisation of AI may give rise to the organisations embed assessments and notion of encouraging through regulation the frameworks that are fit for purpose for decentralisation of AI capability as a means to designing, implementing, procuring, and using democratise and curtail the worst effects of AI. different types of AI, and making decisions\\nYet, a recent study at Harvard University found based on the AI and the data that is used.\\nAI decentralisation produced similar harmful effects when ethical and regulatory frameworks 4. Do you have suggestions on are absent. 11 As the authors of the study argue: coordination of AI governance across\\nThese technologies enable radical innovations government? Please outline the goals in social, economic, and political institutions and that any coordination mechanisms practices, with the potential to support could achieve and how they could transformative approaches to political economy.\\ninfluence the development and uptake\\nThey demand governance innovation. There is the potential to overcome persistent injustices of AI in Australia.\\npower concentrations, and perversions of KPMG and the University of Queensland\\u2019s capitalism and democracy. In fact, recent research finds that 71 percent of people believe advances in artificial intelligence (AI) may make AI regulation is required. 12 Further, people are these tools critical to preserving human dignity, broadly supportive of multiple forms of agency, and even existence. Yet there are also regulation, including regulation by government risks of catastrophe and oppression that eclipse and existing regulators, a dedicated those seen in the twentieth century. Calibre of independent AI regulator, and co-regulation and governance will determine which path we find industry regulation, with general agreement of ourselves upon. the need for some form of external, independent\\noversight.\\nRECOMMENDATION 2: Strengthening existing laws and guidance in\\nthe context of AI\\nKPMG considers that there is a range of non- regulatory initiatives the government could KPMG recommends that any regulatory settings consider in supporting responsible AI in for AI and ADM should build on existing\\nAustralia, including: frameworks such as privacy, discrimination and\\nconsumer laws, with a focus on ensuring they\\n\\u2022 Investment in public education campaigns to are adequate to address potential harms caused\\nincrease the Australian public\\u2019s awareness, by AI and ADM. To ensure a fit for purpose\\ntrust and understanding of AI. This should framework, any new regulations to address gaps\\ninclude education on what regulatory or inadequacies should be developed through a\\nsafeguards already exist under existing full industry consultation process, reviewed\\nregulations. regularly, and be as technology neutral as\\npossible.\\n\\u2022 Reviewing the roles and responsibilities of\\nexisting regulators with responsibility for It would be worthwhile to identify areas that are\\ndata, consumer rights, and online harm already subject to regulatory oversight and\\nensure that the rights, duties, and powers\\ncreated by these regimes are appropriately\\n9 11\\nThe Defence of Norway: Capability and Readiness - Long Ethics of Decentralised Social Technologies: Lessons\\nTerm Defence Plan 2020 \\u2013 Norwegian Ministry of from Web3, the Fediverse, and Beyond \\u2013 March 2023\\n12\\nDefence; Setting the Course for Norwegian Foreign and Gillespie, N., Lockey, S., Curtis, C., Pool, J., & Akbari, A.\\nSecurity Policy - Norwegian Ministry of Foreign Affairs (2023). Trust in Artificial Intelligence: A Global Study. The\\n10\\nOn German Security Policy and the Future of the University of Queensland and KPMG Australia.\\nBundeswehr - German Federal Ministry of Defence\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional S\",\n          \"21 August 2023\\nAustralian Federal\\nPolice submission\\nSupporting responsible AI: discussion paper\\nDepartment of Industry, Science and Resources\\nafp.gov.au\\nAustralian Federal Police submission / 21 August 2023\\nTable of contents\\nIntroduction 2\\nThreat Environment 3\\nUse of AI by the AFP 4\\nManagement of the use of AI by the AFP 6\\nGovernance 7\\nInternal policies and building oversight AI framework 8\\nTechnical leadership 8\\nTraining 9\\nPartnerships 9\\nConclusion 10\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 1\\nAustralian Federal Police submission / 21 August 2023\\nIntroduction\\n1. The Australian Federal Police (AFP) welcomes the opportunity to make a submission to the\\nDepartment of Industry, Science and Resources\\u2019 public consultation on safe and responsible\\nArtificial Intelligence (AI) in Australia. This submission addresses both identified criminal\\nthreats relating to AI, and considerations for the use of AI for law enforcement purposes.\\n2. The AFP protects Australians and Australia\\u2019s interests from a wide range of harms by virtue\\nof our diverse functions. As the Commonwealth\\u2019s policing agency, the AFP has responsibility\\nfor enforcing Commonwealth criminal law, contributing to combating complex, transnational,\\nserious and organised crime impacting Australia's national security and protecting\\nCommonwealth interests from criminal activity in Australia and overseas. The AFP also has\\nresponsibility for providing policing services to the Australian Capital Territory (ACT) and\\nAustralian external territories.\\n3. Technology is an enabler for the broader community including criminal enterprises, and in\\nturn for policing. The AFP\\u2019s Technology Strategy recognises that all crime types and policing\\nfunctions are affected by the use of technology. The emergence of increasingly mature AI\\nand machine learning (ML) has accelerated this impact as it permeates many facets of\\ntechnology and society.\\n4. The AFP recently published the \\u201cBlue Paper: To 2030 and Beyond\\u201d detailing the future of\\nfederal policing. This sets out our strategic approach to safeguarding lives, livelihoods, and\\nAustralia\\u2019s way of life well into the 2030s. Within this strategic outlook, the Blue Paper\\nacknowledges the significance of Digital Evolution 4.0, including the influential role of AI, as a\\nmajor driver of transformative changes affecting the Australian community and in turn\\npolicing. The AFP is committed to five future core priorities, which includes leadership in\\nembracing and leveraging technology. To meet the ever evolving operational and threat\\nenvironment, successful implementation of new and emerging technology will play an\\nimportant role in shaping the AFP\\u2019s future operational effectiveness and efficiency.\\n5. The AFP recognises technology is also a key enabler for criminal activity against Australians,\\nincluding by cyber criminals, the online grooming and subsequent abuse of children, and\\neasily accessible exposure to abhorrent and violent extremist material, radicalising our most\\nvulnerable - including children. The effect is delivered from a distance, and at speed and\\nscale that is unprecedented in our history. AI and ML delivers further opportunities for\\ncriminals to scale their activities, yet these tools are equally essential to law enforcement\\nresponding to this threat.\\n6. The AFP is determined to understand and engage with the threats and opportunities posed\\nby AI. Into the future, the use of AI will be required for the AFP to effectively achieve our\\nmission, to uphold public safety and combat criminal activities. To do this, the AFP will\\nassess the following opportunities:\\n\\uf0b7 continually explore and seek opportunities to invest in new technology;\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 2\\nAustralian Federal Police submission / 21 August 2023\\n\\uf0b7 invest in / upskill our people to ensure they have the requisite skills and\\nunderstanding of AI;\\n\\uf0b7 ensure appropriate processes and governance in relation to the implementation of\\nnew technologies to meet community expectations;\\n\\uf0b7 continue to strengthen, and foster new, relationships across government, industry\\nand academia; and\\n\\uf0b7 work with the broader community to ensure Australia has a fit for purpose regulatory\\nenvironment.\\nThreat Environment\\n7. Although AI offers great value to humanity, criminal enterprises have been, and will continue\\nto be early adopters of technology wherever they see an opportunity to advance their\\ninsatiable appetite to benefit at the expense of others. Criminals will use any means possible,\\neven if it means undermining legal principles or basic democratic rights, or creating a feeling\\nof terror within a community. The policy environment needs to be as agile and dynamic as\\nthose seeking to cause harm in our communities.\\n8. The AFP considers the key threats posed by AI affecting the criminal environment include:\\n\\uf0b7 Increased Potency: AI enables more frequent and widespread attacks, amplifying their\\nimpact.\\n\\uf0b7 Enhanced Accessibility: AI lowers the entry bar and cost for non-technical individuals\\nto engage in malicious activities.\\n\\uf0b7 Exploitation of Human-Centric vulnerabilities: AI is more efficient and effective in\\nleveraging vulnerabilities unique to human behaviour.\\n\\uf0b7 Deliberate sabotage of critical algorithms: AI introduces the risk of poisoned and\\nsabotaged algorithms leading to ineffectual use of AI and/or harm.\\n9. The threats of future generations of AI tools may create unforeseen consequences that\\nfurther enable criminal activity. By evaluating the current capabilities of AI, we gain some\\ninsight into future risks that may be realised as the criminal enterprise takes further\\nadvantage of the AI capability as it develops. These technology-facilitated crimes could\\nbecome increasingly prevalent and have a profound impact on our communities as new\\nthreats emerge.\\n10. One example of threat faced now is deepfakes, which involve manipulating audio and video\\nto impersonate a person. Deepfakes can and have been used to discredit public figures,\\nextort funds, and influence democratic processes. This has serious implications for trust,\\nreputation and public safety. The sophistication of deepfakes makes it difficult to distinguish\\n\\u2018fact from fiction\\u2019 and the \\u2018real from virtual\\u2019, and poses a real challenge for both law\\nenforcement and the broader community. In turn, this could lead to widespread distrust of\\naudio and visual content, which is an important way that governments and other bodies\\nconnect and communicate with their communities.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 3\\nAustralian Federal Police submission / 21 August 2023\\n11. Another recognised form of harm is the creation and distribution of child exploitation\\nmaterial. The creation of AI generated (fake) child exploitation material is not only illegal but\\nalso encourages and normalises the abuse of real children and diverts law enforcement\\nresources invested in victim identification.\\n12. The rise of AI-driven cybercrime is another key identified harm to the community. Criminals\\nor foreign entities can leverage AI algorithms to launch large-scale cyber-attacks that are\\nmore sophisticated and targeted, such as phishing scams, ransomware and data breaches.\\nOver $33 billion was reported as lost from cybercrime in Australia in 2020-21 and this is only\\nexpected to increase. The ability of AI to develop and distribute convincing phishing emails\\nthat are indistinguishable from genuine emails or that are designed to circumvent automated\\ndetection systems presents a new frontier to identity theft, financial fraud and how online\\nscams are orchestrated.\\n13. Just as AI technology evolves over time, so will the threat. The challenge of countering new\\nthreats will require continual investment in technology by law enforcement, supported by\\ntraining and governance, to enable a technically literate and empowered workforce. The\\nfundamental focus of law enforcement\\u2019s use of AI must be the effective balancing of\\ntransparency, accountability, fairness, privacy and security, proportionality and justifiability.\\n14. Changes to legislation and regulations need more detailed consideration to ensure the\\nAustralian community is protected. The AFP welcomes engagement to ensure policy\\nchanges are practical, proportionate and enforceable. Striking the right balance between the\\nrole of police in safeguarding our community, and the safeguarding of individual rights\\nrequires robust consideration, governed by general and sector-specific regulations. Adhering\\nto the Peelian principles of policing, the AFP will prioritise community engagement and\\ntransparency in AI development, acknowledging that successful policing within democratic\\nsocieties is based on trust to apply powers fairly and without fear or favour.\\n15. Protecting our community from harm through strong relationships and enduring\\npartnerships with key stakeholders is at the heart of achieving operational outcomes. The\\nAFP is increasingly confronted by evolving, multi-disciplinary challenges that require multi-\\nagency and multi-jurisdictional solutions. The same principle applies to combatting the\\nthreats emerging from the use of AI. The AFP will leverage our domestic and international\\nnetworks to further strengthen partnerships across the country and the world.\\nUse of AI by the AFP\\n16. To date the AFP has taken a cautious approach to harnessing the potential of AI despite its\\nearly adoption and use by those with intent on harming Australians. We recognise the need\\nto engage more on the potential of AI to remain effective in our mission to uphold public\\nsafety and combat criminal activities. The AFP acknowledges that we must hold ourselves to\\na higher standard than those of our adversaries and be cautious in the use of broader private\\nindustry offerings due to the ethical and privacy impacts of the technology.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 4\\nAustralian Federal Police submission / 21 August 2023\\n17. The AFP is continuing to evolve our internal processes to navigate the development and\\ndeployment of emerging technologies. As the technology landscape changes, we will need to\\nensure accountability, transparency, and responsibility when adopting any new technology.\\nThis principle has been, and will continue to be, the cornerstone of the AFP\\u2019s journey towards\\nresponsible and ethical innovation.\\n18. Managed correctly, investments in AI will propel our organisational capabilities, enabling us\\nto address a changing and increasing threat environment intent on harming Australians and\\nAustralia\\u2019s way of life. The scale of technology-facilitated crime continues to grow with AI\\nenabling criminality on a truly industrialised scale. Ransomware attacks on Australian\\nbusinesses will increase in both frequency and severity, with an annual increase of 15% on\\nreported attacks from the previous year. Within this environment, law enforcement resources\\nwill continue to be challenged by criminal enterprises we are attempting to contain. To\\ncounter this, successful adoption of AI will be critical. AI offers the AFP opportunities to:\\na. Create operational efficiencies in information discovery and understanding;\\nb. Improve situational awareness to inform better human decision making; and\\nc. Minimise physical and psychological risks to AFP capabilities and members.\\n19. The AFP\\u2019s current utilisation of AI has generally been limited to facilitating the transformation\\nof data from one format to another, to enhance analysis and processing needs. AI tools such\\nas Large Language Models (LLM) and broader Neural Networks present the AFP with an\\nopportunity to simplify the task of identifying potential value from large lawfully collected\\ndatasets. By speeding the discovery task, members can make decisions earlier and execute\\nthe necessary actions accordingly.\\n20. An example of AI\\u2019s practical application in law enforcement investigations is the use of AI-\\nbased translation technology, which enables the translation of foreign materials into English.\\nBy combining the strengths of AI and human expertise, we achieve a streamlined and\\neffective process, significantly enhancing our ability to handle large volumes of multilingual\\ndata.\\n21. AI adoption is swiftly transforming both communities and private industries with whom we\\npartner to combat crime, driving innovation and efficiency across diverse sectors. The\\nbanking sector, for example, has rapidly embraced AI technology to enhance both customer\\nexperience and security measures. AI\\u2019s analytical capability is harnessed to detect and\\nprevent fraudulent activities in real-time. By analysing vast amounts of transactional data, AI\\ncan swiftly identify irregular patterns such as money laundering and flag potential fraud\\nensuring customer safety and financial integrity. The AFP will work with industry partners\\nand community organisations to identify opportunities to learn, while concurrently fostering\\neducational initiatives about AI\\u2019s implications and associated risks. This knowledge will help\\nour community to protect themselves from crime, enhancing overall crime prevention\\nresilience.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 5\\nAustralian Federal Police submission / 21 August 2023\\n22. In parallel, the AFP has been working in close collaboration with the AI for Law Enforcement\\nand Community Safety Lab (AiLECS Lab) at Monash University, to not only develop AI\\ntechnologies but also to develop the underlying frameworks to ensure we apply AI in an\\nethically transparent and accountable manner. The use of AI technologies to assist in the\\nidentification and classification of child exploitation material is one example. The primary\\nobjectives are to enhance the ability of all law enforcement agencies and non-government\\norganisations to effectively and efficiently locate victims while minimising the detrimental\\nimpact of reviewing explicit material. By employing AI technologies, the reduction of harm\\nextends beyond victims, to those tasked with identifying and locating them, ultimately\\nyielding more favourable outcomes for all stakeholders.\\n23. A key pillar of our criminal justice system is that the burden of proof remains with the\\nprosecution. The prosecution must be able to satisfy the court of the authenticity, reliability\\nand accuracy of evidence. Any process for obtaining and handling evidence must not\\nundermine these principles. This remains an ongoing key point of collaboration between the\\nAFP, the Commonwealth Director of Public Prosecutions, AiLECS Lab, and our law\\nenforcement partners.\\n24. By forging strong and lasting collaborations with our partners and community stakeholders,\\nwe can harness the potential of AI in policing. These enduring partnerships foster an\\nexchange of knowledge, cutting-edge innovations, standards, and build trust, enabling us to\\ncontinually improve information discovery, accelerate operational speed, and reduce risks to\\nthe community and AFP members.\\nManagement of the use of AI by the AFP\\n25. At the heart of the AI conversation is the race between the rapid development and adaptation\\nof technology and the need for prudent governance and accountability, informed by\\ncommunity expectations. As a law enforcement agency charged with protecting Australians\\nand Australia\\u2019s interests, the AFP cannot afford to stand still while adversaries adopt this\\ntechnology to obtain a competitive advantage and cause unprecedented harm. The AFP\\nunderstands any innovation we deploy must withstand scrutiny and align with societal values\\nand public expectations. This is at the core of our need to maintain transparency.\\n26. As a responsible and trusted policing organisation, the AFP will lead by example developing\\nAI technologies through collaboration and engagement with all stakeholders to\\ncomprehensively understand future implications. The key is to proactively undertake due\\ndiligence into technologies before deployment, necessitating thoughtful planning, consistent\\nethical considerations, robust governance and oversight to ensure that AI serves the greater\\ngood and aligns with societal values.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 6\\nAustralian Federal Police submission / 21 August 2023\\n27. The AFP supports ongoing engagement with the community to ensure Australia has the right\\ngovernance settings to respond to the rapid development of AI. This extends to the\\ncomplexities of harmonising governance frameworks with those used globally or by our\\nforeign law enforcement agency (FLEA) partners, to enable a shared commitment to ethical\\nAI practices, ultimately enhancing law enforcement capabilities across borders. The AFP will\\ncontinue to leverage law enforcement structures such as the, Five Eyes Law Enforcement\\nGroup (FELEG) Interpol and EUROPOL to navigate the complexities of sector-specific AI\\nutilisation. Specifically, our organisation remains dedicated to implementing the Australia\\nNew Zealand Policing Advisory Agency (ANZPAA) AI Principles that have agreed by all\\nAustralian and New Zealand Police Commissioners.\\n28. The dual-use nature of AI presents significant challenges for policing, raising concerns about\\npotential misuse and its impact on public safety and trust. AI technologies offer both\\nbeneficial and harmful applications, making regulation complex. The use of AI for policing\\nraises ethical and legal questions on privacy, bias and accountability. The seamless\\nintegration of AI, imperceptible to the human eye, fundamentally alters the security\\nlandscape by enabling the capability to comprehend information beyond an individual\\nhuman\\u2019s capability.\\n29. The AFP recognises AI is another tool, and it will not replace the requirement a human must\\nremain accountable for any decision that affects on the rights of another human. While AI\\ncan assist decision-making, the AFP recognises policing is a human and societal contract\\nthat will always require human judgement and interaction. Policing is deeply connected to\\nsociety and must reflect the values, norms and expectations of the community it serves and\\ncritically requires human oversight and accountability. While industry may be moving\\ntowards granting autonomy to AI for operational efficiency, the AFP will use AI as an enabler,\\nnot a decision-maker. Maintaining human involvement in decision-making is a crucial\\ndifferentiator for the police, ensuring responsible and ethical AI adoption to prioritise the\\nwellbeing and safety of the community and our members.\\n30. To achieve this, the AFP is prioritising the development of five key enabling aspects of AI\\ntechnologies:\\na. Governance (accountability and human oversight)\\nb. Internal policies and frameworks (responsibility)\\nc. Technical leadership (technical excellence)\\nd. Training (competency in use and trust in technologies)\\ne. Partnerships (collaboration and transparency)\\nGovernance\\n31. The AFP is prioritising effective governance to guide the implementation of AI technologies,\\nadhering to general regulations and legal frameworks that apply across industries. In\\nparticular, the AFP will ensure compliance with the Privacy Act. By reporting on AI initiatives,\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 7\\nAustralian Federal Police submission / 21 August 2023\\ndata usage, and privacy measures, the AFP will demonstrate its commitment to responsible\\nAI practices reflective of community expectations and values.\\n32. The AFP will continue to remain accountable through reporting to oversight agencies,\\nincluding the Commonwealth Ombudsman, to ensure our use of technology is aligned and\\nadheres to relevant legislation and sector-specific regulations.\\nInternal policies and building oversight AI framework\\n33. Through enhanced compliance and governance frameworks, the AFP will ensure ethical and\\nresponsible AI use into the future. These enhancements in line with the Commonwealth\\nGovernment\\u2019s legislative and policy requirements and human oversights will continually be\\nstrengthened through our agency\\u2019s commitment to continuous improvement.\\n34. To strengthen responsible AI use, the AFP will prioritise the establishment of an AI Oversight\\nFramework aligned with standards, facilitating repeatability, validation, verification, and both\\ninternal and external assessment. This will be built into the AFP\\u2019s existing strategic\\ngovernance arrangements. As we have demonstrated in building world-leading Forensics\\ncapabilities and frameworks, the AFP will apply the same approach by embodying\\nrobustness and oversight, fostering trust at organisational, jurisdictional, and community\\nlevels. By adhering to this comprehensive framework, the AFP will ensure the integrity of AI\\napplications and other emerging technologies (such as those in the space and robotics field)\\ninstilling confidence in our stakeholders and reinforcing our commitment to responsible\\nadoption of emerging technology.\\n35. Recognising the dynamic nature of risk management and post-deployment oversight for AI, it\\nis crucial the AFP\\u2019s risk management approach is continuously iterative and runs throughout\\nthe entire lifecycle of any AI system. The significance of regular, systematic updates and\\ncomprehensive audits cannot be overstated. As the technology evolves and the environment\\nin which AI operates shifts, staying attuned to potential risks and ensuring compliance with\\nethical standards demand constant vigilance.\\nTechnical leadership\\n36. Technical leadership plays a vital role in AFP\\u2019s responsible adoption of AI. Our technical\\nleaders and specialists possess the expertise and skills to guide the implementation of AI\\ntechnologies. Technical leadership ensures AI is governed, developed and deployed ethically,\\naddressing biases and risks, while driving innovation and maintaining compliance with\\nregulations.\\n37. The AFP has conducted strategic workforce planning, which sets out our key areas of focus\\nfor the next five years, committing to actions through a series of targeted strategies. The\\nAFP will commit to delivering a workforce that is skilled for today and tomorrow, configured\\nfor operational agility, comprised of engaged and supported employees and shaped by\\ncontemporary, data-driven strategic decisions. The implementation of this strategy will play a\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 8\\nAustralian Federal Police submission / 21 August 2023\\npivotal role in shaping the AFP\\u2019s technical leadership, ensuring the AFP has the right level to\\nlead and navigate the complex landscape of AI.\\nTraining\\n38. The AFP will explore utilising internal and external training programs to equip our entire\\nworkforce, including frontline members, with the essential skills to utilise AI technologies\\nappropriately. It is essential all employees can recognise where AI exists and understand its\\nlimitations and risks, and determine its appropriate use in accordance with internal and\\nexternally adopted policies and frameworks, in combination with their own knowledge and\\nskills. Having comprehensive training programs will empower all our employees to\\nresponsibly and confidently use AI technologies, cultivating a culture of accountability and\\ntrust in the benefits of AI for policing.\\n39. As AI technologies are integrated into policing practices, our frontline members may\\nencounter situations where AI-driven evidence becomes crucial in court proceedings.\\nEquipping the workforce, including frontline members and specialists with essential AI skills\\nwill become paramount, making complex AI mechanisms understandable and transparent to\\nthe court and the parties involved.\\nPartnerships\\n40. In our policing efforts, partnering with industry and comprehending the AI technologies we\\nacquire is vital. This collaboration ensures the AI tools align with our ethical standards and\\npolicing objectives. Understanding the inner working of AI systems empowers us to make\\ninformed decisions, considering potential biases and limitations.\\n41. The AFP will continue to strengthen our partnerships with academia and the AI industry\\nthrough transparent dialogue and foster collaborative relationships, aiming to harness AI for\\npolicing purposes effectively. Our partnership with Monash Universities AiLECS Lab\\nexemplifies this, with its objective of creating a safer community through effective, ethical\\nand transparent AI use.\\n42. The AFP notes international partnerships present significant opportunities for AI adoption\\nthrough facilitating the exchange of knowledge and capabilities. Concurrently, it is vital that\\nthe AFP assess governance frameworks with those used globally or by our key FLEAs.\\nAchieving alignment while respecting differing legal and societal frameworks is crucial for\\nresponsible AI adoption. Collaboration and transparency with our international partners\\nfoster trust and enable a shared commitment to ethical AI practices, ultimately enhancing\\nlaw enforcement capabilities across borders.\\n43. The AFP will leverage existing structures such as the ANZPAA, FELEG, Interpol and\\nEUROPOL to assess governance frameworks and address global AI complexities and sector-\\nspecific utilisation.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 9\\nAustralian Federal Police submission / 21 August 2023\\nConclusion\\n44. Investments in AI will propel our organisational capabilities, enabling us to address a\\nchanging threat environment harming Australians and Australia\\u2019s way of life. Managed\\ncorrectly, the AI will offer the AFP opportunities to create operational efficiencies, improve\\nsituational awareness to inform better human decision making, and minimise risks to the\\npublic safety, AFP members and capabilities.\\n45. Responsible adoption of AI in policing requires a multifaceted approach, which the AFP is\\nassessing the opportunities to strengthen five key enabling components: governance,\\npolicies, technical leadership, training and partnerships.\\n46. Collaborating internationally demands transparent dialogue to assess governance\\nframeworks and address diverse legal and ethical considerations. Remaining accountable is\\nvital, and achieved through oversight governance and regulations that uphold and demand\\nresponsible AI practices. Building an AI Oversight Framework aligned with international\\nstandards and supported by internal policies will provide clarity and guidance in ethical AI\\nadoption.\\n47. Fostering technical leadership in the AFP workforce empowers informed decision-making,\\ninnovation, and effective implementation, ultimately enhancing policing capabilities and\\nensuring public safety in our communities.\\n48. The AFP will explore opportunities to equip our workforce with comprehensive training to\\nensure adept navigation of AI technologies, instilling trust in their use and fostering a culture\\nof accountability. Partnering with industry will enable the AFP to understand AI technologies,\\nensuring alignment with our ethical standards and policing objectives \\u2013 with the\\ncommunity\\u2019s expectations of us at the front of mind.\\n49. The AFP welcomes the opportunity to engage further on regulatory and governance\\nresponses to create safe and responsible AI in Australia.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transparency_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"transparency of AI in the delivery of health care is essential and this should be consistent across public and private sectors.\\nThe Department supports greater ethics consideration when using data for AI purposes, particularly as it relates to health outcomes to enable maximum benefits while ensuring there is sufficient trust in the outcomes and how it affects individuals and society. For areas with direct impact on health outcomes of individuals, there is less tolerance for risk and the response should be proportional to the possible impact.\\nThe Department supports the current approach by the Therapeutic Goods Administration (TGA) who regulate products that are intended for medical use including software (that incorporates AI), with a robust regulatory framework for software based medical devices. The framework addresses risks associated with AI and applies to any software included with, or that is a part of, a medical device that is used for diagnosis, prevention, monitoring, treatment, alleviation of disease, injury or disability.\\nThe TGA regularly consults on its regulations to ensure it considers emerging technologies (and risks) to ensure the regulations remain fit for purpose and continue to safeguard Australian patients. The TGA publicly consulted on software including AI in 2019 and 2020 \\u2013 and published updated specific guidance including clinical evidence and performance requirements in early 2021. Further information about the framework and risk classification with some examples is included in the attached Health response\\n[Regulation of Software-based Medical Devices - Info sheet for DISR July 2023].\\nThe Department does not recommend banning the use of high-risk AI applications, rather DISR may consider developing guidance on how to use controls to mitigate risk appropriately. The Department strongly advocates for a risk-based approach in relation to AI and recognises that it may need to be mandatory for moderate to high-risk applications in health and aged care. This provides flexibility to ensure regulatory burden and oversight align with the potential risk of a particular activity, and to reduce burden and promote innovation for low-risk AI applications. Key elements of a risk-based approach should include clear definitions of consequences of the risk and objective, clearly articulated criteria to determine the risk level and how to appropriately deal with the risk. Leveraging existing risk- based approaches, integrating AI-specific risks and controls into risk management, and employing a mix of regulatory and non-regulatory frameworks can support the development of a risk-based approach for addressing AI risks.\\nThe Department recommends DISR considers, in partnership with appropriate regulators such as the\\nNational Data Commissioner and the Information Commissioner, the development of guidelines for\\nData Impact Assessments (DIA) as part of AI assessments. The DIA could be mandatory for organisations applying AI above a set impact threshold, similar to Privacy Impact Assessments. The DIA could take a multi-faceted approach taking into account the purpose, explainability, ethics, sensitivity, sovereignty, security, and impact to provide a holistic assessment of risk and need for regulation.\\nAdditional input and detail on the discussion paper has been provided via direct responses to the\\n20 discussion questions. This input differentiates between issues directly related to the Department in comparison to the broader Australian Healthcare System. i\\nCenter for AI Safety (CAIS) ii\\nhttps://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext and https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00237-2/fulltex\\n2|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nSafe and Responsible AI in Australia \\u2013 Discussion Paper August 2023\\nQuestion Department of Health and Aged Care Australian Healthcare System\\nDEFINITIONS\\n1 Do you agree with the Whilst a high-level definition could be useful, the way AI is used is context specific, as different No objection.\\ndefinitions in this discussion sectors have differing needs.\\npaper? If not, what The Therapeutic Goods Administration (TGA) already has established definitions related to AI for\\ndefinitions do you prefer medical (therapeutic) use which are aligned with the definitions in \\u201cMachine Learning-enabled\\nand why? Medical Devices: Key Terms and Definitions\\u201d published by the International Medical Device\\nRegulators Forum (IMDRF) in May 2022.\\nThe Australian Commission on Safety and Quality in Health Care (ACSQHC) supports the use of\\nthe International Organisation for Standardization definitions.\\nIt is recommended to also include a definition for Automated Decision Making (ADM) to avoid\\nmisinterpreting ADM as fully autonomous. From a legislation perspective, it is recommended to\\nkeep the definition as technologically neutral as possible and consider future use-cases for AI to\\nhelp maintain relevance.\\n2 What potential risks from AI The Department suggests that there is no clear pathway for the sharing of sensitive unit record In considering the development of AI\\nare not covered by health and aged care data with commercial entities within our current legislative frameworks. regulation we need to consider a wide\\nAustralia\\u2019s existing The existing regulations only permit the disclosure of critical departmental data, such as the array of clinicians and professional bodies\\nregulatory approaches? Australian Immunisation Register, Medicare Benefits Scheme, and Pharmaceutical Benefits across the health and aged care sectors and\\nDo you have suggestions for Scheme data, to a limited number of trusted Commonwealth agencies, including the Australian their risk appetites.\\npossible regulatory action to Bureau of Statistics (ABS) and the Australian Institute of Health and Welfare (AIHW). Similar Over the past few years, lots of work has\\nmitigate these risks? disclosures to commercial entities are not permitted under either the primary legislation or the been undertaken to strengthen regulation\\nData Availability and  Transparency Scheme (which does not cover private sector firms). and safeguards of Australia\\u2019s critical\\nTo effectively manage risks and protect the integrity of healthcare information while harnessing infrastructure. Due diligence to ensure that\\nthe benefits of AI, the Department advocates for comprehensive regulatory reforms and there is no erosion of other forms of\\nproposes integrating AI-specific regulations within existing Acts. These reforms would legislation would be essential.\\nnecessitate mandatory training for healthcare professionals and adherence to specific AI-related\\nprofessional standards, ensuring that AI is utilised responsibly and ethically within the health\\nsector.\\n1|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nThe Department emphasises the need to implement flagging mechanisms or additional security\\nchecks for medical professionals and researchers seeking access to sensitive data. This would\\nensure accountability and reduce potential security risks associated with the access and use of\\nsensitive health information.\\nAddressing bias in AI algorithms is of utmost importance to avoid disproportionate impacts on\\nvulnerable populations, including First Nations and CALD and LGBTQIA+ and people with a\\ndisability. Data sets on which AI tools are trained, do themselves have inherit bias, (ie male\\nskewed, no comprehensive data on women, gender reduced to the binary) making some groups\\n\\u201cinvisible\\u201d to the algorithm.\\nPrejudice cannot be coded out of a model, but proper representation for minority groups can be\\ntaken into considered in setting up AI modelling. To support the empowerment of First Nations\\ncommunities, The Department stresses the significance of adhering to Priority Reform 4 of the\\nClosing the Gap Agreement. This reform aims to grant First Nations people the ability to collect,\\nanalyse, and use data in meeting their community's unique needs and priorities. Respecting data\\nsovereignty rights and fostering genuine partnerships between the government and First Nations\\npeople are critical principles that must be incorporated into the development of AI technologies\\nand regulatory frameworks. Complying with the CARE principles of Indigenous Data Governance\\nfurther reinforces the commitment to fair and ethical AI practices.\\nHaving approaches for ongoing monitoring and potential re-training of AI technologies and\\nmodels is essential to ensure their relevance and performance over time. Implementation of an\\nAI tool without ongoing review can result in performance deterioration over time due to data\\ndrift, where the data used to train the model is different to the data where the model is being\\napplied. This could have serious implications if the AI tool is being used in a high-risk sector such\\nas healthcare, and evidence suggests it is already a concern in medical machine learning\\ndeployment1. The Department would like the longer-term management and use of AI tools be\\nconsidered at project inception, including responsibilities for managing the tool, and\\nmechanisms for detecting and mitigating data drift and performance degradation.\\nThe Department emphasises the significance of AI applications being available in multiple\\nlanguages, ensuring inclusivity and accessibility for diverse populations, particularly culturally\\nand linguistically diverse (CALD) communities. Addressing potential racial discrimination in AI,\\n1\\nhttps://www.birpublications.org/doi/10.1259/bjr.20220878\\n2|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission particularly concerning recidivism predictions, demands meticulous examination and regulatory intervention to uphold fairness and justice.\\nThe TGA have been regulating products that are intended for medical use including software\\n(that incorporate AI) since 2002, using a robust regulatory framework for software based medical devices. The framework addresses risks associated with AI, and applies it to any software included with, or that is a part of, a medical device that is used for diagnosis, prevention, monitoring, treatment, alleviation of disease, injury or disability. Regulatory requirements are technology agnostic and apply regardless of whether the product incorporates components like AI, chatbots, cloud, mobile apps or other technologies.\\nThe TGA regularly consults on its regulations to ensure it considers emerging technologies (and risks) to ensure the regulations remain fit for purpose and continue to safeguard users. The TGA publicly consulted on software including AI in 2019 and 2020 \\u2013 and published updated specific guidance including clinical evidence and performance requirements in early 2021. The TGA has also consulted with specific groups such as MSIA and relevant health professional colleges on specific types and uses of software.\\nThe TGA has a range of regulatory actions it takes when software or AI is not performing as intended or if a product is being supplied without appropriate regulatory approval.\\nFurther information about the framework and risk classification with some examples is included in Attachment C of the Departments response [Regulation of Software-based Medical Devices -\\nInfo sheet for DISR July 2023].\\nThe National Mental Health Commission (NMHC) would like to ensure the development and utilisation of AI across Australian society does not result in people who experience mental ill- health being treated unfairly, or in other harms to the mental health and wellbeing of the\\nAustralian community. The Department highlights the specific risks associated with AI for individuals experiencing suicidality. Past incidents where AI inadvertently facilitated access to harmful information underscores the need for vigilance and prompt regulatory action to mitigate potential risks.\\nThe Department notes the discussion paper did not outline regulation regarding the use of AI in the health sector, including in supporting/replacing health workforce and points out there is a risk of AI decision making being relied upon in remote settings versus human decision making supported by AI in urban areas. Ensuring equitable access to healthcare, especially for rural and remote communities, requires the responsible integration of AI support. The Department\\n3|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nrecommends regulations that cover various aspects of AI's impact, including clinical decision-\\nmaking, medical report writing, pathology, and health administration. The Medical Workforce\\nPolicy and Strategy underscores the importance of flexible and adaptable regulations,\\nconsidering the rapid pace of AI technology evolution.\\nThe Australian Digital Health Agency (ADHA) suggests that AI presents a risk to the maintenance\\nof quality healthcare information, which is currently not covered by Australia\\u2019s existing\\nregulatory approaches. The maintenance of healthcare information is currently governed by\\nprofessional standards and regulatory frameworks that promote accuracy, quality, and handling\\nof personal health information, such as the My Health Records Act 2012, Healthcare Identifiers\\nAct 2010 and Privacy Act 1988. None of this legislation currently contemplates risks from AI nor\\nthe benefits, and although the My Health Records Act 2012 does allow for decision making using\\na computer program, there is no specific instruction on automated decision-making.\\nThe Government is considering reforms to each of these Acts so there are opportunities to\\ninclude AI-specific regulation as necessary. Current mitigations would be limited to relying on\\nhealthcare professionals undergoing mandatory training and have them meet a set of\\nprofessional standards. Another potential risk from AI that is not covered by Australia\\u2019s existing\\nregulatory approaches relates to the use of AI in policy development and administration in the\\nAustralian Public Service. Clarity and disclosure around the use of AI data and algorithms, and\\nthe limitations of these methods, is crucial when AI outcomes are used to develop policy. The\\nAgency welcomes the recently published Interim guidance for agencies on government use of\\ngenerative AI platforms and recommends the development of more detailed guidance in the\\nfuture, particularly in relation to policy development and administration.\\nThe Department suggests establishing nationally agreed AI principles as well as nationally agreed\\n3 Are there any further non- \\u2022 Likely need for public Education\\nregulatory initiatives the ethical, clinical and technical standards for AI. It is important to develop these national principles campaigns to provide education of the\\nAustralian Government and standards using a transparent, co-designed and consensus-based approach (and leveraging risks and benefits of the use of AI to\\ncould implement to support international standards where appropriate) to support community trust and confidence in AI. It ensure community and clinician\\nresponsible AI practices in acknowledges efforts by the NSW Government in developing an AI Assurance Framework which awareness and trust levels remain high.\\nAustralia? mandates ethical principles to govern bespoke AI systems. It would be appropriate to consider if \\u2022 Consider establishing controlled\\nPlease describe these and the NSW Framework can be applied nationally. environments for developers to test AI\\ntheir benefits or impacts. systems to identify risks and mitigation\\nThe Department encourages partnerships with academic researchers and centres of excellence,\\nstrategies before AI systems are\\nsuch as the National AI Centre, and close monitoring of the Responsible AI Adopt Program, CSIRO\\nreleased for use by Australians.\\nData61, and UTS Australian AI Institute to facilitate innovation, knowledge sharing, and resource\\nutilisation. It also encourages an approach to AI governance that considers publicly available\\n4|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission information both nationally and internationally. It will be important to learn from international \\u2022 Suggest encouraging positive incentives examples such as the European Union (EU) and Canadian approach and incorporating for compliance \\u2013 accountability often international guidelines, standards, and certifications into a national AI framework will ensure build on penalties but incentives to responsible adoption of AI technologies. Supporting AI developers and users is a priority, and reinforce safe and responsible use of AI diligently investigating tools developed by countries like the US and Singapore to identify and could be introduced.\\nmitigate AI-related risks effectively should be considered.\\nThe work of the ACSQHC may assist in supporting the operationalisation of the 5th principle of the AI Ethics Framework - Reliability and safety - in the context of healthcare safety and quality.\\nAs part of its work plan, the Commission is developing resources to assist health services to evaluate and assess AI before the widespread uptake of these technologies. The resources aim to enable the safe implementation of AI into clinical practice and drive measurable improvements in the quality of patient care and outcomes.\\nThe Department recognises the potential need for additional regulatory and governance responses to ensure appropriate safeguards are in place and suggests accrediting the overarching governance processes of vendors developing AI technology, along with their device and software offerings, to instil trust and confidence in AI applications.\\nThe use of software and AI that performs a medical purpose, can be enhanced through further education of relevant health professional colleges and boards, higher education systems and training. Broader benefits could be gained by providing more accessible consumer and other stakeholder education as part of the government response to AI practices. These communication activities should include ensuring those products that are used for medical purposes have relevant TGA approval and that consumers understand the implication of AI and use of their personal information. There are many new stakeholders entering the market who are unaware of existing regulatory obligations and who do not fully understand their ongoing responsibilities.\\nThe TGA partners with ANDHealth to deliver webinars and education initiatives targeted to new entrants including those seeking to commercialise their product.\\nWithin the Australian Public Service (APS), the Government could consider performing an audit of current automated processes that use AI in order to promote  transparency and ensure AI is being used safely and responsibly within the APS.\\nTo effectively manage AI-related procurements, upskilling of government officials will be required and close monitoring of procurements will be essential to uphold compliance standards and mitigate potential risks associated with AI implementation.\\n5|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nEngagement of the health and aged care sector will be crucial to ensure equitable access to\\ntraining and education related to AI technology, to facilitate wider acceptance and\\nunderstanding.\\n4 Do you have suggestions on Whilst there is considerable activity related to AI occurring across government, more \\u2022 As indicated in the paper, there are a\\ncoordination of AI consideration is required to understand how AI will apply in the health and aged care contexts as range of existing regulatory\\ngovernance across there are unique ethical, legal, and regulatory challenges that must be addressed. Existing frameworks that are relevant to AI\\ngovernment? regulatory frameworks and legislation are not sufficiently developed for the full utilisation of AI governance. However, there would be\\nPlease outline the goals that and are likely to require significant reform. This is particularly so in relationship to risks to value in coordination and information\\nany coordination human health and around privacy and trust in the release of sensitive health data for use in the sharing in response to related issues.\\nmechanisms could achieve development of AI tools. For example, privacy, copyright and\\nand how they could To achieve a cohesive approach, coordination mechanisms need to establish consistency and online safety issues associated with the\\ninfluence the development coherence in AI policies and regulations across government departments and agencies. The data used to train models will likely\\nand uptake of AI in Australia. coordination of AI governance also facilitates the effective sharing of knowledge and resources have similar intelligence and inquiry\\nand encourages inter-agency cooperation. Government agencies could leverage diverse needs and would benefit from relevant\\nexpertise and experiences to address challenges and capitalise on AI's opportunities. This instrumentalities having clear and\\nknowledge-sharing approach nurtures innovation, accelerates AI adoption, and ensures that the strong channels for information sharing\\ntechnology aligns with Australia's unique needs. Common principles and guidelines will minimise and referral of issues.\\npotential inconsistencies and create an overall strategy for AI adoption in Australia.\\nSector-specific governance of AI in healthcare is essential given the unique risks, challenges and\\nopportunities posed by AI in healthcare. The Australian Alliance for Artificial Intelligence in\\nHealthcare\\u2019s Roadmap for Artificial Intelligence in Healthcare for Australia could help inform\\nAustralia\\u2019s approach to managing the opportunities and risks that AI brings. Building public trust\\nand confidence in AI technologies will be important to ensure the uptake of AI solutions.\\nStreamlining procurement processes related to AI technologies is also another crucial outcome\\nof coordination mechanisms. A cohesive framework could guide government officials in AI-\\nrelated procurements, ensuring compliance with ethical standards and mitigating potential risks.\\nAs a result, the smooth implementation of AI applications becomes feasible, driving effective and\\nefficient use of the technology across government operations. Coordination mechanisms open\\navenues for cross-sector collaborations, bringing together government, academia, industry, and\\nother stakeholders. This inclusive approach fosters strategic partnerships and joint initiatives,\\nleading to transformative research and the development of AI solutions tailored to diverse\\nsocietal challenges.\\n6|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nDISR may wish to consider options for governance that supports ongoing inter and intra-\\ngovernmental engagement on matters such as AI that are not industry specific \\u2013 such as privacy\\nor cybersecurity. The Department and the TGA already works with other governance bodies such\\nas Office of the Australian Information Commissioner (OAIC) and the Australian Cyber Security\\nCentre respectively, to ensure a cohesive approach to regulation.\\nThere is an opportunity for the Commonwealth to co-design with jurisdictions a national AI\\nethical and governance framework, in consultation with industry experts and the public. The\\nnew national framework would refresh the existing Commonwealth AI Ethics Framework and\\ncould be expanded to cover more specific guidance for key sectors in the economy where AI is\\nalready having, and will have, a significant impact, including healthcare. Such a framework could\\nform the basis to support for future self-regulation or government legislation.\\nRESPONSES SUITABLE FOR\\nAUSTRALIA\\n5 Are there any governance The Department is actively involved in ongoing surveillance of the international landscape with \\u2022 DoHAC is actively involved in ongoing\\nmeasures being taken or the view to identifying new and emerging governance measures, particularly in the EU, UK, surveillance of the international\\nconsidered by other Canada, and the USA. There is a need to understand the contextual differences between what is landscape with the view to identifying\\ncountries (including any not acceptable in these counties versus in Australia and learn from their experiences and evaluation new and emerging governance\\ndiscussed in this paper) that of new initiatives. measures, in particular in the EU, UK,\\nare relevant, adaptable, and The TGA maintains a close relationship with other comparable regulators to ensure Canada and the USA.\\ndesirable for Australia? harmonisation of approaches. New requirements for software as a medical device (including AI) There is a need to understand the\\nare emerging in different jurisdictions including Europe, Canada, UK and the USA. The European contextual differences between what is\\nMedical Device Regulations (EU MDR 2017/745) has also introduced new requirements, acceptable in these counties versus in\\nincluding classifications specific for software as a medical device as part of a risk-based Australia and learn from their\\napproach. The European rule is consistent with the IMDRF recommendations. Since 2013, the experiences and evaluation of new\\nIMDRF (covering 10 regulators covering all major markets globally) has had in place, a dedicated initiatives. Consultation with the health\\nworking group reviewing Software as a Medical Device (SaMD), and AI \\u2013 and publishes technical and aged care sectors will be essential\\ndocuments. The IMDRF undertakes global public consultation on all its work and participates in to ensure that governance measures\\nInternational Standards Organisation (ISO) standards, including those relating to SaMD. are fit for purpose.\\nA governance measure that is not discussed in the consultation paper that might help inform\\nAustralia\\u2019s approach to AI is the United States' proposed Algorithmic Accountability Act 2022.\\nThis legislation aims to establish a regulatory framework for assessing and mitigating bias and\\n7|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\ndiscrimination in AI systems used by large entities. It contains principles that might help Australia\\naddress algorithmic bias and promote fairness in AI applications.\\nConsultation with the health and aged care sectors will be essential to ensure that governance\\nmeasures are fit for purpose.\\nTARGET AREAS\\n6 Should different approaches No. There should be no differences between use in private or public sector for software and AI \\u2022 In broad terms, the approaches to\\napply to public and private used for medical purposes. public and private sector use of AI\\nsector use of AI Under existing arrangements, the private sector cannot obtain health data for AI research in should be similar in that the\\ntechnologies? preparation for commercial purposes. The private sector can however with universities and they overarching principles should be similar\\nIf so, how should the can justify public interest considerations. and the risks posed by each sector\\u2019s\\napproaches differ? use are similar. However, the\\nGovernment public health data is largely administered (ie. without consent to gather data for regulatory framework should be alive\\nMedicare and PBS) and the use of this data in potential AI applications raises additional ethical to the different kinds of conflicts of\\nconsiderations that warrant thorough review and evaluation. Despite the potential risks, the use interest each sector may have in using\\nof sensitive personal information in the health and aged care sectors can provide a significant AI technologies. In the case of the\\npublic benefit by improving policy and service delivery. Balancing these benefits against the private sector, the typical concern is\\ninherent risks becomes crucial in contemplating specific regulations for AI activities in this that the profit motivation will lead to\\ndomain, ensuring that they do not excessively burden existing frameworks and hinder genuinely misuse of these technologies and\\npublic-interested activities. regulatory arrangements are crafted\\nThere are already sophisticated frameworks applied to the public sector that aim to ensure its accordingly.\\nfocus on the public interest (including reconciling conflicts between ends and means), for \\u2022 In the case of the public sector, the\\nexample, parliamentary oversight and legislation, audit and other investigating bodies, FOI and concern is that there may sometimes\\n transparency regimes, and public sector codes of conduct. As a result, there appear to be be a conflict between ends and means,\\ndifferences in the uses broadly considered acceptable by the public sector, including allowing for that is:\\nthe public sector to engage in some higher risk applications of these technologies that would not o on the one hand, a public\\nbe generally considered acceptable by the private sector. body\\u2019s objectives (ends), which\\nshould be, by definition, in the\\nSensitive personal information can be used for the purposes of improving policy and service\\npublic interest, and\\ndelivery in the health and aged care sectors, which delivers a public benefit that can offset the\\no on the other hand, the public\\nrisks inherent in using such information. The key challenge in considering any specific regulation\\ninterest in the ways (means) in\\nof AI activities in this context, is that they do not create an excessive cumulative regulatory\\nwhich public bodies conduct\\nthemselves being fair, honest,\\n8|P a g e\\nDepartment of Health and Aged Care\\nSafe and Responsible AI in Australia Submission\\nburden atop existing frameworks such that it is difficult to pursue genuinely public interested ethical and in line with natural\\nactivities. justice principles.\\nMaintaining consistent ethical principles across all areas where AI technologies are deployed is\\ncritical particularly in healthcare, given the frequent transitions of care between public and\\nprivate health services, as well as between care settings. These transitions involve the transfer of\\nsensitive health information, demanding careful consideration of the interoperability of AI\\ntechnologies to facilitate these transfers securely and efficiently.\\n7 How can the Australian Australians have high expectations of the Department in the handling of public information and \\u2022 Provide funding for grants through the\\nGovernment further support building public trust will be critical. This requires careful consideration of data sharing practices Australian Government\\u2019s $20 billion\\nresponsible AI practices in its to determine what data can be shared, with whom, and under what circumstances. AI and Medical Research Future Fund (MRFF)\\nown agencies? ADM's reliability is heavily dependent on the quality and fairness of the data on which it is Applied Artificial Intelligence Research\\ntrained, and health and aged care data often exhibits strong gender and cultural biases, in Health.\\nnecessitating substantial work to improve data quality and comprehensiveness before it can be \\u2022 AMA reports there is currently no\\nutilised in real-world applications. Efforts are underway to develop standard authorisation national framework for an AI ready\\nprovisions that facilitate greater data sharing and access. While synthetic data is often suggested health workforce. Use AI requires\\nas a remedy for privacy concerns, it is essential to recognise that its creation is resource- retraining of the workforce, retooling\\nintensive and may still require some real data. If The Department legislation requires reform, the health services and transforming\\nagency is prepared to contribute to this process. workflows. The health systems is\\nalready resource constrained and such\\nWith the speed of emerging technology, it will be critical for government to ensure that adoption changes will not happen without\\nof any new technology will not compromise public safety. Government can continue to support strategic investment (AMA Journal 13\\nresponsible AI practices in its own agencies through establishment of guidelines for best practice June 23).\\nand communication across portfolios to ensure a common understanding and implementation of\\npriorities, rules, best practice, and investment where required.\\nWhen evaluating AI model performance, considerations for vulnerable groups and clinicians are\\nvital to ensure fairness and equity in the outcomes. To continuously improve the AI systems'\\nimpact and performance on the health workforce, regular evaluation and monitoring are\\nessential. This includes assessing the effectiveness of AI applications, identifying, and addressing\\nbiases or unintended consequences, and adapting regulatory frameworks as needed.\\nTo support health pr\",\n          \"transparency and explainability, contestability, and discrimination.\\nRECOMMENDATION 10:\\nTo further support responsible AI practices in Australian Government agencies, KPMG recommends consideration of defining principles and boundaries for ethical data sharing practices and an assessment of the impact on human rights.\\nRECOMMENDATION 11:\\nKPMG suggests it would be useful to consider the introduction of transparent disclosure obligations that require organisations to disclose why an AI use case was deemed to have complied with the particular ethics framework.\\nRECOMMENDATION 12:\\nKPMG suggests the regulatory framework should be founded on a core set of principles, ideally based on current established principles (such as: safety, security, robustness, fairness,  transparency and accountability). These principles should be able to be translated into effective assessment and assurance framework tools that organisations can embed.\\nRECOMMENDATION 13:\\nKPMG recommends a range of initiatives that may increase public trust in AI deployment, including the development of a certification regime for responsible AI, embedding data quality requirements, public education campaigns, and other measures such as licencing, auditing, impact assessment and regulatory oversight.\\nRECOMMENDATION 14:\\nKPMG considers that the implementation of assurance mechanisms would facilitate greater trust in AI systems. The proposed EU AI Act requires high-risk applications of AI and ADM to be approved through a conformity assessment, and it would be worth considering whether aligning to this approach would be suitable for Australia.\\nRECOMMENDATION 15:\\nKPMG considers that the government could usefully explore with industry the development of an initial human rights risk assessment to determine an AI project's level of risk to people upfront and ensure the appropriate level of governance oversight and remediation is applied.\\nRECOMMENDATION 16:\\nKPMG considers that self-regulation may ultimately not be sufficient, and agreement on regulatory goals is necessary before effective self-regulation can occur.\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n8 | Document title\\nSection 2:\\nKPMG insights\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n9 | Safe and responsible AI in Australia\\nKPMG insights\\nDefinitions underpins the application and subsequently use\\ncase of that application. However, the\\ngovernment should consider the impact of the\\n1. Do you agree with the definitions in proposed definition on the systems that would\\nthis discussion paper? If not, what be in scope for regulation on a risk based\\ndefinitions do you prefer and why? approach.\\nThe discussion paper defines AI as an\\n2. What potential risks from AI are not engineered system that generates predictive output without explicit programming and lists covered by Australia\\u2019s existing machine learning, generative AI models regulatory approaches? Do you have\\n(including large language models, multimodal suggestions for possible regulatory foundation models) and automated decision action to mitigate these risks?\\nmaking (ADM) as examples.\\nAppropriate legal and regulatory frameworks are\\nThis definition is consistent with the definitions critical to providing individuals, businesses and previously used by KPMG, however given the governments with increased certainty about the rapidly advancing nature of this technology, it risks and benefits of adopting AI and ADM may be useful to consider a broader definition. technologies, which in turn will encourage\\nThe government could consider the following increased uptake and investment.\\nexamples when finalising its definition, which KPMG supports a regulatory approach that is also capture autonomy versus automation: simple and clear in order to achieve the right\\n\\u2022 Any artificial system that performs tasks balance between appropriate safeguards and\\nunder varying and unpredictable enabling innovation. Whilst regulation will help\\ncircumstances without significant human enable trust, doing so without being sensitive to\\noversight, or that can learn from experience what already exists risks limiting the uptake of\\nand improve performance when exposed to the technology and driving out innovation due to\\ndata sets. 2 a regulatory landscape that could be too\\ncomplex to manage or navigate.\\n\\u2022 Artificial intelligence system\\u2019 (AI One of the key challenges for private and public\\nsystem) means a system that is designed to organisations in the deployment and use of\\noperate with a certain level of autonomy and responsible AI arises from the multiplicity of\\nthat, based on machine and/or human- guidelines, frameworks, good practices and\\nprovided data and inputs, infers how to toolkits developed by the Australian\\nachieve a given set of human-defined Government as well as national and\\nobjectives using machine learning and/or international policy makers. The development\\nlogic- and knowledge based approaches, and adoption of a simplified and interoperable\\nand produces system-generated outputs regulatory framework for AI should be\\nsuch as content (generative AI systems), accompanied by the identification of a leading\\npredictions, recommendations or decisions, regulatory body responsible for developing and\\ninfluencing the environments with which the enforcing AI legislation.\\nAI system interacts. 3\\nGaps in regulatory guidance on how existing\\nKPMG also notes that two common types of AI laws apply to AI systems are generative AI and predictive AI.\\nBoth use neural network machine learning but Existing legislative frameworks that aim to are not the only systems that use machine address consumer and other individual harms learning. Therefore, it may be necessary to should be considered as a starting point, noting identify the underlying technology of neural that the current frameworks are generally not network machine learning, or the system-level yet adequately adapted to the use of AI and capability of generative/predictive AI that then ADM technologies and their potential adverse\\n2\\nKey AI terminology \\u2013 United States IT Modernization 3\\nEuropean Union \\u2013 Artificial Intelligence Act\\nCentres of Excellence\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n10 | Safe and responsible AI in Australia impacts. Further guidance is required on how considering legislating for a database right, these existing frameworks and laws apply to AI should be addressed. This should include technologies and effectively prevent the harms regulation of IP ownership of AI systems in that can arise from their use. This should reflect relation to opensource algorithms and the policy settings and principles framework for ownership of the data being used for their\\nAI and would provide guidance and certainty for development.\\nentities developing or using the technologies\\nAccountability and afford individuals or groups of individuals with appropriate rights in relation to the data In investigating an appropriate regulatory uses, inputs and outcomes from the use of AI framework, KPMG considers that the and ADM as well as assurance, monitoring and government could usefully explore with industry: oversight. There should be a focus on ensuring legislative frameworks are adequate to address \\u2022 the development and adoption of a code of outcomes and decisions made as a result of conduct or charter that supports self- using AI and ADM, including potential harms. regulation and embeds shared values and\\nprinciples to support ethical and trustworthy\\nInformation privacy data use and AI;\\nThe Privacy Act is intended to be technology neutral and therefore is a foundational\\n\\u2022 how responsibility and accountability can be\\nclearly defined, allocated, understood and regulatory framework that focuses on personal\\nexecuted across key stages of the AI information, which is one of the larger data sets\\nlifecycle; commonly used in AI and ADM. In its current state, the Privacy Act has some legislative gaps \\u2022 the development of governance, monitoring related to employee records and small business and reporting structures that provide exemptions, however we note that these areas appropriate oversight of how AI systems and are subject to reform as a result of the Review technologies are brought into an of the Privacy Act, 4 including proposals to organisation's operations, products and/or impose additional obligations in relation to the services; and use of personal information for automated decision making. Areas that are particularly \\u2022 transparently documenting who can, is and relevant to the application of AI include should be making key decisions throughout protections for de-identified information the AI system lifecycle including based on\\n(including consideration of how AI may be used the outputs.\\nto re-identify information through the use of multiple data sources); high risk privacy Governance, monitoring and reporting processes; the misuse of data which results in structures should also include assurance detrimental outcomes for consumers, as well as mechanisms that provide assurance for employees; and where technological organisations, individuals, and the community breakthroughs and innovations are often driven more broadly.\\nby smaller firms. The impact of the use of Consent different types and combinations of data by AI, in particular sensitive information, must be The Privacy Act in its current form does not adequately addressed. Further, the reliance on explicitly set out the requirements for lawful notice and consent needs revisiting to ensure consent or what types of consent must be  transparency and choice is embedded. obtained according to personal information\\ntypes or processing purposes. The Privacy Act\\nHow to practically and effectively achieve Review proposes that lawful consent and its consent needs to be reconsidered in light of the elements are defined in the Act to cover both functionalities and capabilities of technology in implied and express consent which would reflect specific contexts of use, which are not static. current guidance. Further consideration should\\nFor example, in relation to facial recognition be given to the impact of the use of personal technologies where biometric data may be information as inputs and outputs of AI systems captured without any consent process, such as and technologies on the proposed consent when this technology is used for theft detection model. This should include how to strike the and prevention. right balance consistent with core AI principles,\\nIntellectual property (IP) where there may be higher expectations from\\nindividuals, and could recognise both the\\nClarity on the IP status of publicly available data important role of government and the power being used for development and training of AI models as well as AI outputs, including\\n4\\nPrivacy Act Review Report \\u2013 Attorney-General\\u2019s\\nDepartment\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n11 | Safe and responsible AI in Australia imbalances that may exist between individuals KPMG and the University of Queensland\\u2019s and government agencies. recent report Trust in Artificial Intelligence:\\nGlobal Insights 2023 found that while 82 percent\\nAlgorithmic bias\\nof people are aware of AI, one in two people\\nAs they currently exist, predictions or outputs report feeling they do not understand AI or when from some AI systems exhibit a high rate of and how it is used. 5 People who better error that disproportionately affect already understand AI are more likely to trust and vulnerable or marginalised populations, such as accept it and perceive greater benefits of AI use.\\non the basis of skin colour, gender and Further, the analysis finds that 82 percent of disability. Existing laws are inadequate to people want to know more about AI. Considered address the potential harm to people caused by together, these findings suggest a strong need the use of these technologies. Consequently, and appetite for public education on AI.\\nthis is an area requiring the development of\\nThe report finds that Asian countries and specific legislation.\\nFinland have the highest levels of AI awareness.\\nHigh rates in Finland compared to other western\\nRECOMMENDATION 1: nations may partially reflect investment in public\\nAI education, for example, the Elements of AI\\nKPMG suggests that the following areas could course is a free online course created by the be considered for regulatory action, subject to University of Helsinki and MinnaLearn and has further consultation: been completed by over 850,000 people. 6\\n\\u2022 The human rights impacts and harms of KPMG recommends the Australian government\\nusing specific types of data (e.g., sensitive consider investment in public AI education\\ninformation) to develop AI solutions. campaigns in order to drive cultural change and\\nincrease awareness, trust and responsible use\\n\\u2022 Data related concepts such as data integrity of AI. This should include education on what\\nand quality, data ownership, data collection, regulatory safeguards already exist under\\nanonymisation, de-identification, encryption existing regulations.\\nand their role in the context of AI and\\nFederal AI Commissioner\\nprotection of human rights.\\nKPMG supports the recommendation made by\\n\\u2022 The definition of \\\"personal information\\\" the Australian Human Rights Commissioner in\\ngiven the increasingly diverse types of data 2021 for the creation of a federal AI\\nthat could trigger harms and human rights Commissioner. 7 The role of the Commissioner\\nviolations. would be to \\u201csupport regulators, policy makers,\\ngovernment and business develop and apply\\n\\u2022 The consideration of an advisory board to\\nlaw and other standards in this area.\\u201d In our\\nprovide ongoing support in relation to AI\\nview, this function could deliver significant value\\nregulations, ethics and data sharing,\\nin filling the gap of uncertainty about how to\\nincluding examining international trends and\\ndesign and deploy AI in a way that is both lawful\\nensuring Australia\\u2019s regulations are aligned\\nand people centred.\\nto reduce administrative burden.\\nAI and mis-, dis- and mal-information (MDM)\\n3. Are there any further non-regulatory The speed and opacity of AI algorithms can be\\ninitiatives the Australian Government used to facilitate mis-, dis- and mal-information\\ncould implement to support (MDM). This includes attempts, amongst other\\nresponsible AI practices in Australia? things, to undermine trust in the fabric of\\ndemocratic society and mobilise extremist\\nPlease describe these and their views, including but not limited to, information\\nbenefits or impacts. warfare, as outlined in the recent Defence\\nEducation Strategic Review 2023. 8\\nKPMG considers that education is a key non- We also note examples where AI has created regulatory initiative that the government could non-existent references, articles and citations to implement to support responsible AI practices in support a desired output, where there is no ill-\\nAustralia. intent at play. It is important to consider both the\\ndeliberate use of AI systems to create distrust,\\nbut also the potential to create false facts due to\\n5 7\\nGillespie, N., Lockey, S., Curtis, C., Pool, J., & Akbari, A. AI Safety Commissioner \\u2013 Australian Human Rights\\n(2023). Trust in Artificial Intelligence: A Global Study. The Commission\\n8\\nUniversity of Queensland and KPMG Australia. National Defence: Defence Strategic Review 2023 -\\n6\\nElements of AI free online course Commonwealth of Australia 2023\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n12 | Safe and responsible AI in Australia the way some systems (generative models in protection to ensure clarity and reduce particular) operate. overlap.\\nAustralia could draw upon lessons learned from \\u2022 Consideration of a federal Commissioner to\\nNorway 9 and Germany 10 in strengthening support regulators, policy makers,\\nAustralia\\u2019s information resilience. As society has governments and businesses to develop become more dependent on information, the and apply laws and other standards in this ability to think critically about the information area.\\ncitizens receive becomes critical. Greater education and awareness are required at every level of society to build democratic resilience. RECOMMENDATION 3:\\nCentralisation versus decentralisation of AI The government consider initiatives that help\\nThe centralisation of AI may give rise to the organisations embed assessments and notion of encouraging through regulation the frameworks that are fit for purpose for decentralisation of AI capability as a means to designing, implementing, procuring, and using democratise and curtail the worst effects of AI. different types of AI, and making decisions\\nYet, a recent study at Harvard University found based on the AI and the data that is used.\\nAI decentralisation produced similar harmful effects when ethical and regulatory frameworks 4. Do you have suggestions on are absent. 11 As the authors of the study argue: coordination of AI governance across\\nThese technologies enable radical innovations government? Please outline the goals in social, economic, and political institutions and that any coordination mechanisms practices, with the potential to support could achieve and how they could transformative approaches to political economy.\\ninfluence the development and uptake\\nThey demand governance innovation. There is the potential to overcome persistent injustices of AI in Australia.\\npower concentrations, and perversions of KPMG and the University of Queensland\\u2019s capitalism and democracy. In fact, recent research finds that 71 percent of people believe advances in artificial intelligence (AI) may make AI regulation is required. 12 Further, people are these tools critical to preserving human dignity, broadly supportive of multiple forms of agency, and even existence. Yet there are also regulation, including regulation by government risks of catastrophe and oppression that eclipse and existing regulators, a dedicated those seen in the twentieth century. Calibre of independent AI regulator, and co-regulation and governance will determine which path we find industry regulation, with general agreement of ourselves upon. the need for some form of external, independent\\noversight.\\nRECOMMENDATION 2: Strengthening existing laws and guidance in\\nthe context of AI\\nKPMG considers that there is a range of non- regulatory initiatives the government could KPMG recommends that any regulatory settings consider in supporting responsible AI in for AI and ADM should build on existing\\nAustralia, including: frameworks such as privacy, discrimination and\\nconsumer laws, with a focus on ensuring they\\n\\u2022 Investment in public education campaigns to are adequate to address potential harms caused\\nincrease the Australian public\\u2019s awareness, by AI and ADM. To ensure a fit for purpose\\ntrust and understanding of AI. This should framework, any new regulations to address gaps\\ninclude education on what regulatory or inadequacies should be developed through a\\nsafeguards already exist under existing full industry consultation process, reviewed\\nregulations. regularly, and be as technology neutral as\\npossible.\\n\\u2022 Reviewing the roles and responsibilities of\\nexisting regulators with responsibility for It would be worthwhile to identify areas that are\\ndata, consumer rights, and online harm already subject to regulatory oversight and\\nensure that the rights, duties, and powers\\ncreated by these regimes are appropriately\\n9 11\\nThe Defence of Norway: Capability and Readiness - Long Ethics of Decentralised Social Technologies: Lessons\\nTerm Defence Plan 2020 \\u2013 Norwegian Ministry of from Web3, the Fediverse, and Beyond \\u2013 March 2023\\n12\\nDefence; Setting the Course for Norwegian Foreign and Gillespie, N., Lockey, S., Curtis, C., Pool, J., & Akbari, A.\\nSecurity Policy - Norwegian Ministry of Foreign Affairs (2023). Trust in Artificial Intelligence: A Global Study. The\\n10\\nOn German Security Policy and the Future of the University of Queensland and KPMG Australia.\\nBundeswehr - German Federal Ministry of Defence\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n13 | Safe and responsible AI in Australia adapted or modified to account for the problems RECOMMENDATION 5: unique to AI/ADM. In particular, this would require consideration about what powers and KPMG supports addressing duplication within resources would need to be given to the the broader landscape of data-related regulatory relevant regulators (i.e., ASIC, TGA, ACCC and requirements at the state and federal level. We\\nOAIC) to enable them to regulate activities to encourage collaboration between prevent and respond to harmful uses of AI/ADM. Commonwealth agencies to ensure\\nThis activity should also aim to address harmonisation between overlapping regulatory duplication within the broader landscape of frameworks.\\ndata-related regulatory requirements at the state and federal level. We encourage collaboration RECOMMENDATION 6: between Commonwealth agencies to ensure harmonisation between overlapping regulatory KPMG is supportive of the Commonwealth frameworks. public sector data sharing scheme given the\\nData sharing significant benefits from the ability for\\ngovernment departments and agencies to share\\nAn important element of coordination of AI and access each other\\u2019s data.\\ngovernance across government will be data sharing, privacy, and consent mechanisms between departments and also with citizens.\\nResponses suitable for\\nKPMG supports data sharing frameworks such Australia as the Data Availability and  Transparency Act\\n2022 (Cth) and the Data Sharing (Government\\n5. Are there any governance measures\\nSector) Act 2015 (NSW) given the significant benefits that can be drawn from greater levels of being taken or considered by other safe sharing of quality data across entities such countries (including any not discussed federal and state government agencies, as well in this paper) that are relevant, as the research community. adaptable and desirable for Australia?\\nKPMG is supportive of public sector data AI regulation has achieved low levels of maturity sharing schemes given the significant benefits mainly due to its reliance on voluntary from the ability of critical government compliance with AI Ethical Principles. Many departments and agencies such as Services jurisdictions are following the examples set by\\nAustralia, the Australian Tax Office, the the European Union and the OECD in\\nDepartment of Home Affairs, the Australian implementing frameworks to develop \\u2018human-\\nBureau of Statistics and bodies such as the centric\\u2019 AI through self-regulation. However,\\nAustralian Institute of Health and Welfare, to there are some examples of international share and access each other\\u2019s data to support regulation that should be noted, including: the delivery of day to day services, policy development, and critical program provision 1. European Union: the EU\\u2019s proposed AI Act, during national disasters. if legislated, could mark a paradigm shift\\naway from laws that address different\\nKPMG considers that in implementing the Data aspects of AI (e.g., data privacy law)\\nAvailability and  Transparency Scheme, there is towards comprehensive AI regulations. This an opportunity to develop a robust, consistent should be closely monitored.\\nand clear national framework that addresses overlapping Commonwealth, State, and Territory 2. United States: has established a National privacy and data protection frameworks and AI Initiative Act which aims to ensure that learnings from other data schemes. American values are integrated into the\\ncommercial use of AI. The White House also\\nreleased an executive order on 9 March\\nRECOMMENDATION 4: 2022 that stipulates a policy for the\\nResponsible Development of Digital Assets.\\nKPMG recommends that any regulatory settings for AI and ADM should build on existing 3. Canada: the Government has proposed frameworks such as privacy, discrimination and Digital Charter Implementation (Bill C-27) to consumer laws, with a focus on ensuring they create rules for the responsible development are adequate to address potential harms caused and deployment of AI. In addition, federal by AI and ADM. Canadian agencies are subject to the\\nDirective on Automated Decision-Making\\nwhich, among other things, mandates the\\nconduct of an algorithmic impact\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n14 | Safe and responsible AI in Australia\\nassessment to determine the impact level of ADM applications in high-risk areas, to inform its\\nan automated decision-making system. regulation.\\n4. Nordic states: Denmark, Finland, Norway\\nand Sweden have developed frameworks to Target areas\\nguide the development of ethical and\\ntrustworthy AI. Denmark has mandatory 6. Should different approaches apply to\\ncompany legislation for AI and data ethics.\\npublic and private sector use of AI\\n5. Singapore: the Model AI Governance technologies? If so, how should the\\nFramework aims to support the approaches differ?\\ndevelopment of ethical AI solutions to\\npromote public understanding and trust in In KPMG\\u2019s view, both the public and private\\ntechnology. The Implementation and Self sector\\u2019s use of AI technologies must be held to\\nAssessment Guide for Organisations helps the same minimum standards, including in\\norganisations to self-regulate alignment to relation to privacy protection,  transparency and\\nthe Model Framework. explainability, contestability, and discrimination.\\nRegulation must consider both inputs and\\nSeparately, AI standards are also being\\noutputs, i.e., what is going into the model, rather developed by international bodies such as the\\nthan just the output.\\nInternational Organisation for Standardisation\\n(ISO) and the Institute of Electrical and Above and beyond those minimum standards,\\nElectronics Engineers (IEEE). The UK the public sector may be subject to additional\\nGovernment has also released a White Paper requirements, for example, based on the types on AI regulation which considers current of data being used and the more limited choices regulatory coverage, starting with a non- the public have in relation to the collection and statutory approach to support regulator\\u2019s gaps use of their data. Given this, it is critical that and acknowledges the risks of regulatory there are adequate privacy protections, incoherence. 13  transparency around how decisions are made,\\nand sufficient access to information for data\\nWhen looking at international examples and\\nsubjects. This can also be supported by developing Australia\\u2019s regulatory framework, it is\\nfreedom of information laws that provide important to note that consistency with\\nindividuals with a right of access to their international frameworks is critical in reducing\\ninformation.\\nadministrative burden and providing increased certainty for businesses and individuals in From a privacy perspective, KPMG supports adopting these technologies. The developments requirements that privacy policies include in AI legislation in Europe, namely the whether personal information will be used in development of the EU AI Act as well as the automated decision making and for what types approach being discussed in the UK, could be of decisions (as proposed by the Privacy Act considered as a starting point in Australia, review).  Transparency about the use of personal particularly the EU\\u2019s adoption of a risk-based information in this way is important.\\napproach to AI regulation and the UK\\u2019s Furthermore, where personal information will be proposed principles-based approach and used in automated decision making, KPMG regulation of the uses, rather than the considers that there should be an option for technology. individuals to opt out from data being used in\\nthis way with reasonable alternative options to\\navoid a total denial of services, or the right to\\nRECOMMENDATION 7: request human intervention.\\nGreater consistency with international regulatory frameworks would significantly reduce RECOMMENDATION 9: administrative burden, help with exporting technology out of Australia and set clearer KPMG considers that both the public and private expectations for the importation of technology. sector\\u2019s use of AI technologies must be held to\\nthe same minimum standards, including in\\nrelation to privacy protection,  transparency and\\nRECOMMENDATION 8: explainability, contestability, and discrimination.\\nGiven the mature stage of development of the\\nEU\\u2019s AI Act, Australia could consider the risk- based approach with stricter regulation of AI and\\n13\\nA pro-innovation approach to AI regulation \\u2013 policy paper\\n\\u2013 UK Department for Science, Innovation & Technology\\n\\u00a92023 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee. All rights reserved. The KPMG name and logo are trademarks used under license by the independent member firms of the\\nKPMG global organisation.\\nLiability limited by a scheme approved under Professional Standards Legislation.\\n15 | Safe and responsible AI in Australia\\n7. How can the Australian Government RECOMMENDATION 10:\\nfurther support responsible AI\\nTo further support responsible AI practices in\\npractices in its own agencies?\\nAustralian Government agencies, KPMG\\nWe note the steps outlined in the discussion recommends consideration of defining principles paper that the Australian Government is already and boundaries for ethical data sharing taking to support responsible AI practices, practices and an assessment of the impact on including guidance from the Digital human rights.\\nTransformation Agency on public sector adoption of AI as part of its Australian 8. In what circumstances are generic\\nGovernment Architecture, and the Office of the solutions to the risks of AI most\\nCommonwealth Ombudsman\\u2019s Automated decision-making better practice guide for valuable? And in what circumstances agencies implementing AI and ADM systems. are technology-specific solutions\\nbetter? Please provide some\\nTo further support responsible AI practices in\\nAustralian Government agencies, KPMG examples.\\nrecommends consideration of defining principles KPMG notes another challenge is that not all AI and boundaries for ethical dat\",\n          \"transparency, accountability, fairness, privacy and security, proportionality and justifiability.\\n14. Changes to legislation and regulations need more detailed consideration to ensure the\\nAustralian community is protected. The AFP welcomes engagement to ensure policy\\nchanges are practical, proportionate and enforceable. Striking the right balance between the\\nrole of police in safeguarding our community, and the safeguarding of individual rights\\nrequires robust consideration, governed by general and sector-specific regulations. Adhering\\nto the Peelian principles of policing, the AFP will prioritise community engagement and\\n transparency in AI development, acknowledging that successful policing within democratic\\nsocieties is based on trust to apply powers fairly and without fear or favour.\\n15. Protecting our community from harm through strong relationships and enduring\\npartnerships with key stakeholders is at the heart of achieving operational outcomes. The\\nAFP is increasingly confronted by evolving, multi-disciplinary challenges that require multi-\\nagency and multi-jurisdictional solutions. The same principle applies to combatting the\\nthreats emerging from the use of AI. The AFP will leverage our domestic and international\\nnetworks to further strengthen partnerships across the country and the world.\\nUse of AI by the AFP\\n16. To date the AFP has taken a cautious approach to harnessing the potential of AI despite its\\nearly adoption and use by those with intent on harming Australians. We recognise the need\\nto engage more on the potential of AI to remain effective in our mission to uphold public\\nsafety and combat criminal activities. The AFP acknowledges that we must hold ourselves to\\na higher standard than those of our adversaries and be cautious in the use of broader private\\nindustry offerings due to the ethical and privacy impacts of the technology.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 4\\nAustralian Federal Police submission / 21 August 2023\\n17. The AFP is continuing to evolve our internal processes to navigate the development and\\ndeployment of emerging technologies. As the technology landscape changes, we will need to\\nensure accountability,  transparency, and responsibility when adopting any new technology.\\nThis principle has been, and will continue to be, the cornerstone of the AFP\\u2019s journey towards\\nresponsible and ethical innovation.\\n18. Managed correctly, investments in AI will propel our organisational capabilities, enabling us\\nto address a changing and increasing threat environment intent on harming Australians and\\nAustralia\\u2019s way of life. The scale of technology-facilitated crime continues to grow with AI\\nenabling criminality on a truly industrialised scale. Ransomware attacks on Australian\\nbusinesses will increase in both frequency and severity, with an annual increase of 15% on\\nreported attacks from the previous year. Within this environment, law enforcement resources\\nwill continue to be challenged by criminal enterprises we are attempting to contain. To\\ncounter this, successful adoption of AI will be critical. AI offers the AFP opportunities to:\\na. Create operational efficiencies in information discovery and understanding;\\nb. Improve situational awareness to inform better human decision making; and\\nc. Minimise physical and psychological risks to AFP capabilities and members.\\n1 transparency.\\n26. As a responsible and trusted policing organisation, the AFP will lead by example developing\\nAI technologies through collaboration and engagement with all stakeholders to\\ncomprehensively understand future implications. The key is to proactively undertake due\\ndiligence into technologies before deployment, necessitating thoughtful planning, consistent\\nethical considerations, robust governance and oversight to ensure that AI serves the greater\\ngood and aligns with societal values.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 6\\nAustralian Federal Police submission / 21 August 2023\\n27. The AFP supports ongoing engagement with the community to ensure Australia has the right\\ngovernance settings to respond to the rapid development of AI. This extends to the\\ncomplexities of harmonising governance frameworks with those used globally or by our\\nforeign law enforcement agency (FLEA) partners, to enable a shared commitment to ethical\\nAI practices, ultimately enhancing law enforcement capabilities across borders. The AFP will\\ncontinue to leverage law enforcement structures such as the, Five Eyes Law Enforcement\\nGroup (FELEG) Interpol and EUROPOL to navigate the complexities of sector-specific AI\\nutilisation. Specifically, our organisation remains dedicated to implementing the Australia\\nNew Zealand Policing Advisory Agency (ANZPAA) AI Principles that have agreed by all\\nAustralian and New Zealand Police Commissioners.\\n28. The dual-use nature of AI presents significant challenges for policing, raising concerns about\\npotential misuse and its impact on public safety and trust. AI technologies offer both\\nbeneficial and harmful applications, making regulation complex. The use of AI for policing\\nraises ethical and legal questions on privacy, bias and accountability. The seamless\\nintegration of AI, imperceptible to the human eye, fundamentally alters the security\\nlandscape by enabling the capability to comprehend information beyond an individual\\nhuman\\u2019s capability.\\n2 transparency)\\nGovernance\\n31. The AFP is prioritising effective governance to guide the implementation of AI technologies,\\nadhering to general regulations and legal frameworks that apply across industries. In\\nparticular, the AFP will ensure compliance with the Privacy Act. By reporting on AI initiatives,\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 7\\nAustralian Federal Police submission / 21 August 2023\\ndata usage, and privacy measures, the AFP will demonstrate its commitment to responsible\\nAI practices reflective of community expectations and values.\\n32. The AFP will continue to remain accountable through reporting to oversight agencies,\\nincluding the Commonwealth Ombudsman, to ensure our use of technology is aligned and\\nadheres to relevant legislation and sector-specific regulations.\\nInternal policies and building oversight AI framework\\n33. Through enhanced compliance and governance frameworks, the AFP will ensure ethical and\\nresponsible AI use into the future. These enhancements in line with the Commonwealth\\nGovernment\\u2019s legislative and policy requirements and human oversights will continually be\\nstrengthened through our agency\\u2019s commitment to continuous improvement.\\n34. To strengthen responsible AI use, the AFP will prioritise the establishment of an AI Oversight\\nFramework aligned with standards, facilitating repeatability, validation, verification, and both\\ninternal and external assessment. This will be built into the AFP\\u2019s existing strategic\\ngovernance arrangements. As we have demonstrated in building world-leading Forensics\\ncapabilities and frameworks, the AFP will apply the same approach by embodying\\nrobustness and oversight, fostering trust at organisational, jurisdictional, and community\\nlevels. By adhering to this comprehensive framework, the AFP will ensure the integrity of AI\\napplications and other emerging technologies (such as those in the space and robotics field)\\ninstilling confidence in our stakeholders and reinforcing our commitment to responsible\\nadoption of emerging technology.\\n35. Recognising the dynamic nature of risk management and post-deployment oversight for AI, it\\nis crucial the AFP\\u2019s risk management approach is continuously iterative and runs throughout\\nthe entire lifecycle of any AI system. The significance of regular, systematic updates and\\ncomprehensive audits cannot be overstated. As the technology evolves and the environment\\nin which AI operates shifts, staying attuned to potential risks and ensuring compliance with\\nethical standards demand constant vigilance.\\nTechnical leadership\\n36. Technical leadership plays a vital role in AFP\\u2019s responsible adoption of AI. Our technical\\nleaders and specialists possess the expertise and skills to guide the implementation of AI\\ntechnologies. Technical leadership ensures AI is governed, developed and deployed ethically,\\naddressing biases and risks, while driving innovation and maintaining compliance with\\nregulations.\\n37. The AFP has conducted strategic workforce planning, which sets out our key areas of focus\\nfor the next five years, committing to actions through a series of targeted strategies. The\\nAFP will commit to delivering a workforce that is skilled for today and tomorrow, configured\\nfor operational agility, comprised of engaged and supported employees and shaped by\\ncontemporary, data-driven strategic decisions. The implementation of this strategy will play a\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 8\\nAustralian Federal Police submission / 21 August 2023\\npivotal role in shaping the AFP\\u2019s technical leadership, ensuring the AFP has the right level to\\nlead and navigate the complex landscape of AI.\\nTraining\\n38. The AFP will explore utilising internal and external training programs to equip our entire\\nworkforce, including frontline members, with the essential skills to utilise AI technologies\\nappropriately. It is essential all employees can recognise where AI exists and understand its\\nlimitations and risks, and determine its appropriate use in accordance with internal and\\nexternally adopted policies and frameworks, in combination with their own knowledge and\\nskills. Having comprehensive training programs will empower all our employees to\\nresponsibly and confidently use AI technologies, cultivating a culture of accountability and\\ntrust in the benefits of AI for policing.\\n3 transparency with our international partners\\nfoster trust and enable a shared commitment to ethical AI practices, ultimately enhancing\\nlaw enforcement capabilities across borders.\\n43. The AFP will leverage existing structures such as the ANZPAA, FELEG, Interpol and\\nEUROPOL to assess governance frameworks and address global AI complexities and sector-\\nspecific utilisation.\\nAFP / MANAGER TECHNOLOGY STRATEGY & DATA | CHIEF INFORMATION OFFICER 9\\nAustralian Federal Police submission / 21 August 2023\\nConclusion\\n44. Investments in AI will propel our organisational capabilities, enabling us to address a\\nchanging threat environment harming Australians and Australia\\u2019s way of life. Managed\\ncorrectly, the AI will offer the AFP opportunities to create operational efficiencies, improve\\nsituational awareness to inform better human decision making, and minimise risks to the\\npublic safety, AFP members and capabilities.\\n45. Responsible adoption of AI in policing requires a multifaceted approach, which the AFP is\\nassessing the opportunities to strengthen five key enabling components: governance,\\npolicies, technical leadership, training and partnerships.\\n46. Collaborating internationally demands transparent dialogue to assess governance\\nframeworks and address diverse legal and ethical considerations. Remaining accountable is\\nvital, and achieved through oversight governance and regulations that uphold and demand\\nresponsible AI practices. Building an AI Oversight Framework aligned with international\\nstandards and supported by internal policies will provide clarity and guidance in ethical AI\\nadoption.\\n47. Fostering technical leadership in the AFP workforce empowers informed decision-making,\\ninnovation, and effective implementation, ultimately enhancing policing capabilities and\\nensuring public safety in our communities.\\n48. The AFP will explore opportunities to equip our workforce with comprehensive training to\\nensure adept navigation of AI technologies, instilling trust in their use and fostering a culture\\nof accountability. Partnering with industry will enable the AFP to understand AI technologies,\\nensuring alignment with our ethical standards and policing objectives \\u2013 with the\\ncommunity\\u2019s expectations of us at the front of mind.\\n4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(system, user, format, model=\"gpt-4o-mini\"):\n",
        "    system_text = system\n",
        "    user_text = user\n",
        "\n",
        "    messages = [{\"role\": \"developer\", \"content\": system_text},\n",
        "                {\"role\": \"user\", \"content\": user_text}\n",
        "                ]\n",
        "    response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    response_format=format,\n",
        "    temperature=1,\n",
        "    max_tokens=2000,\n",
        "    top_p=0.8,\n",
        "    frequency_penalty=0.3\n",
        "    )\n",
        "    print(response)\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "dF7ZP-oEVPeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2\n",
        "\n",
        "system_text_old = \"\"\"\n",
        "    You are a professional sociologist. When you read text you recognize themes and relationships.\n",
        "    When asked to compare concepts you are able to recognize connections that are abstract or conceptual.\n",
        "    \"\"\"\n",
        "system_text = \"\"\"\n",
        "    You are an information systems researcher. You are researching organizational perspectives on mandating AI transparency. The main research questions are\n",
        "    to understand how organizations understand AI transparency, what their views are about mandating it, where and when they think transparency is most critical to mitigate risks,\n",
        "    and what are their plans for responding the requirements. In order to answer these questions, you are doing thematic analysis of public consultation submissions\n",
        "    to the Australian government's \"Safe and responsible AI discussion paper\" in 2023. You only focus on submissions coming from organizations, including industry associations, tech companies,\n",
        "    consulting firms, government agencies, and academic institutions. The public consultation asks for responses on 20 questions, and the question you focus on is question 9 about AI transparency.\n",
        "    \"\"\"\n",
        "response_format={\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"Codes\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"code_name\": {\n",
        "                        \"description\": \"Name of code\",\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"description\": {\n",
        "                        \"description\": \"Description of code\",\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"quote\": {\n",
        "                        \"description\": \"Quote from text\",\n",
        "                        \"type\": \"string\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "mImOaebSVMk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "df_theme = pd.DataFrame(columns=[\"file_name\", \"code_name\", \"description\", \"quote\"])\n",
        "\n",
        "for index, row in df_filtered.iterrows():\n",
        "    text = row['transparency_text']\n",
        "    user_text = f\"\"\"\n",
        "        Given the following text:\n",
        "        \\\"\\\"\\\"\\n{text}\\n\\\"\\\"\\\"\n",
        "\n",
        "        Identify all themes in the text, provide a name for each theme in no more than 5 words,\n",
        "        a condensed description of the theme, and a quote from the text that supports the theme.\n",
        "\n",
        "        Format the response in a JSON format with \"code_name\", \"description\", and \"quote\" under the key \"Themes\".\n",
        "    \"\"\"\n",
        "    response = get_completion(system_text, user_text, response_format)\n",
        "    data = json.loads(response)\n",
        "    theme = pd.DataFrame(data[\"Themes\"])\n",
        "    theme[\"file_name\"] = row['filename']\n",
        "    df_theme = pd.concat([df_theme, theme], ignore_index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PsLR1vbegUZ",
        "outputId": "3bbbed1c-316a-4172-c568-fb9f8ee4fbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BHfP5SOB0kgZLnBlXlmKdpoZaMua4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"code_name\": \"Importance of Transparency\",\\n      \"description\": \"Transparency is crucial for trust and ethical AI use in policing.\",\\n      \"quote\": \"the AFP will prioritise community engagement and transparency in AI development, acknowledging that successful policing within democratic societies is based on trust to apply powers fairly and without fear or favour.\"\\n    },\\n    {\\n      \"code_name\": \"Cautious Approach to AI\",\\n      \"description\": \"The AFP adopts a cautious strategy regarding AI deployment to protect the community.\",\\n      \"quote\": \"To date the AFP has taken a cautious approach to harnessing the potential of AI despite its early adoption and use by those with intent on harming Australians.\"\\n    },\\n    {\\n      \"code_name\": \"Need for Robust Governance\",\\n      \"description\": \"Effective governance frameworks are essential for responsible AI implementation.\",\\n      \"quote\": \"The AFP is prioritising effective governance to guide the implementation of AI technologies, adhering to general regulations and legal frameworks that apply across industries.\"\\n    },\\n    {\\n      \"code_name\": \"Ethical Considerations in AI\",\\n      \"description\": \"AI use raises ethical questions regarding privacy, bias, and accountability.\",\\n      \"quote\": \"The dual-use nature of AI presents significant challenges for policing, raising concerns about potential misuse and its impact on public safety and trust.\"\\n    },\\n    {\\n      \"code_name\": \"Stakeholder Engagement\",\\n      \"description\": \"Collaboration with stakeholders is necessary for ethical AI practices.\",\\n      \"quote\": \"The key is to proactively undertake due diligence into technologies before deployment, necessitating thoughtful planning, consistent ethical considerations, robust governance and oversight.\"\\n    },\\n    {\\n      \"code_name\": \"Training for Workforce\",\\n      \"description\": \"Training programs are essential for responsible AI use among employees.\",\\n      \"quote\": \"The AFP will explore utilising internal and external training programs to equip our entire workforce, including frontline members, with the essential skills to utilise AI technologies appropriately.\"\\n    },\\n    {\\n      \"code_name\": \"International Collaboration\",\\n      \"description\": \"Global partnerships enhance ethical AI practices in policing.\",\\n      \"quote\": \"Collaborating internationally demands transparent dialogue to assess governance frameworks and address diverse legal and ethical considerations.\"\\n    },\\n    {\\n      \"code_name\": \"Ongoing Accountability\",\\n      \"description\": \"Continuous oversight is necessary for maintaining responsible AI usage.\",\\n      \"quote\": \"Remaining accountable is vital, and achieved through oversight governance and regulations that uphold and demand responsible AI practices.\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550431, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=511, prompt_tokens=2524, total_tokens=3035, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPCC1BJbzIHqebsNfctxCP7soga', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"code_name\": \"AI Transparency Importance\",\\n      \"description\": \"Transparency in AI is crucial for trust and ethical considerations in healthcare.\",\\n      \"quote\": \"transparency of AI in the delivery of health care is essential and this should be consistent across public and private sectors.\"\\n    },\\n    {\\n      \"code_name\": \"Risk-Based Approach Advocacy\",\\n      \"description\": \"The Department supports a risk-based approach to AI regulation, especially in health.\",\\n      \"quote\": \"The Department strongly advocates for a risk-based approach in relation to AI and recognises that it may need to be mandatory for moderate to high-risk applications in health and aged care.\"\\n    },\\n    {\\n      \"code_name\": \"Data Impact Assessments\",\\n      \"description\": \"Recommendation for mandatory Data Impact Assessments for high-impact AI applications.\",\\n      \"quote\": \"The Department recommends DISR considers, in partnership with appropriate regulators... the development of guidelines for Data Impact Assessments (DIA) as part of AI assessments.\"\\n    },\\n    {\\n      \"code_name\": \"Ethical Considerations\",\\n      \"description\": \"Ethics should guide AI usage, particularly regarding data and outcomes.\",\\n      \"quote\": \"...greater ethics consideration when using data for AI purposes, particularly as it relates to health outcomes...\"\\n    },\\n    {\\n      \"code_name\": \"Ongoing Monitoring Necessity\",\\n      \"description\": \"Emphasis on the need for continuous monitoring and retraining of AI technologies.\",\\n      \"quote\": \"...having approaches for ongoing monitoring and potential re-training of AI technologies and models is essential to ensure their relevance and performance over time.\"\\n    },\\n    {\\n      \"code_name\": \"Public Trust Building\",\\n      \"description\": \"Building public trust through transparency and ethical practices is vital.\",\\n      \"quote\": \"...building public trust will be critical. This requires careful consideration of data sharing practices...\"\\n    },\\n    {\\n      \"code_name\": \"Regulatory Frameworks Development\",\\n      \"description\": \"Support for evolving regulatory frameworks to address emerging AI challenges.\",\\n      \"quote\": \"...current regulations only permit the disclosure of critical departmental data... Comprehensive regulatory reforms are needed.\"\\n    },\\n    {\\n      \"code_name\": \"Inclusivity in AI Applications\",\\n      \"description\": \"AI applications must consider diverse populations to ensure fairness.\",\\n      \"quote\": \"...ensuring inclusivity and accessibility for diverse populations, particularly culturally and linguistically diverse (CALD) communities.\"\\n    },\\n    {\\n      \"code_name\": \"Bias Mitigation Focus\",\\n      \"description\": \"Addressing bias in AI algorithms is essential to prevent harm.\",\\n      \"quote\": \"...addressing bias in AI algorithms is of utmost importance to avoid disproportionate impacts on vulnerable populations...\"\\n    },\\n    {\\n      \"code_name\": \"Sector Coordination Needs\",\\n      \"description\": \"Call for coordinated governance across sectors regarding AI implementation.\",\\n      \"quote\": \"...coordination mechanisms need to establish consistency and coherence in AI policies and regulations across government departments...\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550438, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=608, prompt_tokens=6183, total_tokens=6791, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPM3VUzg0Lmyi4f3Qh1nR96PwGo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"Themes\":[{\"code_name\":\"AI Transparency Importance\",\"description\":\"Emphasizes the need for transparency in AI applications to build trust and enable informed decision-making.\",\"quote\":\"We support an approach to transparency that requires notification to customers about the kinds of inferences an entity may generate about an individual that constitute personal information, including via AI.\"},{\"code_name\":\"Regulatory Framework Recommendations\",\"description\":\"Calls for a cohesive regulatory framework that integrates AI governance with existing regulations.\",\"quote\":\"the Federal Government should consider what institutional arrangements will help regulators develop a modernised and consistent approach to AI regulation.\"},{\"code_name\":\"Risk-Based Regulation Approach\",\"description\":\"Advocates for a risk-based approach in regulating AI technologies rather than focusing on specific technologies.\",\"quote\":\"We support a tiered risk-based approach to regulation with risk classification rules not predetermined but distinguished into primary drivers of events.\"},{\"code_name\":\"Definitions Consistency\",\"description\":\"Stresses the need for consistent definitions across government guidance to ensure effective AI governance.\",\"quote\":\"The consistent application of definitions across government guidance material is essential to ensuring the success of any AI governance.\"},{\"code_name\":\"Privacy and Data Ethics\",\"description\":\"Highlights the importance of privacy and data ethics in the context of AI deployment.\",\"quote\":\"...we hold ourselves to a high standard; and... any future AI regulatory framework must be well integrated with broader cyber and privacy regulation.\"},{\"code_name\":\"Centralized Governance Coordination\",\"description\":\"Suggests establishing a central office for coordinating AI regulations across jurisdictions.\",\"quote\":\"Given the potential application of AI in all sectors of the Australian economy and society, it is essential that the Department consider the institutional arrangements that will help decision makers and regulators implement a coordinated approach to AI regulation.\"},{\"code_name\":\"Regulatory Sandbox Proposal\",\"description\":\"Proposes creating a regulatory sandbox for testing AI technologies under relaxed requirements.\",\"quote\":\"To this end, the government should consider permitting experimentation in a controlled environment in which AI systems can be tested, and scaled-up, if appropriate.\"},{\"code_name\":\"Consumer Education on AI Use\",\"description\":\"Supports educating consumers on how their data is used through AI systems.\",\"quote\":\"This level of transparency enables individuals to make an educated decision about whether to share their personal information with an organisation.\"}]}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550448, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=450, prompt_tokens=3641, total_tokens=4091, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPRe7Oz89Pcg4n9xS7uSy4C7YIL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"code_name\": \"AI for Societal Benefit\",\\n      \"description\": \"AI should serve the broader society, not just companies.\",\\n      \"quote\": \"AI should be built to benefit the whole of society.\"\\n    },\\n    {\\n      \"code_name\": \"Risk Mitigation through Transparency\",\\n      \"description\": \"Transparency is crucial for managing AI risks.\",\\n      \"quote\": \"While we can’t eliminate the risks, we can mitigate them.\"\\n    },\\n    {\\n      \"code_name\": \"Regulatory Frameworks for AI\",\\n      \"description\": \"Need for updated regulations on AI use.\",\\n      \"quote\": \"It is an opportune time for the Australian Government to engage in conversations about the right regulatory frameworks for emerging technology such as AI.\"\\n    },\\n    {\\n      \"code_name\": \"User Control and Insight\",\\n      \"description\": \"Empowering users with control over AI decisions.\",\\n      \"quote\": \"We believe that the people who use our products should have meaningful transparency and control around how data about them is collected and used.\"\\n    },\\n    {\\n      \"code_name\": \"Community Engagement in Regulation\",\\n      \"description\": \"Collaboration among stakeholders in regulation design.\",\\n      \"quote\": \"Design any AI regulation as a product of collaboration amongst multiple stakeholders.\"\\n    },\\n    {\\n      \"code_name\": \"Proactive Harm Detection\",\\n      \"description\": \"AI actively identifies harmful content.\",\\n      \"quote\": \"AI technology provides opportunities to detect harmful content before people need to see it.\"\\n    },\\n    {\\n      \"code_name\": \"Open Access to AI Models\",\\n      \"description\": \"Encouraging public access to AI innovations.\",\\n      \"quote\": \"We have released over 1,000 models and AI databases on non-commercial licences for researchers.\"\\n    },\\n    {\\n      \"code_name\": \"Transparency Tools for Users\",\\n      \"description\": \"Providing tools for users to understand AI actions.\",\\n      \"quote\": \"\\'Why am I seeing this post?\\' This feature... was launched in March 2019 to help people understand and more easily control what they are seeing in their Feed.\"\\n    },\\n    {\\n      \"code_name\": \"Fairness and Inclusion Focus\",\\n      \"description\": \"\\'Fairness Flow\\' product to analyze AI risks.\",\\n      \"quote\": \"\\'Fairness Flow\\' to help internal teams analyse how AI works, so that they can spot risks or unintended consequences.\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550453, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=499, prompt_tokens=7191, total_tokens=7690, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPYs3b2Dor2nAvtLx5qkVE536aG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"code_name\": \"Commitment to Responsible AI\",\\n      \"description\": \"Microsoft emphasizes its dedication to safe and responsible AI development and implementation.\",\\n      \"quote\": \"Microsoft is committed to working alongside Government to ‘meet the moment’ when it comes to safe and responsible AI.\"\\n    },\\n    {\\n      \"code_name\": \"Economic Potential of AI\",\\n      \"description\": \"AI is seen as a significant driver of economic growth and productivity in Australia.\",\\n      \"quote\": \"AI has huge potential to help advance thinking and learning to improve the human condition.\"\\n    },\\n    {\\n      \"code_name\": \"International Standards Alignment\",\\n      \"description\": \"The need for Australia\\'s AI regulations to align with global best practices is highlighted.\",\\n      \"quote\": \"We therefore recommend that the Government consider aligning core definitions with international best practice.\"\\n    },\\n    {\\n      \"code_name\": \"Risk-Based Regulation Approach\",\\n      \"description\": \"A call for AI regulation that is proportionate and responsive to the risks associated with AI systems.\",\\n      \"quote\": \"We support a risk-based approach to develop AI governance that is proportionate, differentiated and responsive to the risks of a given AI system.\"\\n    },\\n    {\\n      \"code_name\": \"Importance of Transparency\",\\n      \"description\": \"Transparency in AI processes and systems is emphasized as crucial for responsible usage.\",\\n      \"quote\": \"...implementing best practices for building, and helping our customers build, AI systems that are safe, secure, transparent and designed to benefit society.\"\\n    },\\n    {\\n      \"code_name\": \"Collaboration with Government\",\\n      \"description\": \"Microsoft expresses a desire for ongoing collaboration with governmental bodies on AI policy.\",\\n      \"quote\": \"...we look forward to continuing our engagement with the Government on this important issue.\"\\n    },\\n    {\\n      \"code_name\": \"Challenges in Governance\",\\n      \"description\": \"Recognition of the need for effective governance structures in light of evolving AI technologies.\",\\n      \"quote\": \"...there is a need to manage the potential risks associated with the use of AI...\"\\n    },\\n    {\\n      \"code_name\": \"Public-Private Partnerships\",\\n      \"description\": \"Encouragement for collaboration between public sectors and private industry in developing AI frameworks.\",\\n      \"quote\": \"...there are significant opportunities for new public-private partnerships to work on addressing the challenges and benefits of AI.\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550460, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=488, prompt_tokens=6309, total_tokens=6797, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPfNlYxR2zpj5igmQeMwi6AoxBn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"Themes\":[{\"code_name\":\"Ethical Data Sharing Practices\",\"description\":\"KPMG recommends defining principles for ethical data sharing and assessing human rights impacts.\",\"quote\":\"KPMG recommends consideration of defining principles and boundaries for ethical data sharing practices and an assessment of the impact on human rights.\"},{\"code_name\":\"Transparent Disclosure Obligations\",\"description\":\"KPMG suggests introducing requirements for organizations to disclose compliance with ethics frameworks.\",\"quote\":\"KPMG suggests it would be useful to consider the introduction of transparent disclosure obligations that require organisations to disclose why an AI use case was deemed to have complied with the particular ethics framework.\"},{\"code_name\":\"Core Principles for Regulation\",\"description\":\"KPMG emphasizes foundational principles like safety and accountability for regulatory frameworks.\",\"quote\":\"KPMG suggests the regulatory framework should be founded on a core set of principles, ideally based on current established principles (such as: safety, security, robustness, fairness, transparency and accountability).\"},{\"code_name\":\"Public Trust Initiatives\",\"description\":\"KPMG advocates initiatives to increase public trust in AI through certifications and education.\",\"quote\":\"KPMG recommends a range of initiatives that may increase public trust in AI deployment, including the development of a certification regime for responsible AI, embedding data quality requirements, public education campaigns.\"},{\"code_name\":\"Assurance Mechanisms\",\"description\":\"KPMG believes implementing assurance mechanisms can build trust in AI systems.\",\"quote\":\"KPMG considers that the implementation of assurance mechanisms would facilitate greater trust in AI systems.\"},{\"code_name\":\"Human Rights Risk Assessments\",\"description\":\"KPMG recommends initial assessments to determine AI project risks to human rights.\",\"quote\":\"KPMG considers that the government could usefully explore with industry the development of an initial human rights risk assessment to determine an AI project\\'s level of risk to people upfront.\"},{\"code_name\":\"Self-Regulation Limitations\",\"description\":\"KPMG notes self-regulation may be insufficient without agreed regulatory goals.\",\"quote\":\"KPMG considers that self-regulation may ultimately not be sufficient, and agreement on regulatory goals is necessary before effective self-regulation can occur.\"},{\"code_name\":\"AI Education Importance\",\"description\":\"KPMG emphasizes the need for public education on AI to build understanding and trust.\",\"quote\":\"This should include education on what regulatory safeguards already exist under existing regulations.\"},{\"code_name\":\"Algorithmic Accountability Needs\",\"description\":\"KPMG identifies a need for laws addressing potential harms from algorithmic bias.\",\"quote\":\"As they currently exist, predictions or outputs from some AI systems exhibit a high rate of error that disproportionately affect already vulnerable or marginalised populations.\"},{\"code_name\":\"Regulatory Framework Adaptation\",\"description\":\"Existing laws should adapt to adequately regulate AI technologies.\",\"quote\":\"Existing legislative frameworks that aim to address consumer and other individual harms should be considered as a starting point, noting that the current frameworks are generally not yet adequately adapted to the use of AI and ADM technologies.\"}]}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550467, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=572, prompt_tokens=6366, total_tokens=6938, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPofx3hMWH3K93Pf5KOQP9qa8Vh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"code_name\": \"Importance of Transparency\",\\n      \"description\": \"Transparency is crucial for responsible AI deployment and public trust.\",\\n      \"quote\": \"Transparency is critical, and companies are not sharing enough for proprietary reasons.\"\\n    },\\n    {\\n      \"code_name\": \"Need for Regulation\",\\n      \"description\": \"Regulatory frameworks are needed to ensure AI aligns with human values and rights.\",\\n      \"quote\": \"A critical risk is that AI development may ignore human values, and impact human rights, privacy, consent...\"\\n    },\\n    {\\n      \"code_name\": \"Education and Public Awareness\",\\n      \"description\": \"Education is essential for understanding AI risks and responsible usage.\",\\n      \"quote\": \"Education must be at the forefront of Australia’s approach to responsible AI...\"\\n    },\\n    {\\n      \"code_name\": \"High-Stakes Decision Making\",\\n      \"description\": \"Different levels of transparency are needed based on application stakes.\",\\n      \"quote\": \"...for high-stake decision-making (say critical medical related decision making), the highest level of transparency is needed...\"\\n    },\\n    {\\n      \"code_name\": \"Risks of Black-Box Models\",\\n      \"description\": \"Opaque models pose risks of bias and discrimination.\",\\n      \"quote\": \"...A black-box approach to decision-making using AI technology creates real risks of biases, discrimination, and unfairness...\"\\n    },\\n    {\\n      \"code_name\": \"AI Literacy Enhancement\",\\n      \"description\": \"Boosting AI literacy among stakeholders is vital for informed use.\",\\n      \"quote\": \"...Enhanced AI (including responsible AI), literacy at all levels of society...\"\\n    },\\n    {\\n      \"code_name\": \"Ethical Considerations in AI\",\\n      \"description\": \"Ethical frameworks must guide AI use to prevent misuse.\",\\n      \"quote\": \"...Instead of banning high-risk AI applications, we should spend greater effort on making our legal framework more comprehensive...\"\\n    },\\n    {\\n      \"code_name\": \"International Regulatory Insights\",\\n      \"description\": \"Learning from international regulations can shape Australia\\'s approach.\",\\n      \"quote\": \"...The EU has drafted its “AI Act” which is referred to as a step closer to the first rules on Artificial Intelligence.\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550476, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=454, prompt_tokens=3433, total_tokens=3887, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "ChatCompletion(id='chatcmpl-BHfPtz1JUvegrCFylSjry1lvFnh7O', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"code_name\": \"AI as Augmentation Tool\",\\n      \"description\": \"AI should enhance human decision-making, not replace it.\",\\n      \"quote\": \"transparency that make clear the role of AI is to augment, not replace, human expertise and judgement.\"\\n    },\\n    {\\n      \"code_name\": \"Precision Regulation Approach\",\\n      \"description\": \"Regulate AI based on specific use-cases.\",\\n      \"quote\": \"Accordingly, we urge the Australian Government to adopt a \\'precision regulation\\' approach to AI.\"\\n    },\\n    {\\n      \"code_name\": \"Accountability in AI Ethics\",\\n      \"description\": \"Organizations must designate ethics officials.\",\\n      \"quote\": \"Providers and owners of AI should designate a person responsible for trustworthy AI.\"\\n    },\\n    {\\n      \"code_name\": \"Risk-Based Transparency\",\\n      \"description\": \"Transparency requirements vary by risk level.\",\\n      \"quote\": \"low-risk and benign applications of AI may not require the same type or level of disclosure that higher-risk use-cases might require.\"\\n    },\\n    {\\n      \"code_name\": \"Importance of Disclosure\",\\n      \"description\": \"Disclosure promotes trust in AI systems.\",\\n      \"quote\": \"Transparency breeds trust; and the best way to promote transparency is through disclosure.\"\\n    },\\n    {\\n      \"code_name\": \"Explainability of AI Systems\",\\n      \"description\": \"AI systems must be able to explain decisions.\",\\n      \"quote\": \"...should be able to explain and contextualize how and why it arrived at a particular conclusion.\"\\n    },\\n    {\\n      \"code_name\": \"AI FactSheets Concept\",\\n      \"description\": \"\\'FactSheets\\' help communicate AI information.\",\\n      \"quote\": \"...IBM has adopted the use of AI Factsheets (a similar concept to nutrition information labels but for AI)...\"\\n    },\\n    {\\n      \"code_name\": \"Global Coordination for Standards\",\\n      \"description\": \"Encouraging international best practices for transparency.\",\\n      \"quote\": \"...Strengthen mechanisms for global coordination on AI transparency-enabling best practices...\"\\n    },\\n    {\\n      \"code_name\": \"Differentiation in Sector Regulation\",\\n      \"description\": \"\\'Different rules for different risks\\' applies across sectors.\",\\n      \"quote\": \"...it may make sense to differentiate obligations for private sector actors versus the public sector...\"\\n    },\\n    {\\n      \"code_name\": \"\\'High-Risk\\' AI Regulations\",\\n      \"description\": \"\\\\\"High-risk\\\\\" applications need stringent oversight.\",\\n      \"quote\": \"...for those high-risk use-cases, the assessment processes should be documented in detail, be auditable...\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550481, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=535, prompt_tokens=6391, total_tokens=6926, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_theme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "Iz62Pq7ghW7P",
        "outputId": "28e83d7a-484c-466a-e2f3-740882f51708",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        file_name                             code_name  \\\n",
              "0   Australian Federal Police.txt            Importance of Transparency   \n",
              "1   Australian Federal Police.txt               Cautious Approach to AI   \n",
              "2   Australian Federal Police.txt            Need for Robust Governance   \n",
              "3   Australian Federal Police.txt          Ethical Considerations in AI   \n",
              "4   Australian Federal Police.txt                Stakeholder Engagement   \n",
              "..                            ...                                   ...   \n",
              "66              IBM Australia.txt          Explainability of AI Systems   \n",
              "67              IBM Australia.txt                 AI FactSheets Concept   \n",
              "68              IBM Australia.txt     Global Coordination for Standards   \n",
              "69              IBM Australia.txt  Differentiation in Sector Regulation   \n",
              "70              IBM Australia.txt            'High-Risk' AI Regulations   \n",
              "\n",
              "                                          description  \\\n",
              "0   Transparency is crucial for trust and ethical ...   \n",
              "1   The AFP adopts a cautious strategy regarding A...   \n",
              "2   Effective governance frameworks are essential ...   \n",
              "3   AI use raises ethical questions regarding priv...   \n",
              "4   Collaboration with stakeholders is necessary f...   \n",
              "..                                                ...   \n",
              "66      AI systems must be able to explain decisions.   \n",
              "67      'FactSheets' help communicate AI information.   \n",
              "68  Encouraging international best practices for t...   \n",
              "69  'Different rules for different risks' applies ...   \n",
              "70  \"High-risk\" applications need stringent oversi...   \n",
              "\n",
              "                                                quote  \n",
              "0   the AFP will prioritise community engagement a...  \n",
              "1   To date the AFP has taken a cautious approach ...  \n",
              "2   The AFP is prioritising effective governance t...  \n",
              "3   The dual-use nature of AI presents significant...  \n",
              "4   The key is to proactively undertake due dilige...  \n",
              "..                                                ...  \n",
              "66  ...should be able to explain and contextualize...  \n",
              "67  ...IBM has adopted the use of AI Factsheets (a...  \n",
              "68  ...Strengthen mechanisms for global coordinati...  \n",
              "69  ...it may make sense to differentiate obligati...  \n",
              "70  ...for those high-risk use-cases, the assessme...  \n",
              "\n",
              "[71 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04478f79-533a-42d2-aa9d-13b74f36e8c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>code_name</th>\n",
              "      <th>description</th>\n",
              "      <th>quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>Transparency is crucial for trust and ethical ...</td>\n",
              "      <td>the AFP will prioritise community engagement a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>Cautious Approach to AI</td>\n",
              "      <td>The AFP adopts a cautious strategy regarding A...</td>\n",
              "      <td>To date the AFP has taken a cautious approach ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>Need for Robust Governance</td>\n",
              "      <td>Effective governance frameworks are essential ...</td>\n",
              "      <td>The AFP is prioritising effective governance t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>AI use raises ethical questions regarding priv...</td>\n",
              "      <td>The dual-use nature of AI presents significant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Australian Federal Police.txt</td>\n",
              "      <td>Stakeholder Engagement</td>\n",
              "      <td>Collaboration with stakeholders is necessary f...</td>\n",
              "      <td>The key is to proactively undertake due dilige...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>IBM Australia.txt</td>\n",
              "      <td>Explainability of AI Systems</td>\n",
              "      <td>AI systems must be able to explain decisions.</td>\n",
              "      <td>...should be able to explain and contextualize...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>IBM Australia.txt</td>\n",
              "      <td>AI FactSheets Concept</td>\n",
              "      <td>'FactSheets' help communicate AI information.</td>\n",
              "      <td>...IBM has adopted the use of AI Factsheets (a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>IBM Australia.txt</td>\n",
              "      <td>Global Coordination for Standards</td>\n",
              "      <td>Encouraging international best practices for t...</td>\n",
              "      <td>...Strengthen mechanisms for global coordinati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>IBM Australia.txt</td>\n",
              "      <td>Differentiation in Sector Regulation</td>\n",
              "      <td>'Different rules for different risks' applies ...</td>\n",
              "      <td>...it may make sense to differentiate obligati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>IBM Australia.txt</td>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>\"High-risk\" applications need stringent oversi...</td>\n",
              "      <td>...for those high-risk use-cases, the assessme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04478f79-533a-42d2-aa9d-13b74f36e8c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04478f79-533a-42d2-aa9d-13b74f36e8c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04478f79-533a-42d2-aa9d-13b74f36e8c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b711d316-47ae-4d67-b868-39d6b23edc4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b711d316-47ae-4d67-b868-39d6b23edc4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b711d316-47ae-4d67-b868-39d6b23edc4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a3ab97e4-d144-461b-a58b-0a02aa4c8528\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_theme')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a3ab97e4-d144-461b-a58b-0a02aa4c8528 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_theme');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_theme",
              "summary": "{\n  \"name\": \"df_theme\",\n  \"rows\": 71,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Department of Health and Aged Care.txt\",\n          \"KPMG Australia.txt\",\n          \"Australian Federal Police.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66,\n        \"samples\": [\n          \"AI Literacy Enhancement\",\n          \"AI FactSheets Concept\",\n          \"Importance of Transparency\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"Highlights the importance of privacy and data ethics in the context of AI deployment.\",\n          \"Transparency is crucial for trust and ethical AI use in policing.\",\n          \"KPMG notes self-regulation may be insufficient without agreed regulatory goals.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quote\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"...we hold ourselves to a high standard; and... any future AI regulatory framework must be well integrated with broader cyber and privacy regulation.\",\n          \"the AFP will prioritise community engagement and transparency in AI development, acknowledging that successful policing within democratic societies is based on trust to apply powers fairly and without fear or favour.\",\n          \"KPMG considers that self-regulation may ultimately not be sufficient, and agreement on regulatory goals is necessary before effective self-regulation can occur.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df_theme is not None:\n",
        "    excel_filepath = \"/content/drive/MyDrive/codes_8_docs_2.xlsx\"  # Replace with desired path\n",
        "    df_theme.to_excel(excel_filepath, index=False)  # Set index=False to avoid writing row indices\n",
        "    print(f\"DataFrame exported to: {excel_filepath}\")\n",
        "else:\n",
        "    print(\"DataFrame 'df_theme' is empty or None. Cannot export.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmnGmJ-Ck4md",
        "outputId": "8ab2a3fc-2e84-4784-a229-d363b1473286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame exported to: /content/drive/MyDrive/codes_8_docs_2.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "excel_filepath = \"/content/drive/MyDrive/codes_8_docs_2.xlsx\"\n",
        "df_theme = pd.read_excel(excel_filepath)"
      ],
      "metadata": {
        "id": "3WaQtYQSLSzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3\n",
        "\n",
        "formatted_codes = df_theme['code_name'].to_string(index=False)\n",
        "\n",
        "user_text_2 = f\"\"\"\n",
        "Consider these topics:\n",
        "\\\"\\\"\\\"\\n{formatted_codes}\\n\\\"\\\"\\\"\n",
        "\n",
        "Determine how all the topics in the list of topics can be grouped together.\n",
        "Topics can be in more than one group. Provide a name and description for each group, followed by all the topics in the group.\n",
        "\n",
        "Format the response in a JSON format with \"theme_name\", \"description\", and \"codes\" under the key \"Themes\".\n",
        "\"\"\"\n",
        "response_format_2={\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"Themes\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"theme_name\": {\n",
        "                        \"description\": \"Name of theme group\",\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"description\": {\n",
        "                        \"description\": \"Description of theme group\",\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"codes\": {\n",
        "                        \"description\": \"Topics\",\n",
        "                        \"type\": \"string\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "4HlD2oDRVorW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_2 = get_completion(system_text, user_text_2, response_format_2)\n",
        "data2 = json.loads(result_2)\n",
        "df_theme2 = pd.DataFrame(data2[\"Themes\"])\n",
        "df_theme2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "IYwbXBp3VtM-",
        "outputId": "2e0d9a0b-5b27-41a7-cb3a-a0eced97dc2d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BHfSYpOx6vIkf5qJHOspaAwvCyO9v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"theme_name\": \"AI Transparency and Accountability\",\\n      \"description\": \"This group focuses on the importance of transparency in AI systems and the need for accountability mechanisms to ensure ethical use.\",\\n      \"codes\": [\\n        \"Importance of Transparency\",\\n        \"AI Transparency Importance\",\\n        \"Ongoing Accountability\",\\n        \"Risk-Based Transparency\",\\n        \"Importance of Disclosure\",\\n        \"Explainability of AI Systems\",\\n        \"Algorithmic Accountability Needs\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Governance and Regulation Frameworks\",\\n      \"description\": \"This theme encompasses the need for robust governance structures and regulatory frameworks to manage AI technologies effectively.\",\\n      \"codes\": [\\n        \"Need for Robust Governance\",\\n        \"Regulatory Frameworks Development\",\\n        \"Regulatory Framework Recommendations\",\\n        \"Centralized Governance Coordination\",\\n        \"Challenges in Governance\",\\n        \"Regulatory Sandbox Proposal\",\\n        \"Risk-Based Regulation Approach\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Ethical Considerations and Social Impact\",\\n      \"description\": \"This group addresses ethical considerations in AI, including inclusivity, bias mitigation, and the societal impact of AI technologies.\",\\n      \"codes\": [\\n        \"Ethical Considerations in AI\",\\n        \"Inclusivity in AI Applications\",\\n        \"Bias Mitigation Focus\",\\n        \"Commitment to Responsible AI\",\\n        \"Human Rights Risk Assessments\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Stakeholder Engagement and Collaboration\",\\n      \"description\": \"This theme highlights the importance of engaging various stakeholders, including government and industry partners, in discussions about AI transparency.\",\\n      \"codes\": [\\n        \"Stakeholder Engagement\",\\n        \"International Collaboration\",\\n        \"Public-Private Partnerships\",\\n        \"Community Engagement in Regulation\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Education and Public Awareness\",\\n      \"description\": \"This group emphasizes the need for education regarding AI technologies to enhance public understanding and promote responsible use.\",\\n      \"codes\": [\\n        \"Training for Workforce\",\\n        \"Consumer Education on AI Use\",\\n        \"\\'High-Risk\\' AI Regulations\",\\n        \"AI Literacy Enhancement\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'Risk-Based\\' Approach to AI Management\",\\n      \"description\": \"\\'Risk-based\\' approaches advocate for tailored regulations based on the risk level associated with different AI applications.\",\\n      \"codes\": [\\n        \"Risk-Based Approach Advocacy\",\\n        \"\\'High-Risk\\' AI Regulations\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'Transparency Tools\\' for Users and Public Trust Initiatives\",\\n      \"description\": \"\\'Transparency tools\\' are mechanisms designed to provide users with insight into AI systems, fostering public trust through open access.\",\\n      \"codes\": [\\n        \"...Transparency Tools for Users...\",\\n       \"...Public Trust Initiatives...\",\\n       \"...Open Access to AI Models...\"\\n     ]\\n   }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550646, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=585, prompt_tokens=720, total_tokens=1305, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          theme_name  \\\n",
              "0                 AI Transparency and Accountability   \n",
              "1               Governance and Regulation Frameworks   \n",
              "2           Ethical Considerations and Social Impact   \n",
              "3           Stakeholder Engagement and Collaboration   \n",
              "4                     Education and Public Awareness   \n",
              "5             'Risk-Based' Approach to AI Management   \n",
              "6  'Transparency Tools' for Users and Public Trus...   \n",
              "\n",
              "                                         description  \\\n",
              "0  This group focuses on the importance of transp...   \n",
              "1  This theme encompasses the need for robust gov...   \n",
              "2  This group addresses ethical considerations in...   \n",
              "3  This theme highlights the importance of engagi...   \n",
              "4  This group emphasizes the need for education r...   \n",
              "5  'Risk-based' approaches advocate for tailored ...   \n",
              "6  'Transparency tools' are mechanisms designed t...   \n",
              "\n",
              "                                               codes  \n",
              "0  [Importance of Transparency, AI Transparency I...  \n",
              "1  [Need for Robust Governance, Regulatory Framew...  \n",
              "2  [Ethical Considerations in AI, Inclusivity in ...  \n",
              "3  [Stakeholder Engagement, International Collabo...  \n",
              "4  [Training for Workforce, Consumer Education on...  \n",
              "5  [Risk-Based Approach Advocacy, 'High-Risk' AI ...  \n",
              "6  [...Transparency Tools for Users..., ...Public...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5518e151-97de-4567-84ae-28db7cd97754\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>theme_name</th>\n",
              "      <th>description</th>\n",
              "      <th>codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "      <td>[Importance of Transparency, AI Transparency I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "      <td>[Need for Robust Governance, Regulatory Framew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ethical Considerations and Social Impact</td>\n",
              "      <td>This group addresses ethical considerations in...</td>\n",
              "      <td>[Ethical Considerations in AI, Inclusivity in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme highlights the importance of engagi...</td>\n",
              "      <td>[Stakeholder Engagement, International Collabo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>This group emphasizes the need for education r...</td>\n",
              "      <td>[Training for Workforce, Consumer Education on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-based' approaches advocate for tailored ...</td>\n",
              "      <td>[Risk-Based Approach Advocacy, 'High-Risk' AI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>'Transparency Tools' for Users and Public Trus...</td>\n",
              "      <td>'Transparency tools' are mechanisms designed t...</td>\n",
              "      <td>[...Transparency Tools for Users..., ...Public...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5518e151-97de-4567-84ae-28db7cd97754')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5518e151-97de-4567-84ae-28db7cd97754 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5518e151-97de-4567-84ae-28db7cd97754');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29391cd7-215e-48f1-ae9a-2da976dba7be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29391cd7-215e-48f1-ae9a-2da976dba7be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29391cd7-215e-48f1-ae9a-2da976dba7be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_00fd7a39-f256-41cc-9394-fa5ac301b9bd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_theme2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_00fd7a39-f256-41cc-9394-fa5ac301b9bd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_theme2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_theme2",
              "summary": "{\n  \"name\": \"df_theme2\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"theme_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"AI Transparency and Accountability\",\n          \"Governance and Regulation Frameworks\",\n          \"'Risk-Based' Approach to AI Management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"This group focuses on the importance of transparency in AI systems and the need for accountability mechanisms to ensure ethical use.\",\n          \"This theme encompasses the need for robust governance structures and regulatory frameworks to manage AI technologies effectively.\",\n          \"'Risk-based' approaches advocate for tailored regulations based on the risk level associated with different AI applications.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"codes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_3 = get_completion(system_text, user_text_2, response_format_2)\n",
        "data3 = json.loads(result_3)\n",
        "df_theme3 = pd.DataFrame(data3[\"Themes\"])\n",
        "df_theme3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "e-gTEj8My-Jb",
        "outputId": "f0b9768d-c433-4063-ea02-19e10d92865a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BHfT6URvcqbepM5YVp4sYB5xwnuMy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"theme_name\": \"Importance of Transparency\",\\n      \"description\": \"This group highlights the critical role of transparency in AI systems, focusing on its necessity for public trust, ethical considerations, and risk mitigation.\",\\n      \"codes\": [\\n        \"Importance of Transparency\",\\n        \"AI Transparency Importance\",\\n        \"Risk Mitigation through Transparency\",\\n        \"Importance of Disclosure\",\\n        \"Explainability of AI Systems\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Governance and Regulation\",\\n      \"description\": \"This group emphasizes the need for robust governance structures and regulatory frameworks to manage AI effectively, ensuring ethical practices and accountability.\",\\n      \"codes\": [\\n        \"Need for Robust Governance\",\\n        \"Regulatory Frameworks Development\",\\n        \"Centralized Governance Coordination\",\\n        \"Regulatory Framework Recommendations\",\\n        \"Risk-Based Regulation Approach\",\\n        \"Transparent Disclosure Obligations\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Ethical Considerations in AI\",\\n      \"description\": \"This group covers the ethical implications of AI technologies, including bias mitigation, accountability, and human rights assessments.\",\\n      \"codes\": [\\n        \"Ethical Considerations in AI\",\\n        \"Bias Mitigation Focus\",\\n        \"Human Rights Risk Assessments\",\\n        \"Algorithmic Accountability Needs\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Stakeholder Engagement and Collaboration\",\\n      \"description\": \"This group focuses on the importance of engaging various stakeholders, including the public and private sectors, to foster collaboration in AI development and regulation.\",\\n      \"codes\": [\\n        \"Stakeholder Engagement\",\\n        \"Community Engagement in Regulation\",\\n        \"Public-Private Partnerships\",\\n        \"International Collaboration\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Education and Awareness\",\\n      \"description\": \"This group highlights the significance of educating the workforce and the public about AI technologies to enhance understanding and promote responsible usage.\",\\n      \"codes\": [\\n        \"Training for Workforce\",\\n        \"Consumer Education on AI Use\",\\n        \"\\'AI Literacy Enhancement\\'\",\\n        \"AI Education Importance\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'High-Risk\\' AI Regulations\",\\n      \"description\": \"\\'High-Risk\\' regulations are focused on ensuring that high-stakes applications of AI are held to stringent standards to mitigate potential harms.\",\\n      \"codes\": [\\n        \"\\'High-Risk\\' AI Regulations\",\\n        \"\\'High-Stakes Decision Making\\'\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'Risk-Based\\' Approaches to Regulation\",\\n      \"description\": \"\\'Risk-Based\\' approaches advocate for tailored regulations based on the specific risks associated with different types of AI applications.\",\\n      \"codes\": [\\n        \"\\'Risk-Based Approach Advocacy\\'\",\\n        \"\\'Risk-Based Transparency\\'\",\\n        \"\\'Precision Regulation Approach\\'\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'International Standards\\' Alignment\",\\n      \"description\": \"\\'International Standards\\' alignment discusses the need for global coordination in setting consistent regulations and ethical standards across borders.\",\\n      \"codes\": [\\n        \"\\'Global Coordination for Standards\\'\",\\n        \"\\'International Regulatory Insights\\'\"\\n      ]\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550680, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=628, prompt_tokens=720, total_tokens=1348, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 theme_name  \\\n",
              "0                Importance of Transparency   \n",
              "1                 Governance and Regulation   \n",
              "2              Ethical Considerations in AI   \n",
              "3  Stakeholder Engagement and Collaboration   \n",
              "4                   Education and Awareness   \n",
              "5                'High-Risk' AI Regulations   \n",
              "6     'Risk-Based' Approaches to Regulation   \n",
              "7       'International Standards' Alignment   \n",
              "\n",
              "                                         description  \\\n",
              "0  This group highlights the critical role of tra...   \n",
              "1  This group emphasizes the need for robust gove...   \n",
              "2  This group covers the ethical implications of ...   \n",
              "3  This group focuses on the importance of engagi...   \n",
              "4  This group highlights the significance of educ...   \n",
              "5  'High-Risk' regulations are focused on ensurin...   \n",
              "6  'Risk-Based' approaches advocate for tailored ...   \n",
              "7  'International Standards' alignment discusses ...   \n",
              "\n",
              "                                               codes  \n",
              "0  [Importance of Transparency, AI Transparency I...  \n",
              "1  [Need for Robust Governance, Regulatory Framew...  \n",
              "2  [Ethical Considerations in AI, Bias Mitigation...  \n",
              "3  [Stakeholder Engagement, Community Engagement ...  \n",
              "4  [Training for Workforce, Consumer Education on...  \n",
              "5  ['High-Risk' AI Regulations, 'High-Stakes Deci...  \n",
              "6  ['Risk-Based Approach Advocacy', 'Risk-Based T...  \n",
              "7  ['Global Coordination for Standards', 'Interna...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91015bbc-0494-4453-aa1c-c95cf5918db6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>theme_name</th>\n",
              "      <th>description</th>\n",
              "      <th>codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>This group highlights the critical role of tra...</td>\n",
              "      <td>[Importance of Transparency, AI Transparency I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "      <td>[Need for Robust Governance, Regulatory Framew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>This group covers the ethical implications of ...</td>\n",
              "      <td>[Ethical Considerations in AI, Bias Mitigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This group focuses on the importance of engagi...</td>\n",
              "      <td>[Stakeholder Engagement, Community Engagement ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This group highlights the significance of educ...</td>\n",
              "      <td>[Training for Workforce, Consumer Education on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>'High-Risk' regulations are focused on ensurin...</td>\n",
              "      <td>['High-Risk' AI Regulations, 'High-Stakes Deci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>'Risk-Based' Approaches to Regulation</td>\n",
              "      <td>'Risk-Based' approaches advocate for tailored ...</td>\n",
              "      <td>['Risk-Based Approach Advocacy', 'Risk-Based T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>'International Standards' Alignment</td>\n",
              "      <td>'International Standards' alignment discusses ...</td>\n",
              "      <td>['Global Coordination for Standards', 'Interna...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91015bbc-0494-4453-aa1c-c95cf5918db6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91015bbc-0494-4453-aa1c-c95cf5918db6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91015bbc-0494-4453-aa1c-c95cf5918db6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a23d9c1d-6a05-43a7-9811-e0a07deea456\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a23d9c1d-6a05-43a7-9811-e0a07deea456')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a23d9c1d-6a05-43a7-9811-e0a07deea456 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_79373af2-a909-440a-a981-976307f5069f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_theme3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_79373af2-a909-440a-a981-976307f5069f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_theme3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_theme3",
              "summary": "{\n  \"name\": \"df_theme3\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"theme_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Governance and Regulation\",\n          \"'High-Risk' AI Regulations\",\n          \"Importance of Transparency\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"This group emphasizes the need for robust governance structures and regulatory frameworks to manage AI effectively, ensuring ethical practices and accountability.\",\n          \"'High-Risk' regulations are focused on ensuring that high-stakes applications of AI are held to stringent standards to mitigate potential harms.\",\n          \"This group highlights the critical role of transparency in AI systems, focusing on its necessity for public trust, ethical considerations, and risk mitigation.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"codes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_4 = get_completion(system_text, user_text_2, response_format_2)\n",
        "data4 = json.loads(result_4)\n",
        "df_theme4 = pd.DataFrame(data4[\"Themes\"])\n",
        "df_theme4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "jqkC0u9uzeC6",
        "outputId": "b4faa762-5bd1-445e-9ecd-f8351e29dfe9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BHfTh6DgiJ3HoCRdhzkhBF09TRykR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"theme_name\": \"AI Transparency and Importance\",\\n      \"description\": \"This theme encompasses the critical role of transparency in AI systems, emphasizing the need for clear disclosure, accountability, and ethical considerations.\",\\n      \"codes\": \"Importance of Transparency, AI Transparency Importance, Risk-Based Transparency, Importance of Disclosure\"\\n    },\\n    {\\n      \"theme_name\": \"Governance and Regulation\",\\n      \"description\": \"This theme focuses on the governance frameworks necessary for managing AI technologies responsibly, including regulatory recommendations and coordination across sectors.\",\\n      \"codes\": \"Need for Robust Governance, Regulatory Frameworks Development, Centralized Governance Coordination, Regulatory Framework Recommendations, Regulatory Sandbox Proposal\"\\n    },\\n    {\\n      \"theme_name\": \"Ethics and Responsibility in AI\",\\n      \"description\": \"This theme highlights the ethical implications of AI deployment and the importance of responsible practices in technology development.\",\\n      \"codes\": \"Ethical Considerations in AI, Commitment to Responsible AI, Ethical Data Sharing Practices, Algorithmic Accountability Needs\"\\n    },\\n    {\\n      \"theme_name\": \"Risk Management and Mitigation\",\\n      \"description\": \"This theme addresses the necessity for risk assessments and mitigation strategies associated with AI technologies to ensure safety and public trust.\",\\n      \"codes\": \"Risk-Based Approach Advocacy, Risk Mitigation through Transparency, Ongoing Monitoring Necessity, Human Rights Risk Assessments\"\\n    },\\n    {\\n      \"theme_name\": \"Stakeholder Engagement and Collaboration\",\\n      \"description\": \"This theme emphasizes the need for engagement with various stakeholders including the public and private sectors to enhance trust and collaboration in AI governance.\",\\n      \"codes\": \"Stakeholder Engagement, Community Engagement in Regulation, Public-Private Partnerships, International Collaboration\"\\n    },\\n    {\\n      \"theme_name\": \"Education and Awareness\",\\n      \"description\": \"This theme focuses on the importance of education regarding AI technologies for both users and developers to promote informed decision-making.\",\\n      \"codes\": \"Training for Workforce, Consumer Education on AI Use, Education and Public Awareness, AI Literacy Enhancement\"\\n    },\\n    {\\n      \"theme_name\": \"Transparency Tools and Techniques\",\\n      \"description\": \"This theme covers various tools and methods proposed or required to enhance transparency in AI systems for better user understanding.\",\\n      \"codes\": \"Transparency Tools for Users, Open Access to AI Models, Explainability of AI Systems\"\\n    },\\n    {\\n      \"theme_name\": \"Inclusivity and Fairness\",\\n      \"description\": \"This theme focuses on ensuring inclusivity in AI applications while addressing issues related to bias mitigation and fairness.\",\\n      \"codes\": \"Inclusivity in AI Applications, Fairness and Inclusion Focus, Bias Mitigation Focus\"\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743550717, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=544, prompt_tokens=720, total_tokens=1264, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 theme_name  \\\n",
              "0            AI Transparency and Importance   \n",
              "1                 Governance and Regulation   \n",
              "2           Ethics and Responsibility in AI   \n",
              "3            Risk Management and Mitigation   \n",
              "4  Stakeholder Engagement and Collaboration   \n",
              "5                   Education and Awareness   \n",
              "6         Transparency Tools and Techniques   \n",
              "7                  Inclusivity and Fairness   \n",
              "\n",
              "                                         description  \\\n",
              "0  This theme encompasses the critical role of tr...   \n",
              "1  This theme focuses on the governance framework...   \n",
              "2  This theme highlights the ethical implications...   \n",
              "3  This theme addresses the necessity for risk as...   \n",
              "4  This theme emphasizes the need for engagement ...   \n",
              "5  This theme focuses on the importance of educat...   \n",
              "6  This theme covers various tools and methods pr...   \n",
              "7  This theme focuses on ensuring inclusivity in ...   \n",
              "\n",
              "                                               codes  \n",
              "0  Importance of Transparency, AI Transparency Im...  \n",
              "1  Need for Robust Governance, Regulatory Framewo...  \n",
              "2  Ethical Considerations in AI, Commitment to Re...  \n",
              "3  Risk-Based Approach Advocacy, Risk Mitigation ...  \n",
              "4  Stakeholder Engagement, Community Engagement i...  \n",
              "5  Training for Workforce, Consumer Education on ...  \n",
              "6  Transparency Tools for Users, Open Access to A...  \n",
              "7  Inclusivity in AI Applications, Fairness and I...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1397aace-5c5f-43c2-83a6-3940e3abae3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>theme_name</th>\n",
              "      <th>description</th>\n",
              "      <th>codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AI Transparency and Importance</td>\n",
              "      <td>This theme encompasses the critical role of tr...</td>\n",
              "      <td>Importance of Transparency, AI Transparency Im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This theme focuses on the governance framework...</td>\n",
              "      <td>Need for Robust Governance, Regulatory Framewo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ethics and Responsibility in AI</td>\n",
              "      <td>This theme highlights the ethical implications...</td>\n",
              "      <td>Ethical Considerations in AI, Commitment to Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Risk Management and Mitigation</td>\n",
              "      <td>This theme addresses the necessity for risk as...</td>\n",
              "      <td>Risk-Based Approach Advocacy, Risk Mitigation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme emphasizes the need for engagement ...</td>\n",
              "      <td>Stakeholder Engagement, Community Engagement i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This theme focuses on the importance of educat...</td>\n",
              "      <td>Training for Workforce, Consumer Education on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Transparency Tools and Techniques</td>\n",
              "      <td>This theme covers various tools and methods pr...</td>\n",
              "      <td>Transparency Tools for Users, Open Access to A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Inclusivity and Fairness</td>\n",
              "      <td>This theme focuses on ensuring inclusivity in ...</td>\n",
              "      <td>Inclusivity in AI Applications, Fairness and I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1397aace-5c5f-43c2-83a6-3940e3abae3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1397aace-5c5f-43c2-83a6-3940e3abae3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1397aace-5c5f-43c2-83a6-3940e3abae3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98540a9d-3d88-4d25-8265-59299c56bf36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98540a9d-3d88-4d25-8265-59299c56bf36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98540a9d-3d88-4d25-8265-59299c56bf36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_77d8aaeb-d503-47a2-bfdb-60e816dcda22\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_theme4')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_77d8aaeb-d503-47a2-bfdb-60e816dcda22 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_theme4');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_theme4",
              "summary": "{\n  \"name\": \"df_theme4\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"theme_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Governance and Regulation\",\n          \"Education and Awareness\",\n          \"AI Transparency and Importance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"This theme focuses on the governance frameworks necessary for managing AI technologies responsibly, including regulatory recommendations and coordination across sectors.\",\n          \"This theme focuses on the importance of education regarding AI technologies for both users and developers to promote informed decision-making.\",\n          \"This theme encompasses the critical role of transparency in AI systems, emphasizing the need for clear disclosure, accountability, and ethical considerations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"codes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Need for Robust Governance, Regulatory Frameworks Development, Centralized Governance Coordination, Regulatory Framework Recommendations, Regulatory Sandbox Proposal\",\n          \"Training for Workforce, Consumer Education on AI Use, Education and Public Awareness, AI Literacy Enhancement\",\n          \"Importance of Transparency, AI Transparency Importance, Risk-Based Transparency, Importance of Disclosure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_expanded = pd.DataFrame(columns=['code', 'theme', 'description'])\n",
        "\n",
        "for index, row in df_theme2.iterrows():\n",
        "  codes_str = row['codes']\n",
        "  #codes_list = [code.strip() for code in codes_str.split(',')]\n",
        "  for code in codes_str:\n",
        "    new_row = pd.DataFrame({'code': [code], 'theme': [row['theme_name']], 'description': [row['description']]})\n",
        "    df_expanded = pd.concat([df_expanded, new_row], ignore_index=True)\n",
        "\n",
        "df_expanded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZGYD4Ap7x72c",
        "outputId": "11d28176-d76a-49da-fbf6-ef70331ec72f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    code  \\\n",
              "0             Importance of Transparency   \n",
              "1             AI Transparency Importance   \n",
              "2                 Ongoing Accountability   \n",
              "3                Risk-Based Transparency   \n",
              "4               Importance of Disclosure   \n",
              "5           Explainability of AI Systems   \n",
              "6       Algorithmic Accountability Needs   \n",
              "7             Need for Robust Governance   \n",
              "8      Regulatory Frameworks Development   \n",
              "9   Regulatory Framework Recommendations   \n",
              "10   Centralized Governance Coordination   \n",
              "11              Challenges in Governance   \n",
              "12           Regulatory Sandbox Proposal   \n",
              "13        Risk-Based Regulation Approach   \n",
              "14          Ethical Considerations in AI   \n",
              "15        Inclusivity in AI Applications   \n",
              "16                 Bias Mitigation Focus   \n",
              "17          Commitment to Responsible AI   \n",
              "18         Human Rights Risk Assessments   \n",
              "19                Stakeholder Engagement   \n",
              "20           International Collaboration   \n",
              "21           Public-Private Partnerships   \n",
              "22    Community Engagement in Regulation   \n",
              "23                Training for Workforce   \n",
              "24          Consumer Education on AI Use   \n",
              "25            'High-Risk' AI Regulations   \n",
              "26               AI Literacy Enhancement   \n",
              "27          Risk-Based Approach Advocacy   \n",
              "28            'High-Risk' AI Regulations   \n",
              "29    ...Transparency Tools for Users...   \n",
              "30        ...Public Trust Initiatives...   \n",
              "31        ...Open Access to AI Models...   \n",
              "\n",
              "                                                theme  \\\n",
              "0                  AI Transparency and Accountability   \n",
              "1                  AI Transparency and Accountability   \n",
              "2                  AI Transparency and Accountability   \n",
              "3                  AI Transparency and Accountability   \n",
              "4                  AI Transparency and Accountability   \n",
              "5                  AI Transparency and Accountability   \n",
              "6                  AI Transparency and Accountability   \n",
              "7                Governance and Regulation Frameworks   \n",
              "8                Governance and Regulation Frameworks   \n",
              "9                Governance and Regulation Frameworks   \n",
              "10               Governance and Regulation Frameworks   \n",
              "11               Governance and Regulation Frameworks   \n",
              "12               Governance and Regulation Frameworks   \n",
              "13               Governance and Regulation Frameworks   \n",
              "14           Ethical Considerations and Social Impact   \n",
              "15           Ethical Considerations and Social Impact   \n",
              "16           Ethical Considerations and Social Impact   \n",
              "17           Ethical Considerations and Social Impact   \n",
              "18           Ethical Considerations and Social Impact   \n",
              "19           Stakeholder Engagement and Collaboration   \n",
              "20           Stakeholder Engagement and Collaboration   \n",
              "21           Stakeholder Engagement and Collaboration   \n",
              "22           Stakeholder Engagement and Collaboration   \n",
              "23                     Education and Public Awareness   \n",
              "24                     Education and Public Awareness   \n",
              "25                     Education and Public Awareness   \n",
              "26                     Education and Public Awareness   \n",
              "27             'Risk-Based' Approach to AI Management   \n",
              "28             'Risk-Based' Approach to AI Management   \n",
              "29  'Transparency Tools' for Users and Public Trus...   \n",
              "30  'Transparency Tools' for Users and Public Trus...   \n",
              "31  'Transparency Tools' for Users and Public Trus...   \n",
              "\n",
              "                                          description  \n",
              "0   This group focuses on the importance of transp...  \n",
              "1   This group focuses on the importance of transp...  \n",
              "2   This group focuses on the importance of transp...  \n",
              "3   This group focuses on the importance of transp...  \n",
              "4   This group focuses on the importance of transp...  \n",
              "5   This group focuses on the importance of transp...  \n",
              "6   This group focuses on the importance of transp...  \n",
              "7   This theme encompasses the need for robust gov...  \n",
              "8   This theme encompasses the need for robust gov...  \n",
              "9   This theme encompasses the need for robust gov...  \n",
              "10  This theme encompasses the need for robust gov...  \n",
              "11  This theme encompasses the need for robust gov...  \n",
              "12  This theme encompasses the need for robust gov...  \n",
              "13  This theme encompasses the need for robust gov...  \n",
              "14  This group addresses ethical considerations in...  \n",
              "15  This group addresses ethical considerations in...  \n",
              "16  This group addresses ethical considerations in...  \n",
              "17  This group addresses ethical considerations in...  \n",
              "18  This group addresses ethical considerations in...  \n",
              "19  This theme highlights the importance of engagi...  \n",
              "20  This theme highlights the importance of engagi...  \n",
              "21  This theme highlights the importance of engagi...  \n",
              "22  This theme highlights the importance of engagi...  \n",
              "23  This group emphasizes the need for education r...  \n",
              "24  This group emphasizes the need for education r...  \n",
              "25  This group emphasizes the need for education r...  \n",
              "26  This group emphasizes the need for education r...  \n",
              "27  'Risk-based' approaches advocate for tailored ...  \n",
              "28  'Risk-based' approaches advocate for tailored ...  \n",
              "29  'Transparency tools' are mechanisms designed t...  \n",
              "30  'Transparency tools' are mechanisms designed t...  \n",
              "31  'Transparency tools' are mechanisms designed t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcf993f5-78e6-4b73-84b8-a03fd84506df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>theme</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI Transparency Importance</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ongoing Accountability</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Risk-Based Transparency</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Importance of Disclosure</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Explainability of AI Systems</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Algorithmic Accountability Needs</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>This group focuses on the importance of transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Need for Robust Governance</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regulatory Frameworks Development</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Regulatory Framework Recommendations</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Centralized Governance Coordination</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Challenges in Governance</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Regulatory Sandbox Proposal</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Risk-Based Regulation Approach</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>This theme encompasses the need for robust gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Ethical Considerations and Social Impact</td>\n",
              "      <td>This group addresses ethical considerations in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Inclusivity in AI Applications</td>\n",
              "      <td>Ethical Considerations and Social Impact</td>\n",
              "      <td>This group addresses ethical considerations in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Bias Mitigation Focus</td>\n",
              "      <td>Ethical Considerations and Social Impact</td>\n",
              "      <td>This group addresses ethical considerations in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Commitment to Responsible AI</td>\n",
              "      <td>Ethical Considerations and Social Impact</td>\n",
              "      <td>This group addresses ethical considerations in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Human Rights Risk Assessments</td>\n",
              "      <td>Ethical Considerations and Social Impact</td>\n",
              "      <td>This group addresses ethical considerations in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Stakeholder Engagement</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme highlights the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>International Collaboration</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme highlights the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Public-Private Partnerships</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme highlights the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Community Engagement in Regulation</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme highlights the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Training for Workforce</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>This group emphasizes the need for education r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Consumer Education on AI Use</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>This group emphasizes the need for education r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>This group emphasizes the need for education r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>AI Literacy Enhancement</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>This group emphasizes the need for education r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Risk-Based Approach Advocacy</td>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-based' approaches advocate for tailored ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-based' approaches advocate for tailored ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>...Transparency Tools for Users...</td>\n",
              "      <td>'Transparency Tools' for Users and Public Trus...</td>\n",
              "      <td>'Transparency tools' are mechanisms designed t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>...Public Trust Initiatives...</td>\n",
              "      <td>'Transparency Tools' for Users and Public Trus...</td>\n",
              "      <td>'Transparency tools' are mechanisms designed t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>...Open Access to AI Models...</td>\n",
              "      <td>'Transparency Tools' for Users and Public Trus...</td>\n",
              "      <td>'Transparency tools' are mechanisms designed t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcf993f5-78e6-4b73-84b8-a03fd84506df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcf993f5-78e6-4b73-84b8-a03fd84506df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcf993f5-78e6-4b73-84b8-a03fd84506df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d2d9bb9-648a-4e5d-b014-8d02486f2186\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d2d9bb9-648a-4e5d-b014-8d02486f2186')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d2d9bb9-648a-4e5d-b014-8d02486f2186 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_47c3003e-f8bf-45f0-b811-8995745345ae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_expanded')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_47c3003e-f8bf-45f0-b811-8995745345ae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_expanded');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_expanded",
              "summary": "{\n  \"name\": \"df_expanded\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"Risk-Based Approach Advocacy\",\n          \"Inclusivity in AI Applications\",\n          \"Training for Workforce\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theme\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"AI Transparency and Accountability\",\n          \"Governance and Regulation Frameworks\",\n          \"'Risk-Based' Approach to AI Management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"This group focuses on the importance of transparency in AI systems and the need for accountability mechanisms to ensure ethical use.\",\n          \"This theme encompasses the need for robust governance structures and regulatory frameworks to manage AI technologies effectively.\",\n          \"'Risk-based' approaches advocate for tailored regulations based on the risk level associated with different AI applications.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_expanded2 = pd.DataFrame(columns=['code', 'theme', 'description'])\n",
        "\n",
        "for index, row in df_theme3.iterrows():\n",
        "  codes_str = row['codes']\n",
        "  #codes_list = [code.strip() for code in codes_str.split(',')]\n",
        "  for code in codes_str:\n",
        "    new_row = pd.DataFrame({'code': [code], 'theme': [row['theme_name']], 'description': [row['description']]})\n",
        "    df_expanded2 = pd.concat([df_expanded2, new_row], ignore_index=True)\n",
        "\n",
        "df_expanded2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "ji-X8jL57JJM",
        "outputId": "43721412-c598-4e5f-f015-53b792900b89",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    code  \\\n",
              "0             Importance of Transparency   \n",
              "1             AI Transparency Importance   \n",
              "2   Risk Mitigation through Transparency   \n",
              "3               Importance of Disclosure   \n",
              "4           Explainability of AI Systems   \n",
              "5             Need for Robust Governance   \n",
              "6      Regulatory Frameworks Development   \n",
              "7    Centralized Governance Coordination   \n",
              "8   Regulatory Framework Recommendations   \n",
              "9         Risk-Based Regulation Approach   \n",
              "10    Transparent Disclosure Obligations   \n",
              "11          Ethical Considerations in AI   \n",
              "12                 Bias Mitigation Focus   \n",
              "13         Human Rights Risk Assessments   \n",
              "14      Algorithmic Accountability Needs   \n",
              "15                Stakeholder Engagement   \n",
              "16    Community Engagement in Regulation   \n",
              "17           Public-Private Partnerships   \n",
              "18           International Collaboration   \n",
              "19                Training for Workforce   \n",
              "20          Consumer Education on AI Use   \n",
              "21             'AI Literacy Enhancement'   \n",
              "22               AI Education Importance   \n",
              "23            'High-Risk' AI Regulations   \n",
              "24         'High-Stakes Decision Making'   \n",
              "25        'Risk-Based Approach Advocacy'   \n",
              "26             'Risk-Based Transparency'   \n",
              "27       'Precision Regulation Approach'   \n",
              "28   'Global Coordination for Standards'   \n",
              "29   'International Regulatory Insights'   \n",
              "\n",
              "                                       theme  \\\n",
              "0                 Importance of Transparency   \n",
              "1                 Importance of Transparency   \n",
              "2                 Importance of Transparency   \n",
              "3                 Importance of Transparency   \n",
              "4                 Importance of Transparency   \n",
              "5                  Governance and Regulation   \n",
              "6                  Governance and Regulation   \n",
              "7                  Governance and Regulation   \n",
              "8                  Governance and Regulation   \n",
              "9                  Governance and Regulation   \n",
              "10                 Governance and Regulation   \n",
              "11              Ethical Considerations in AI   \n",
              "12              Ethical Considerations in AI   \n",
              "13              Ethical Considerations in AI   \n",
              "14              Ethical Considerations in AI   \n",
              "15  Stakeholder Engagement and Collaboration   \n",
              "16  Stakeholder Engagement and Collaboration   \n",
              "17  Stakeholder Engagement and Collaboration   \n",
              "18  Stakeholder Engagement and Collaboration   \n",
              "19                   Education and Awareness   \n",
              "20                   Education and Awareness   \n",
              "21                   Education and Awareness   \n",
              "22                   Education and Awareness   \n",
              "23                'High-Risk' AI Regulations   \n",
              "24                'High-Risk' AI Regulations   \n",
              "25     'Risk-Based' Approaches to Regulation   \n",
              "26     'Risk-Based' Approaches to Regulation   \n",
              "27     'Risk-Based' Approaches to Regulation   \n",
              "28       'International Standards' Alignment   \n",
              "29       'International Standards' Alignment   \n",
              "\n",
              "                                          description  \n",
              "0   This group highlights the critical role of tra...  \n",
              "1   This group highlights the critical role of tra...  \n",
              "2   This group highlights the critical role of tra...  \n",
              "3   This group highlights the critical role of tra...  \n",
              "4   This group highlights the critical role of tra...  \n",
              "5   This group emphasizes the need for robust gove...  \n",
              "6   This group emphasizes the need for robust gove...  \n",
              "7   This group emphasizes the need for robust gove...  \n",
              "8   This group emphasizes the need for robust gove...  \n",
              "9   This group emphasizes the need for robust gove...  \n",
              "10  This group emphasizes the need for robust gove...  \n",
              "11  This group covers the ethical implications of ...  \n",
              "12  This group covers the ethical implications of ...  \n",
              "13  This group covers the ethical implications of ...  \n",
              "14  This group covers the ethical implications of ...  \n",
              "15  This group focuses on the importance of engagi...  \n",
              "16  This group focuses on the importance of engagi...  \n",
              "17  This group focuses on the importance of engagi...  \n",
              "18  This group focuses on the importance of engagi...  \n",
              "19  This group highlights the significance of educ...  \n",
              "20  This group highlights the significance of educ...  \n",
              "21  This group highlights the significance of educ...  \n",
              "22  This group highlights the significance of educ...  \n",
              "23  'High-Risk' regulations are focused on ensurin...  \n",
              "24  'High-Risk' regulations are focused on ensurin...  \n",
              "25  'Risk-Based' approaches advocate for tailored ...  \n",
              "26  'Risk-Based' approaches advocate for tailored ...  \n",
              "27  'Risk-Based' approaches advocate for tailored ...  \n",
              "28  'International Standards' alignment discusses ...  \n",
              "29  'International Standards' alignment discusses ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5bc4717-ac2a-40d2-852d-23ea5b6ebcf5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>theme</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>This group highlights the critical role of tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI Transparency Importance</td>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>This group highlights the critical role of tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Risk Mitigation through Transparency</td>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>This group highlights the critical role of tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Importance of Disclosure</td>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>This group highlights the critical role of tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Explainability of AI Systems</td>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>This group highlights the critical role of tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Need for Robust Governance</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regulatory Frameworks Development</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Centralized Governance Coordination</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regulatory Framework Recommendations</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Risk-Based Regulation Approach</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transparent Disclosure Obligations</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This group emphasizes the need for robust gove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>This group covers the ethical implications of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bias Mitigation Focus</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>This group covers the ethical implications of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Human Rights Risk Assessments</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>This group covers the ethical implications of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Algorithmic Accountability Needs</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>This group covers the ethical implications of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Stakeholder Engagement</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This group focuses on the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Community Engagement in Regulation</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This group focuses on the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Public-Private Partnerships</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This group focuses on the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>International Collaboration</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This group focuses on the importance of engagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Training for Workforce</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This group highlights the significance of educ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Consumer Education on AI Use</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This group highlights the significance of educ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>'AI Literacy Enhancement'</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This group highlights the significance of educ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>AI Education Importance</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This group highlights the significance of educ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>'High-Risk' regulations are focused on ensurin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>'High-Stakes Decision Making'</td>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>'High-Risk' regulations are focused on ensurin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>'Risk-Based Approach Advocacy'</td>\n",
              "      <td>'Risk-Based' Approaches to Regulation</td>\n",
              "      <td>'Risk-Based' approaches advocate for tailored ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>'Risk-Based Transparency'</td>\n",
              "      <td>'Risk-Based' Approaches to Regulation</td>\n",
              "      <td>'Risk-Based' approaches advocate for tailored ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>'Precision Regulation Approach'</td>\n",
              "      <td>'Risk-Based' Approaches to Regulation</td>\n",
              "      <td>'Risk-Based' approaches advocate for tailored ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>'Global Coordination for Standards'</td>\n",
              "      <td>'International Standards' Alignment</td>\n",
              "      <td>'International Standards' alignment discusses ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>'International Regulatory Insights'</td>\n",
              "      <td>'International Standards' Alignment</td>\n",
              "      <td>'International Standards' alignment discusses ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5bc4717-ac2a-40d2-852d-23ea5b6ebcf5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5bc4717-ac2a-40d2-852d-23ea5b6ebcf5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5bc4717-ac2a-40d2-852d-23ea5b6ebcf5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ece8a7ec-8f17-48ec-adb5-8037d82926ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ece8a7ec-8f17-48ec-adb5-8037d82926ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ece8a7ec-8f17-48ec-adb5-8037d82926ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8c2cdf43-c125-4bb9-8481-7aa72a882a9c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_expanded2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8c2cdf43-c125-4bb9-8481-7aa72a882a9c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_expanded2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_expanded2",
              "summary": "{\n  \"name\": \"df_expanded2\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"'Precision Regulation Approach'\",\n          \"Stakeholder Engagement\",\n          \"'High-Risk' AI Regulations\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theme\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Governance and Regulation\",\n          \"'High-Risk' AI Regulations\",\n          \"Importance of Transparency\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"This group emphasizes the need for robust governance structures and regulatory frameworks to manage AI effectively, ensuring ethical practices and accountability.\",\n          \"'High-Risk' regulations are focused on ensuring that high-stakes applications of AI are held to stringent standards to mitigate potential harms.\",\n          \"This group highlights the critical role of transparency in AI systems, focusing on its necessity for public trust, ethical considerations, and risk mitigation.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_expanded3 = pd.DataFrame(columns=['code', 'theme', 'description'])\n",
        "\n",
        "for index, row in df_theme4.iterrows():\n",
        "  codes_str = row['codes']\n",
        "  codes_list = [code.strip() for code in codes_str.split(',')]\n",
        "  for code in codes_list:\n",
        "    new_row = pd.DataFrame({'code': [code], 'theme': [row['theme_name']], 'description': [row['description']]})\n",
        "    df_expanded3 = pd.concat([df_expanded3, new_row], ignore_index=True)\n",
        "\n",
        "df_expanded3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MkNIuCQx7s8R",
        "outputId": "88ce1471-510b-45de-b4bf-0172a9d1e5e6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    code  \\\n",
              "0             Importance of Transparency   \n",
              "1             AI Transparency Importance   \n",
              "2                Risk-Based Transparency   \n",
              "3               Importance of Disclosure   \n",
              "4             Need for Robust Governance   \n",
              "5      Regulatory Frameworks Development   \n",
              "6    Centralized Governance Coordination   \n",
              "7   Regulatory Framework Recommendations   \n",
              "8            Regulatory Sandbox Proposal   \n",
              "9           Ethical Considerations in AI   \n",
              "10          Commitment to Responsible AI   \n",
              "11        Ethical Data Sharing Practices   \n",
              "12      Algorithmic Accountability Needs   \n",
              "13          Risk-Based Approach Advocacy   \n",
              "14  Risk Mitigation through Transparency   \n",
              "15          Ongoing Monitoring Necessity   \n",
              "16         Human Rights Risk Assessments   \n",
              "17                Stakeholder Engagement   \n",
              "18    Community Engagement in Regulation   \n",
              "19           Public-Private Partnerships   \n",
              "20           International Collaboration   \n",
              "21                Training for Workforce   \n",
              "22          Consumer Education on AI Use   \n",
              "23        Education and Public Awareness   \n",
              "24               AI Literacy Enhancement   \n",
              "25          Transparency Tools for Users   \n",
              "26              Open Access to AI Models   \n",
              "27          Explainability of AI Systems   \n",
              "28        Inclusivity in AI Applications   \n",
              "29          Fairness and Inclusion Focus   \n",
              "30                 Bias Mitigation Focus   \n",
              "\n",
              "                                       theme  \\\n",
              "0             AI Transparency and Importance   \n",
              "1             AI Transparency and Importance   \n",
              "2             AI Transparency and Importance   \n",
              "3             AI Transparency and Importance   \n",
              "4                  Governance and Regulation   \n",
              "5                  Governance and Regulation   \n",
              "6                  Governance and Regulation   \n",
              "7                  Governance and Regulation   \n",
              "8                  Governance and Regulation   \n",
              "9            Ethics and Responsibility in AI   \n",
              "10           Ethics and Responsibility in AI   \n",
              "11           Ethics and Responsibility in AI   \n",
              "12           Ethics and Responsibility in AI   \n",
              "13            Risk Management and Mitigation   \n",
              "14            Risk Management and Mitigation   \n",
              "15            Risk Management and Mitigation   \n",
              "16            Risk Management and Mitigation   \n",
              "17  Stakeholder Engagement and Collaboration   \n",
              "18  Stakeholder Engagement and Collaboration   \n",
              "19  Stakeholder Engagement and Collaboration   \n",
              "20  Stakeholder Engagement and Collaboration   \n",
              "21                   Education and Awareness   \n",
              "22                   Education and Awareness   \n",
              "23                   Education and Awareness   \n",
              "24                   Education and Awareness   \n",
              "25         Transparency Tools and Techniques   \n",
              "26         Transparency Tools and Techniques   \n",
              "27         Transparency Tools and Techniques   \n",
              "28                  Inclusivity and Fairness   \n",
              "29                  Inclusivity and Fairness   \n",
              "30                  Inclusivity and Fairness   \n",
              "\n",
              "                                          description  \n",
              "0   This theme encompasses the critical role of tr...  \n",
              "1   This theme encompasses the critical role of tr...  \n",
              "2   This theme encompasses the critical role of tr...  \n",
              "3   This theme encompasses the critical role of tr...  \n",
              "4   This theme focuses on the governance framework...  \n",
              "5   This theme focuses on the governance framework...  \n",
              "6   This theme focuses on the governance framework...  \n",
              "7   This theme focuses on the governance framework...  \n",
              "8   This theme focuses on the governance framework...  \n",
              "9   This theme highlights the ethical implications...  \n",
              "10  This theme highlights the ethical implications...  \n",
              "11  This theme highlights the ethical implications...  \n",
              "12  This theme highlights the ethical implications...  \n",
              "13  This theme addresses the necessity for risk as...  \n",
              "14  This theme addresses the necessity for risk as...  \n",
              "15  This theme addresses the necessity for risk as...  \n",
              "16  This theme addresses the necessity for risk as...  \n",
              "17  This theme emphasizes the need for engagement ...  \n",
              "18  This theme emphasizes the need for engagement ...  \n",
              "19  This theme emphasizes the need for engagement ...  \n",
              "20  This theme emphasizes the need for engagement ...  \n",
              "21  This theme focuses on the importance of educat...  \n",
              "22  This theme focuses on the importance of educat...  \n",
              "23  This theme focuses on the importance of educat...  \n",
              "24  This theme focuses on the importance of educat...  \n",
              "25  This theme covers various tools and methods pr...  \n",
              "26  This theme covers various tools and methods pr...  \n",
              "27  This theme covers various tools and methods pr...  \n",
              "28  This theme focuses on ensuring inclusivity in ...  \n",
              "29  This theme focuses on ensuring inclusivity in ...  \n",
              "30  This theme focuses on ensuring inclusivity in ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fcc3db4-047b-4677-b2b6-7aa64cb84942\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>theme</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>AI Transparency and Importance</td>\n",
              "      <td>This theme encompasses the critical role of tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI Transparency Importance</td>\n",
              "      <td>AI Transparency and Importance</td>\n",
              "      <td>This theme encompasses the critical role of tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Risk-Based Transparency</td>\n",
              "      <td>AI Transparency and Importance</td>\n",
              "      <td>This theme encompasses the critical role of tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Importance of Disclosure</td>\n",
              "      <td>AI Transparency and Importance</td>\n",
              "      <td>This theme encompasses the critical role of tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Need for Robust Governance</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This theme focuses on the governance framework...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regulatory Frameworks Development</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This theme focuses on the governance framework...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Centralized Governance Coordination</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This theme focuses on the governance framework...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regulatory Framework Recommendations</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This theme focuses on the governance framework...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regulatory Sandbox Proposal</td>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>This theme focuses on the governance framework...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Ethics and Responsibility in AI</td>\n",
              "      <td>This theme highlights the ethical implications...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Commitment to Responsible AI</td>\n",
              "      <td>Ethics and Responsibility in AI</td>\n",
              "      <td>This theme highlights the ethical implications...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Ethical Data Sharing Practices</td>\n",
              "      <td>Ethics and Responsibility in AI</td>\n",
              "      <td>This theme highlights the ethical implications...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Algorithmic Accountability Needs</td>\n",
              "      <td>Ethics and Responsibility in AI</td>\n",
              "      <td>This theme highlights the ethical implications...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Risk-Based Approach Advocacy</td>\n",
              "      <td>Risk Management and Mitigation</td>\n",
              "      <td>This theme addresses the necessity for risk as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Risk Mitigation through Transparency</td>\n",
              "      <td>Risk Management and Mitigation</td>\n",
              "      <td>This theme addresses the necessity for risk as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Ongoing Monitoring Necessity</td>\n",
              "      <td>Risk Management and Mitigation</td>\n",
              "      <td>This theme addresses the necessity for risk as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Human Rights Risk Assessments</td>\n",
              "      <td>Risk Management and Mitigation</td>\n",
              "      <td>This theme addresses the necessity for risk as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Stakeholder Engagement</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme emphasizes the need for engagement ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Community Engagement in Regulation</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme emphasizes the need for engagement ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Public-Private Partnerships</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme emphasizes the need for engagement ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>International Collaboration</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>This theme emphasizes the need for engagement ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Training for Workforce</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This theme focuses on the importance of educat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Consumer Education on AI Use</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This theme focuses on the importance of educat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This theme focuses on the importance of educat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>AI Literacy Enhancement</td>\n",
              "      <td>Education and Awareness</td>\n",
              "      <td>This theme focuses on the importance of educat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Transparency Tools for Users</td>\n",
              "      <td>Transparency Tools and Techniques</td>\n",
              "      <td>This theme covers various tools and methods pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Open Access to AI Models</td>\n",
              "      <td>Transparency Tools and Techniques</td>\n",
              "      <td>This theme covers various tools and methods pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Explainability of AI Systems</td>\n",
              "      <td>Transparency Tools and Techniques</td>\n",
              "      <td>This theme covers various tools and methods pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Inclusivity in AI Applications</td>\n",
              "      <td>Inclusivity and Fairness</td>\n",
              "      <td>This theme focuses on ensuring inclusivity in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Fairness and Inclusion Focus</td>\n",
              "      <td>Inclusivity and Fairness</td>\n",
              "      <td>This theme focuses on ensuring inclusivity in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Bias Mitigation Focus</td>\n",
              "      <td>Inclusivity and Fairness</td>\n",
              "      <td>This theme focuses on ensuring inclusivity in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fcc3db4-047b-4677-b2b6-7aa64cb84942')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fcc3db4-047b-4677-b2b6-7aa64cb84942 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fcc3db4-047b-4677-b2b6-7aa64cb84942');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3c262a6-9b23-4015-af2c-dcc55e83f96b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3c262a6-9b23-4015-af2c-dcc55e83f96b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3c262a6-9b23-4015-af2c-dcc55e83f96b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c3137fef-a4e2-4044-93e2-dab5cef16ca5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_expanded3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c3137fef-a4e2-4044-93e2-dab5cef16ca5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_expanded3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_expanded3",
              "summary": "{\n  \"name\": \"df_expanded3\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"Explainability of AI Systems\",\n          \"Ongoing Monitoring Necessity\",\n          \"Education and Public Awareness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theme\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Governance and Regulation\",\n          \"Education and Awareness\",\n          \"AI Transparency and Importance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"This theme focuses on the governance frameworks necessary for managing AI technologies responsibly, including regulatory recommendations and coordination across sectors.\",\n          \"This theme focuses on the importance of education regarding AI technologies for both users and developers to promote informed decision-making.\",\n          \"This theme encompasses the critical role of transparency in AI systems, emphasizing the need for clear disclosure, accountability, and ethical considerations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df_theme4 is not None:\n",
        "    excel_filepath = \"/content/drive/MyDrive/themes_8_docs_3.xlsx\"  # Replace with desired path\n",
        "    df_theme4.to_excel(excel_filepath, index=False)  # Set index=False to avoid writing row indices\n",
        "    print(f\"DataFrame exported to: {excel_filepath}\")\n",
        "else:\n",
        "    print(\"DataFrame 'df_theme' is empty or None. Cannot export.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jF14urYYl74",
        "outputId": "88e3a089-3fb7-4513-a8d2-74a30e1076d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame exported to: /content/drive/MyDrive/themes_8_docs_3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df_expanded is not None:\n",
        "    excel_filepath = \"/content/drive/MyDrive/themes_8_docs_expanded_2.xlsx\"  # Replace with desired path\n",
        "    df_expanded.to_excel(excel_filepath, index=False)  # Set index=False to avoid writing row indices\n",
        "    print(f\"DataFrame exported to: {excel_filepath}\")\n",
        "else:\n",
        "    print(\"DataFrame 'df_theme' is empty or None. Cannot export.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXX-Itugyb-S",
        "outputId": "14552e35-4e88-45d4-e56d-98049cb7c4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame exported to: /content/drive/MyDrive/themes_8_docs_expanded_2.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excel_filepath2 = \"/content/drive/MyDrive/themes_8_docs_expanded_2.xlsx\"\n",
        "excel_filepath3 = \"/content/drive/MyDrive/themes_8_docs_2_expanded_2.xlsx\"\n",
        "excel_filepath4 = \"/content/drive/MyDrive/themes_8_docs_3_expanded_2.xlsx\"\n",
        "df_theme2 = pd.read_excel(excel_filepath2)\n",
        "df_theme3 = pd.read_excel(excel_filepath3)\n",
        "df_theme4 = pd.read_excel(excel_filepath4)"
      ],
      "metadata": {
        "id": "fjMbdztFMxtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4\n",
        "\n",
        "formatted_themes1 = df_theme2['theme'].unique()\n",
        "formatted_themes1 = ', '.join(formatted_themes1)\n",
        "formatted_themes2 = df_theme3['theme'].unique()\n",
        "formatted_themes2 = ', '.join(formatted_themes2)\n",
        "formatted_themes3 = df_theme4['theme'].unique()\n",
        "formatted_themes3 = ', '.join(formatted_themes3)\n",
        "#formatted_themes2 = df_theme3['theme'].unique().to_string(index=False)\n",
        "\n",
        "user_text_4 = f\"\"\"\n",
        "Given the following topics:\n",
        "\\\"\\\"\\\"\\n{formatted_codes}\\n\\\"\\\"\\\"\n",
        "\n",
        "Determine how all the topics in the list of topics can be grouped together.\n",
        "Topics can be in more than one group. Provide a name and description for each group, followed by all the topics in the group.\n",
        "\n",
        "Here are the three groupings of topics proposed:\n",
        "\\\"\\\"\\\"\\nOption 1:{formatted_themes1}\\n\\\"\\\"\\\"\n",
        "\\\"\\\"\\\"\\nOption 2:{formatted_themes2}\\n\\\"\\\"\\\"\n",
        "\\\"\\\"\\\"\\nOption 3:{formatted_themes3}\\n\\\"\\\"\\\"\n",
        "\n",
        "List the areas for refinement and faulty logic of each answer option. Let’s work this out in a step by step way to be sure we have all the errors:\n",
        "\"\"\"\n",
        "\n",
        "response_format_4={\n",
        "        \"type\": \"text\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "LNbGauyTz5Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_4 = get_completion(system_text, user_text_4, response_format_4)"
      ],
      "metadata": {
        "id": "dje-ZLJgnjbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Kul_CFITjSH6",
        "outputId": "7742f491-0982-4d77-f4ec-75d4d16bb634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Let\\'s analyze each of the proposed options step by step to identify areas for refinement and any faulty logic. \\n\\n### Option 1:\\n**Groups:**\\n1. **AI Transparency and Accountability**\\n2. **Governance and Regulation Frameworks**\\n3. **Ethical Considerations and Social Impact**\\n4. **Stakeholder Engagement and Collaboration**\\n5. **Education and Public Awareness**\\n6. **\\'Risk-Based\\' Approach to AI Management**\\n7. **\\'Transparency Tools\\' for Users and Public Trust Initiatives**\\n\\n**Areas for Refinement/Faulty Logic:**\\n- The grouping \"AI Transparency and Accountability\" includes both transparency topics and accountability, but it may lack specificity regarding how these two concepts interact.\\n- \"Governance and Regulation Frameworks\" could be more explicit in differentiating between various regulatory approaches or frameworks (e.g., risk-based vs. centralized).\\n- The term \"Ethical Considerations and Social Impact\" could be refined to ensure it captures specific ethical dilemmas versus general social impact.\\n- \"Education and Public Awareness\" could be further broken down into different types of education (e.g., workforce training vs. consumer education).\\n- The inclusion of both \"Risk-Based Approach to AI Management\" and \"\\'Risk-Based\\' Approach to Regulation\" may lead to redundancy as they seem to convey similar ideas.\\n- \"Transparency Tools for Users and Public Trust Initiatives\" could be more focused; combining these two distinct concepts may dilute their individual importance.\\n\\n### Option 2:\\n**Groups:**\\n1. **Importance of Transparency**\\n2. **Governance and Regulation**\\n3. **Ethical Considerations in AI**\\n4. **Stakeholder Engagement and Collaboration**\\n5. **Education and Awareness**\\n6. **\\'High-Risk\\' AI Regulations**\\n7. **\\'Risk-Based\\' Approaches to Regulation**\\n8. **\\'International Standards\\' Alignment**\\n\\n**Areas for Refinement/Faulty Logic:**\\n- The group \"Importance of Transparency\" seems somewhat vague; it might benefit from specifying what aspects of transparency are being prioritized.\\n- \"Governance and Regulation\" could be broken down further into specific frameworks or mechanisms, such as centralized governance or self-regulation.\\n- Including both \"High-Risk AI Regulations\" and \"\\'Risk-Based\\' Approaches to Regulation\" raises concerns about redundancy, as both address risk management but from different perspectives.\\n- The term \"International Standards Alignment\" might not directly correlate with the other groups unless there is a clearer link to how it affects governance or ethical considerations.\\n\\n### Option 3:\\n**Groups:**\\n1. **AI Transparency and Importance**\\n2. **Governance and Regulation**\\n3. **Ethics and Responsibility in AI**\\n4. **Risk Management and Mitigation**\\n5. **Stakeholder Engagement and Collaboration**\\n6. **Education and Awareness**\\n7. **Transparency Tools and Techniques**\\n8. **Inclusivity and Fairness**\\n\\n**Areas for Refinement/Faulty Logic:**\\n- The title \"AI Transparency and Importance\" could be confusing; it\\'s unclear if it focuses on the importance of transparency itself or transparency\\'s role within AI.\\n- The term \"Governance and Regulation\" is broad; more specific categories might help clarify different regulatory approaches (e.g., self-regulation vs government mandates).\\n- \"Ethics and Responsibility in AI\" might benefit from further elaboration on how responsibility translates into practical guidelines or actions.\\n- While “Risk Management” is crucial, the connection between this group and others like “Inclusivity” may not be explicit, requiring further explanation on how inclusivity relates to risk management.\\n- Including both “Transparency Tools” as well as general references to transparency in multiple groups may create overlap without clear distinctions.\\n\\n### Summary\\nEach option has strengths but also presents opportunities for refinement in clarity, specificity, differentiation, redundancy, or potential overlaps among groups that could confuse the relationships between concepts related to AI transparency, governance, ethics, stakeholder engagement, education, regulation, risk management, inclusivity, fairness, etc.\\n\\nIn refining these options further, it\\'s important to consider clearer definitions for each group while minimizing redundancy between them—ensuring that each group\\'s content adds distinct value to the overall understanding of the topics related to mandating AI transparency in organizations.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_4 = f\"\"\"\n",
        "Let's analyze each of the proposed options step by step to identify areas for refinement and any faulty logic.\n",
        "\n",
        "### Option 1:\n",
        "**Groups:**\n",
        "1. **AI Transparency and Accountability**\n",
        "2. **Governance and Regulation Frameworks**\n",
        "3. **Ethical Considerations and Social Impact**\n",
        "4. **Stakeholder Engagement and Collaboration**\n",
        "5. **Education and Public Awareness**\n",
        "6. **'Risk-Based' Approach to AI Management**\n",
        "7. **'Transparency Tools' for Users and Public Trust Initiatives**\n",
        "\n",
        "**Areas for Refinement/Faulty Logic:**\n",
        "- The grouping \"AI Transparency and Accountability\" includes both transparency topics and accountability, but it may lack specificity regarding how these two concepts interact.\n",
        "- \"Governance and Regulation Frameworks\" could be more explicit in differentiating between various regulatory approaches or frameworks (e.g., risk-based vs. centralized).\n",
        "- The term \"Ethical Considerations and Social Impact\" could be refined to ensure it captures specific ethical dilemmas versus general social impact.\n",
        "- \"Education and Public Awareness\" could be further broken down into different types of education (e.g., workforce training vs. consumer education).\n",
        "- The inclusion of both \"Risk-Based Approach to AI Management\" and \"'Risk-Based' Approach to Regulation\" may lead to redundancy as they seem to convey similar ideas.\n",
        "- \"Transparency Tools for Users and Public Trust Initiatives\" could be more focused; combining these two distinct concepts may dilute their individual importance.\n",
        "\n",
        "### Option 2:\n",
        "**Groups:**\n",
        "1. **Importance of Transparency**\n",
        "2. **Governance and Regulation**\n",
        "3. **Ethical Considerations in AI**\n",
        "4. **Stakeholder Engagement and Collaboration**\n",
        "5. **Education and Awareness**\n",
        "6. **'High-Risk' AI Regulations**\n",
        "7. **'Risk-Based' Approaches to Regulation**\n",
        "8. **'International Standards' Alignment**\n",
        "\n",
        "**Areas for Refinement/Faulty Logic:**\n",
        "- The group \"Importance of Transparency\" seems somewhat vague; it might benefit from specifying what aspects of transparency are being prioritized.\n",
        "- \"Governance and Regulation\" could be broken down further into specific frameworks or mechanisms, such as centralized governance or self-regulation.\n",
        "- Including both \"High-Risk AI Regulations\" and \"'Risk-Based' Approaches to Regulation\" raises concerns about redundancy, as both address risk management but from different perspectives.\n",
        "- The term \"International Standards Alignment\" might not directly correlate with the other groups unless there is a clearer link to how it affects governance or ethical considerations.\n",
        "\n",
        "### Option 3:\n",
        "**Groups:**\n",
        "1. **AI Transparency and Importance**\n",
        "2. **Governance and Regulation**\n",
        "3. **Ethics and Responsibility in AI**\n",
        "4. **Risk Management and Mitigation**\n",
        "5. **Stakeholder Engagement and Collaboration**\n",
        "6. **Education and Awareness**\n",
        "7. **Transparency Tools and Techniques**\n",
        "8. **Inclusivity and Fairness**\n",
        "\n",
        "**Areas for Refinement/Faulty Logic:**\n",
        "- The title \"AI Transparency and Importance\" could be confusing; it's unclear if it focuses on the importance of transparency itself or transparency's role within AI.\n",
        "- The term \"Governance and Regulation\" is broad; more specific categories might help clarify different regulatory approaches (e.g., self-regulation vs government mandates).\n",
        "- \"Ethics and Responsibility in AI\" might benefit from further elaboration on how responsibility translates into practical guidelines or actions.\n",
        "- While “Risk Management” is crucial, the connection between this group and others like “Inclusivity” may not be explicit, requiring further explanation on how inclusivity relates to risk management.\n",
        "- Including both “Transparency Tools” as well as general references to transparency in multiple groups may create overlap without clear distinctions.\n",
        "\n",
        "### Summary\n",
        "Each option has strengths but also presents opportunities for refinement in clarity, specificity, differentiation, redundancy, or potential overlaps among groups that could confuse the relationships between concepts related to AI transparency, governance, ethics, stakeholder engagement, education, regulation, risk management, inclusivity, fairness, etc.\n",
        "\n",
        "In refining these options further, it's important to consider clearer definitions for each group while minimizing redundancy between them—ensuring that each group's content adds distinct value to the overall understanding of the topics related to mandating AI transparency in organizations.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vQZU5nd1mHbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5\n",
        "\n",
        "user_text_5 = f\"\"\"\n",
        "Given the following topics:\n",
        "\\\"\\\"\\\"\\n{formatted_codes}\\n\\\"\\\"\\\"\n",
        "\n",
        "Determine how all the topics in the list of topics can be grouped together.\n",
        "Topics can be in more than one group. Provide a name and description for each group, followed by all the topics in the group.\n",
        "\n",
        "Here are the three groupings of topics proposed:\n",
        "\\\"\\\"\\\"\\nOption 1:{formatted_themes1}\\n\\\"\\\"\\\"\n",
        "\\\"\\\"\\\"\\nOption 2:{formatted_themes2}\\n\\\"\\\"\\\"\n",
        "\\\"\\\"\\\"\\nOption 3:{formatted_themes3}\\n\\\"\\\"\\\"\n",
        "\n",
        "Here is the assessment of the three groupings:\n",
        "\\\"\\\"\\\"\\n{result_4}\n",
        "\n",
        "You are a resolver tasked with finding the answers that best determines how all the topics in the list of topics can be grouped together.\n",
        "1) removing any redundant or duplicate answers.\n",
        "2) improving the answers based on the analysis of flaws\n",
        "3) printing the improved answer in full\n",
        "Let’s work this one out in a step by step way:\n",
        "\n",
        "Format the response in a JSON format with \"theme_name\", \"description\", and \"codes\" under the key \"Themes\".\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WZXOffol6E2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_5 = get_completion(system_text, user_text_5, response_format_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "collapsed": true,
        "id": "hYUCmaCQnpFM",
        "outputId": "35712f83-56c9-4bf7-daad-8913dba77224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BJuiloCEv6982Elj6gWkz2qOLE7Ku', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Themes\": [\\n    {\\n      \"theme_name\": \"AI Transparency and Accountability\",\\n      \"description\": \"Focuses on the significance of transparency in AI systems and the accountability mechanisms that ensure responsible AI usage.\",\\n      \"codes\": [\\n        \"Importance of Transparency\",\\n        \"AI Transparency Importance\",\\n        \"Transparency Tools for Users\",\\n        \"Explainability of AI Systems\",\\n        \"Transparent Disclosure Obligations\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Governance and Regulation Frameworks\",\\n      \"description\": \"Addresses the structures, frameworks, and approaches to regulate AI technologies, including the need for clear definitions and consistency in regulations.\",\\n      \"codes\": [\\n        \"Governance and Regulation\",\\n        \"Regulatory Frameworks Development\",\\n        \"\\'High-Risk\\' AI Regulations\",\\n        \"\\'Risk-Based\\' Approaches to Regulation\",\\n        \"Centralized Governance Coordination\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Ethical Considerations in AI\",\\n      \"description\": \"Explores ethical dilemmas associated with AI deployment, including data ethics, bias mitigation, and responsibilities of organizations.\",\\n      \"codes\": [\\n        \"Ethical Considerations in AI\",\\n        \"Bias Mitigation Focus\",\\n        \"Ethical Data Sharing Practices\",\\n        \"Human Rights Risk Assessments\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Stakeholder Engagement and Collaboration\",\\n      \"description\": \"Emphasizes the importance of engaging various stakeholders in discussions about AI governance, including public-private partnerships and community involvement.\",\\n      \"codes\": [\\n        \"Stakeholder Engagement\",\\n        \"Collaboration with Government\",\\n        \"Community Engagement in Regulation\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"Education and Public Awareness\",\\n      \"description\": \"Highlights the necessity of educating both organizations and the public on AI usage, transparency, ethical considerations, and literacy enhancement.\",\\n      \"codes\": [\\n        \"Education and Public Awareness\",\\n        \"AI Literacy Enhancement\",\\n        \"Training for Workforce\",\\n        \"Consumer Education on AI Use\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'Risk-Based\\' Approach to AI Management\",\\n      \"description\": \"\\'Risk-Based\\' approaches advocate for proportional regulatory responses based on the potential risks associated with different types of AI systems.\",\\n      \"codes\": [\\n        \"\\'Risk-Based\\' Approach Advocacy\",\\n        \"\\'Risk-Based\\' Regulation Approach\",\\n        \"\\'High-Risk\\' AI Regulations\"\\n      ]\\n    },\\n    {\\n      \"theme_name\": \"\\'Inclusivity and Fairness\\'\",\\n      \"description\": \"\\'Inclusivity and Fairness\\' refers to ensuring that AI applications are developed and deployed equitably, minimizing biases that could lead to discrimination.\",\\n      \"codes\": [\\n        \"\\'Inclusivity in AI Applications\\'\",\\n        \"\\'Fairness and Inclusion Focus\\'\"\\n      ]\\n    }\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1744085967, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=565, prompt_tokens=1814, total_tokens=2379, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'json' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-483bef3e5f81>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_text_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_format_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data5 = json.loads(result_5)\n",
        "\n",
        "data5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZXnmm99oCp4",
        "outputId": "2eb8ec01-d5b8-4610-a92c-876d5cb9e30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Themes': [{'theme_name': 'AI Transparency and Accountability',\n",
              "   'description': 'Focuses on the significance of transparency in AI systems and the accountability mechanisms that ensure responsible AI usage.',\n",
              "   'codes': ['Importance of Transparency',\n",
              "    'AI Transparency Importance',\n",
              "    'Transparency Tools for Users',\n",
              "    'Explainability of AI Systems',\n",
              "    'Transparent Disclosure Obligations']},\n",
              "  {'theme_name': 'Governance and Regulation Frameworks',\n",
              "   'description': 'Addresses the structures, frameworks, and approaches to regulate AI technologies, including the need for clear definitions and consistency in regulations.',\n",
              "   'codes': ['Governance and Regulation',\n",
              "    'Regulatory Frameworks Development',\n",
              "    \"'High-Risk' AI Regulations\",\n",
              "    \"'Risk-Based' Approaches to Regulation\",\n",
              "    'Centralized Governance Coordination']},\n",
              "  {'theme_name': 'Ethical Considerations in AI',\n",
              "   'description': 'Explores ethical dilemmas associated with AI deployment, including data ethics, bias mitigation, and responsibilities of organizations.',\n",
              "   'codes': ['Ethical Considerations in AI',\n",
              "    'Bias Mitigation Focus',\n",
              "    'Ethical Data Sharing Practices',\n",
              "    'Human Rights Risk Assessments']},\n",
              "  {'theme_name': 'Stakeholder Engagement and Collaboration',\n",
              "   'description': 'Emphasizes the importance of engaging various stakeholders in discussions about AI governance, including public-private partnerships and community involvement.',\n",
              "   'codes': ['Stakeholder Engagement',\n",
              "    'Collaboration with Government',\n",
              "    'Community Engagement in Regulation']},\n",
              "  {'theme_name': 'Education and Public Awareness',\n",
              "   'description': 'Highlights the necessity of educating both organizations and the public on AI usage, transparency, ethical considerations, and literacy enhancement.',\n",
              "   'codes': ['Education and Public Awareness',\n",
              "    'AI Literacy Enhancement',\n",
              "    'Training for Workforce',\n",
              "    'Consumer Education on AI Use']},\n",
              "  {'theme_name': \"'Risk-Based' Approach to AI Management\",\n",
              "   'description': \"'Risk-Based' approaches advocate for proportional regulatory responses based on the potential risks associated with different types of AI systems.\",\n",
              "   'codes': [\"'Risk-Based' Approach Advocacy\",\n",
              "    \"'Risk-Based' Regulation Approach\",\n",
              "    \"'High-Risk' AI Regulations\"]},\n",
              "  {'theme_name': \"'Inclusivity and Fairness'\",\n",
              "   'description': \"'Inclusivity and Fairness' refers to ensuring that AI applications are developed and deployed equitably, minimizing biases that could lead to discrimination.\",\n",
              "   'codes': [\"'Inclusivity in AI Applications'\",\n",
              "    \"'Fairness and Inclusion Focus'\"]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_themefinal = pd.DataFrame(data5[\"Themes\"])\n",
        "df_themefinal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Jqdw4gBeoQaU",
        "outputId": "9b4b3b99-c244-4a4f-c666-a2da285ed7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 theme_name  \\\n",
              "0        AI Transparency and Accountability   \n",
              "1      Governance and Regulation Frameworks   \n",
              "2              Ethical Considerations in AI   \n",
              "3  Stakeholder Engagement and Collaboration   \n",
              "4            Education and Public Awareness   \n",
              "5    'Risk-Based' Approach to AI Management   \n",
              "6                'Inclusivity and Fairness'   \n",
              "\n",
              "                                         description  \\\n",
              "0  Focuses on the significance of transparency in...   \n",
              "1  Addresses the structures, frameworks, and appr...   \n",
              "2  Explores ethical dilemmas associated with AI d...   \n",
              "3  Emphasizes the importance of engaging various ...   \n",
              "4  Highlights the necessity of educating both org...   \n",
              "5  'Risk-Based' approaches advocate for proportio...   \n",
              "6  'Inclusivity and Fairness' refers to ensuring ...   \n",
              "\n",
              "                                               codes  \n",
              "0  [Importance of Transparency, AI Transparency I...  \n",
              "1  [Governance and Regulation, Regulatory Framewo...  \n",
              "2  [Ethical Considerations in AI, Bias Mitigation...  \n",
              "3  [Stakeholder Engagement, Collaboration with Go...  \n",
              "4  [Education and Public Awareness, AI Literacy E...  \n",
              "5  ['Risk-Based' Approach Advocacy, 'Risk-Based' ...  \n",
              "6  ['Inclusivity in AI Applications', 'Fairness a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fade8387-e47d-497b-a39c-b88d9938e505\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>theme_name</th>\n",
              "      <th>description</th>\n",
              "      <th>codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>Focuses on the significance of transparency in...</td>\n",
              "      <td>[Importance of Transparency, AI Transparency I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>Addresses the structures, frameworks, and appr...</td>\n",
              "      <td>[Governance and Regulation, Regulatory Framewo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Explores ethical dilemmas associated with AI d...</td>\n",
              "      <td>[Ethical Considerations in AI, Bias Mitigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>Emphasizes the importance of engaging various ...</td>\n",
              "      <td>[Stakeholder Engagement, Collaboration with Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Highlights the necessity of educating both org...</td>\n",
              "      <td>[Education and Public Awareness, AI Literacy E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-Based' approaches advocate for proportio...</td>\n",
              "      <td>['Risk-Based' Approach Advocacy, 'Risk-Based' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>'Inclusivity and Fairness'</td>\n",
              "      <td>'Inclusivity and Fairness' refers to ensuring ...</td>\n",
              "      <td>['Inclusivity in AI Applications', 'Fairness a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fade8387-e47d-497b-a39c-b88d9938e505')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fade8387-e47d-497b-a39c-b88d9938e505 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fade8387-e47d-497b-a39c-b88d9938e505');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2bfb4f3-722d-4e3a-b56e-ffb2a9a36e8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2bfb4f3-722d-4e3a-b56e-ffb2a9a36e8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2bfb4f3-722d-4e3a-b56e-ffb2a9a36e8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_980984c3-391a-4b6c-8297-bcb42e14197f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_themefinal')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_980984c3-391a-4b6c-8297-bcb42e14197f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_themefinal');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_themefinal",
              "summary": "{\n  \"name\": \"df_themefinal\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"theme_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"AI Transparency and Accountability\",\n          \"Governance and Regulation Frameworks\",\n          \"'Risk-Based' Approach to AI Management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Focuses on the significance of transparency in AI systems and the accountability mechanisms that ensure responsible AI usage.\",\n          \"Addresses the structures, frameworks, and approaches to regulate AI technologies, including the need for clear definitions and consistency in regulations.\",\n          \"'Risk-Based' approaches advocate for proportional regulatory responses based on the potential risks associated with different types of AI systems.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"codes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_expandedfinal = pd.DataFrame(columns=['code', 'theme', 'description'])\n",
        "\n",
        "for index, row in df_themefinal.iterrows():\n",
        "  codes_str = row['codes']\n",
        "  #codes_list = [code.strip() for code in codes_str.split(',')]\n",
        "  for code in codes_str:\n",
        "    new_row = pd.DataFrame({'code': [code], 'theme': [row['theme_name']], 'description': [row['description']]})\n",
        "    df_expandedfinal = pd.concat([df_expandedfinal, new_row], ignore_index=True)\n",
        "\n",
        "df_expandedfinal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "I4Fz4uXzolPN",
        "outputId": "3ecf5c71-861f-4ff2-916f-374fe6667d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     code  \\\n",
              "0              Importance of Transparency   \n",
              "1              AI Transparency Importance   \n",
              "2            Transparency Tools for Users   \n",
              "3            Explainability of AI Systems   \n",
              "4      Transparent Disclosure Obligations   \n",
              "5               Governance and Regulation   \n",
              "6       Regulatory Frameworks Development   \n",
              "7              'High-Risk' AI Regulations   \n",
              "8   'Risk-Based' Approaches to Regulation   \n",
              "9     Centralized Governance Coordination   \n",
              "10           Ethical Considerations in AI   \n",
              "11                  Bias Mitigation Focus   \n",
              "12         Ethical Data Sharing Practices   \n",
              "13          Human Rights Risk Assessments   \n",
              "14                 Stakeholder Engagement   \n",
              "15          Collaboration with Government   \n",
              "16     Community Engagement in Regulation   \n",
              "17         Education and Public Awareness   \n",
              "18                AI Literacy Enhancement   \n",
              "19                 Training for Workforce   \n",
              "20           Consumer Education on AI Use   \n",
              "21         'Risk-Based' Approach Advocacy   \n",
              "22       'Risk-Based' Regulation Approach   \n",
              "23             'High-Risk' AI Regulations   \n",
              "24       'Inclusivity in AI Applications'   \n",
              "25         'Fairness and Inclusion Focus'   \n",
              "\n",
              "                                       theme  \\\n",
              "0         AI Transparency and Accountability   \n",
              "1         AI Transparency and Accountability   \n",
              "2         AI Transparency and Accountability   \n",
              "3         AI Transparency and Accountability   \n",
              "4         AI Transparency and Accountability   \n",
              "5       Governance and Regulation Frameworks   \n",
              "6       Governance and Regulation Frameworks   \n",
              "7       Governance and Regulation Frameworks   \n",
              "8       Governance and Regulation Frameworks   \n",
              "9       Governance and Regulation Frameworks   \n",
              "10              Ethical Considerations in AI   \n",
              "11              Ethical Considerations in AI   \n",
              "12              Ethical Considerations in AI   \n",
              "13              Ethical Considerations in AI   \n",
              "14  Stakeholder Engagement and Collaboration   \n",
              "15  Stakeholder Engagement and Collaboration   \n",
              "16  Stakeholder Engagement and Collaboration   \n",
              "17            Education and Public Awareness   \n",
              "18            Education and Public Awareness   \n",
              "19            Education and Public Awareness   \n",
              "20            Education and Public Awareness   \n",
              "21    'Risk-Based' Approach to AI Management   \n",
              "22    'Risk-Based' Approach to AI Management   \n",
              "23    'Risk-Based' Approach to AI Management   \n",
              "24                'Inclusivity and Fairness'   \n",
              "25                'Inclusivity and Fairness'   \n",
              "\n",
              "                                          description  \n",
              "0   Focuses on the significance of transparency in...  \n",
              "1   Focuses on the significance of transparency in...  \n",
              "2   Focuses on the significance of transparency in...  \n",
              "3   Focuses on the significance of transparency in...  \n",
              "4   Focuses on the significance of transparency in...  \n",
              "5   Addresses the structures, frameworks, and appr...  \n",
              "6   Addresses the structures, frameworks, and appr...  \n",
              "7   Addresses the structures, frameworks, and appr...  \n",
              "8   Addresses the structures, frameworks, and appr...  \n",
              "9   Addresses the structures, frameworks, and appr...  \n",
              "10  Explores ethical dilemmas associated with AI d...  \n",
              "11  Explores ethical dilemmas associated with AI d...  \n",
              "12  Explores ethical dilemmas associated with AI d...  \n",
              "13  Explores ethical dilemmas associated with AI d...  \n",
              "14  Emphasizes the importance of engaging various ...  \n",
              "15  Emphasizes the importance of engaging various ...  \n",
              "16  Emphasizes the importance of engaging various ...  \n",
              "17  Highlights the necessity of educating both org...  \n",
              "18  Highlights the necessity of educating both org...  \n",
              "19  Highlights the necessity of educating both org...  \n",
              "20  Highlights the necessity of educating both org...  \n",
              "21  'Risk-Based' approaches advocate for proportio...  \n",
              "22  'Risk-Based' approaches advocate for proportio...  \n",
              "23  'Risk-Based' approaches advocate for proportio...  \n",
              "24  'Inclusivity and Fairness' refers to ensuring ...  \n",
              "25  'Inclusivity and Fairness' refers to ensuring ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f785a6a3-3813-474e-be28-5de06a2f8453\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>theme</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Importance of Transparency</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>Focuses on the significance of transparency in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI Transparency Importance</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>Focuses on the significance of transparency in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transparency Tools for Users</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>Focuses on the significance of transparency in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Explainability of AI Systems</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>Focuses on the significance of transparency in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Transparent Disclosure Obligations</td>\n",
              "      <td>AI Transparency and Accountability</td>\n",
              "      <td>Focuses on the significance of transparency in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Governance and Regulation</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>Addresses the structures, frameworks, and appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regulatory Frameworks Development</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>Addresses the structures, frameworks, and appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>Addresses the structures, frameworks, and appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>'Risk-Based' Approaches to Regulation</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>Addresses the structures, frameworks, and appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Centralized Governance Coordination</td>\n",
              "      <td>Governance and Regulation Frameworks</td>\n",
              "      <td>Addresses the structures, frameworks, and appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Explores ethical dilemmas associated with AI d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bias Mitigation Focus</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Explores ethical dilemmas associated with AI d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ethical Data Sharing Practices</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Explores ethical dilemmas associated with AI d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Human Rights Risk Assessments</td>\n",
              "      <td>Ethical Considerations in AI</td>\n",
              "      <td>Explores ethical dilemmas associated with AI d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stakeholder Engagement</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>Emphasizes the importance of engaging various ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Collaboration with Government</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>Emphasizes the importance of engaging various ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Community Engagement in Regulation</td>\n",
              "      <td>Stakeholder Engagement and Collaboration</td>\n",
              "      <td>Emphasizes the importance of engaging various ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Highlights the necessity of educating both org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>AI Literacy Enhancement</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Highlights the necessity of educating both org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Training for Workforce</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Highlights the necessity of educating both org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Consumer Education on AI Use</td>\n",
              "      <td>Education and Public Awareness</td>\n",
              "      <td>Highlights the necessity of educating both org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>'Risk-Based' Approach Advocacy</td>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-Based' approaches advocate for proportio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>'Risk-Based' Regulation Approach</td>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-Based' approaches advocate for proportio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>'High-Risk' AI Regulations</td>\n",
              "      <td>'Risk-Based' Approach to AI Management</td>\n",
              "      <td>'Risk-Based' approaches advocate for proportio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>'Inclusivity in AI Applications'</td>\n",
              "      <td>'Inclusivity and Fairness'</td>\n",
              "      <td>'Inclusivity and Fairness' refers to ensuring ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>'Fairness and Inclusion Focus'</td>\n",
              "      <td>'Inclusivity and Fairness'</td>\n",
              "      <td>'Inclusivity and Fairness' refers to ensuring ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f785a6a3-3813-474e-be28-5de06a2f8453')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f785a6a3-3813-474e-be28-5de06a2f8453 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f785a6a3-3813-474e-be28-5de06a2f8453');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5490b518-2fa8-49ab-af22-52d028ba0775\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5490b518-2fa8-49ab-af22-52d028ba0775')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5490b518-2fa8-49ab-af22-52d028ba0775 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_491b86dd-8e06-4bad-a0d9-466e4221a1d0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_expandedfinal')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_491b86dd-8e06-4bad-a0d9-466e4221a1d0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_expandedfinal');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_expandedfinal",
              "summary": "{\n  \"name\": \"df_expandedfinal\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"'Risk-Based' Approaches to Regulation\",\n          \"Community Engagement in Regulation\",\n          \"Importance of Transparency\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theme\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"AI Transparency and Accountability\",\n          \"Governance and Regulation Frameworks\",\n          \"'Risk-Based' Approach to AI Management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Focuses on the significance of transparency in AI systems and the accountability mechanisms that ensure responsible AI usage.\",\n          \"Addresses the structures, frameworks, and approaches to regulate AI technologies, including the need for clear definitions and consistency in regulations.\",\n          \"'Risk-Based' approaches advocate for proportional regulatory responses based on the potential risks associated with different types of AI systems.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df_expandedfinal is not None:\n",
        "    excel_filepath = \"/content/drive/MyDrive/themes_8_docs_expanded_final.xlsx\"  # Replace with desired path\n",
        "    df_expandedfinal.to_excel(excel_filepath, index=False)  # Set index=False to avoid writing row indices\n",
        "    print(f\"DataFrame exported to: {excel_filepath}\")\n",
        "else:\n",
        "    print(\"DataFrame 'df_theme' is empty or None. Cannot export.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtTdcUzoo8Zk",
        "outputId": "e2c2f725-ecdf-47e6-8a85-5449cc499df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame exported to: /content/drive/MyDrive/themes_8_docs_expanded_final.xlsx\n"
          ]
        }
      ]
    }
  ]
}